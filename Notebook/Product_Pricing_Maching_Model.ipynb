{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "6a13d9ab354b4a268ce9e8d466f4292d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_24089cc9e47849d0a2edf68791ccbe23",
              "IPY_MODEL_2cb46ebe65974b289916d5146825d186",
              "IPY_MODEL_d672fd43ce734b15a8d67dc69cf9f6ed"
            ],
            "layout": "IPY_MODEL_3738a43c2dca4375a66e69ce1f83cc99"
          }
        },
        "24089cc9e47849d0a2edf68791ccbe23": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_668d019dc7574d41acf1bbac667fbab5",
            "placeholder": "​",
            "style": "IPY_MODEL_f5ff15a0877b4df5ab23dc8bec6fa966",
            "value": "modules.json: 100%"
          }
        },
        "2cb46ebe65974b289916d5146825d186": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_b95477ae42564db4a76c93b5633c4e91",
            "max": 349,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_d780bf59ce864743833719ca28b4f1db",
            "value": 349
          }
        },
        "d672fd43ce734b15a8d67dc69cf9f6ed": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_60e00d43356a4dc0b018bb30be475c72",
            "placeholder": "​",
            "style": "IPY_MODEL_b935462be84a4a4dbfc91bee7979b095",
            "value": " 349/349 [00:00&lt;00:00, 25.4kB/s]"
          }
        },
        "3738a43c2dca4375a66e69ce1f83cc99": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "668d019dc7574d41acf1bbac667fbab5": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f5ff15a0877b4df5ab23dc8bec6fa966": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "b95477ae42564db4a76c93b5633c4e91": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d780bf59ce864743833719ca28b4f1db": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "60e00d43356a4dc0b018bb30be475c72": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b935462be84a4a4dbfc91bee7979b095": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "2ce9ca98834542f88cc718ff3e45d14c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_0340fe685af34a36aa8707f69c203f78",
              "IPY_MODEL_6a36a8f4b3d944a9839bb9c29cb15df4",
              "IPY_MODEL_47671fb6cee0439b99e45050e0d50091"
            ],
            "layout": "IPY_MODEL_1d2562bf68ff4490b5e435df924fcd47"
          }
        },
        "0340fe685af34a36aa8707f69c203f78": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_12b15bea1d2b4f6889c181cc8d2d8543",
            "placeholder": "​",
            "style": "IPY_MODEL_7a3d2507451e400a9764e9d45ff1604c",
            "value": "config_sentence_transformers.json: 100%"
          }
        },
        "6a36a8f4b3d944a9839bb9c29cb15df4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_febb14da97eb498cadb934e1fbbbb204",
            "max": 116,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_20c7ace016be472094ce6337d4f56087",
            "value": 116
          }
        },
        "47671fb6cee0439b99e45050e0d50091": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_4964d752b6d640dfb9c512cbaf6c503f",
            "placeholder": "​",
            "style": "IPY_MODEL_1ab97b7af2ac4c04b4e162322fb812cd",
            "value": " 116/116 [00:00&lt;00:00, 12.0kB/s]"
          }
        },
        "1d2562bf68ff4490b5e435df924fcd47": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "12b15bea1d2b4f6889c181cc8d2d8543": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "7a3d2507451e400a9764e9d45ff1604c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "febb14da97eb498cadb934e1fbbbb204": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "20c7ace016be472094ce6337d4f56087": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "4964d752b6d640dfb9c512cbaf6c503f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "1ab97b7af2ac4c04b4e162322fb812cd": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "f2c85fde80c04cda92347dd9b7719a4b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_569251917da84fbfa0d4614d82666590",
              "IPY_MODEL_ed1330da7c0c47d781030b0b885a3185",
              "IPY_MODEL_e2650e8ab5784d6d9c009b872bafa686"
            ],
            "layout": "IPY_MODEL_0742ba8280554ab99043aa369dd122b0"
          }
        },
        "569251917da84fbfa0d4614d82666590": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_40ea450145a34563b2d1b993c4c759b8",
            "placeholder": "​",
            "style": "IPY_MODEL_fe5023f9c31f4a689d14532a07cb88db",
            "value": "README.md: "
          }
        },
        "ed1330da7c0c47d781030b0b885a3185": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_5352943d3881462d9474cfe63b1c5236",
            "max": 1,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_1684dc022f374b48bed94b0ac0ff8d02",
            "value": 1
          }
        },
        "e2650e8ab5784d6d9c009b872bafa686": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_68c00567039d489893d4cfd7afdb4333",
            "placeholder": "​",
            "style": "IPY_MODEL_a1cb897ee2654944919df491803af46e",
            "value": " 10.5k/? [00:00&lt;00:00, 859kB/s]"
          }
        },
        "0742ba8280554ab99043aa369dd122b0": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "40ea450145a34563b2d1b993c4c759b8": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "fe5023f9c31f4a689d14532a07cb88db": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "5352943d3881462d9474cfe63b1c5236": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": "20px"
          }
        },
        "1684dc022f374b48bed94b0ac0ff8d02": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "68c00567039d489893d4cfd7afdb4333": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a1cb897ee2654944919df491803af46e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "cfd9a0ebace44b4780f46dae13aeeb9e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_b5c9ce9a6f5449f58ededada0c295aef",
              "IPY_MODEL_08184348d24047459470584b94be9e54",
              "IPY_MODEL_6ff7d6672cdc4341827ca87999c3d624"
            ],
            "layout": "IPY_MODEL_389a8e50d63d481b9438b446618269c8"
          }
        },
        "b5c9ce9a6f5449f58ededada0c295aef": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_eb3c37d7b6804ed79033e24900779074",
            "placeholder": "​",
            "style": "IPY_MODEL_606f25c1e0af4a98bd5eb93804793f6b",
            "value": "sentence_bert_config.json: 100%"
          }
        },
        "08184348d24047459470584b94be9e54": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_f988c885a19d46acb76990eaa7dcdb3f",
            "max": 53,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_979b415731764679a1844c86adfdb9f2",
            "value": 53
          }
        },
        "6ff7d6672cdc4341827ca87999c3d624": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_0cc923366347446eaf88b173f695f5a1",
            "placeholder": "​",
            "style": "IPY_MODEL_387791244807446781c0c1d1f6ee5f47",
            "value": " 53.0/53.0 [00:00&lt;00:00, 2.92kB/s]"
          }
        },
        "389a8e50d63d481b9438b446618269c8": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "eb3c37d7b6804ed79033e24900779074": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "606f25c1e0af4a98bd5eb93804793f6b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "f988c885a19d46acb76990eaa7dcdb3f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "979b415731764679a1844c86adfdb9f2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "0cc923366347446eaf88b173f695f5a1": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "387791244807446781c0c1d1f6ee5f47": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "3a103142f6194d95b87218965bc589f2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_c8dddfae39014c8180536c102f1f0ce8",
              "IPY_MODEL_39988fee25704caf9f05aee9cd661549",
              "IPY_MODEL_2df64b95ea874d1baaaaaf97ad9d6d37"
            ],
            "layout": "IPY_MODEL_9ab9c4224870477ca666d4642c3833b8"
          }
        },
        "c8dddfae39014c8180536c102f1f0ce8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_0ce4b54e439b47a68d4fadfd00806946",
            "placeholder": "​",
            "style": "IPY_MODEL_9ed0a8a086b04f8f9186a86c95e28c01",
            "value": "config.json: 100%"
          }
        },
        "39988fee25704caf9f05aee9cd661549": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_f23582aaa73e42398fa1cbb89191fbc0",
            "max": 612,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_3ed0f34b29924e58be743e4091463700",
            "value": 612
          }
        },
        "2df64b95ea874d1baaaaaf97ad9d6d37": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_ea74e085b016441ba5785a193c31f3af",
            "placeholder": "​",
            "style": "IPY_MODEL_3aa3b9a34e914e459175be29116c69c0",
            "value": " 612/612 [00:00&lt;00:00, 47.1kB/s]"
          }
        },
        "9ab9c4224870477ca666d4642c3833b8": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "0ce4b54e439b47a68d4fadfd00806946": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "9ed0a8a086b04f8f9186a86c95e28c01": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "f23582aaa73e42398fa1cbb89191fbc0": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "3ed0f34b29924e58be743e4091463700": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "ea74e085b016441ba5785a193c31f3af": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "3aa3b9a34e914e459175be29116c69c0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "4836cb77b43841c2b94ff15b593d2a97": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_bd1ed6b893564a2ca4f06b14403f64e6",
              "IPY_MODEL_a6d5b5357a1b4f7ab0f610eed13101c1",
              "IPY_MODEL_4cd771acee414346bee1c69ed0210347"
            ],
            "layout": "IPY_MODEL_7512d8ec86874acf8edbf2d67e5da97f"
          }
        },
        "bd1ed6b893564a2ca4f06b14403f64e6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_a141d31bd312477ca41bbedf2c9e55f7",
            "placeholder": "​",
            "style": "IPY_MODEL_dad3a5cdd3b34a5990ec870e26f3aefe",
            "value": "model.safetensors: 100%"
          }
        },
        "a6d5b5357a1b4f7ab0f610eed13101c1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_244b7a9b004c4fd09e64eb51402f839e",
            "max": 90868376,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_0eeb73b8b4284488a3e663dec9fdd1ee",
            "value": 90868376
          }
        },
        "4cd771acee414346bee1c69ed0210347": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_dec1ce2657d9441887af7c380de39cd1",
            "placeholder": "​",
            "style": "IPY_MODEL_8cdddf5a9ff945dba8ba79fee1ecba15",
            "value": " 90.9M/90.9M [00:01&lt;00:00, 121MB/s]"
          }
        },
        "7512d8ec86874acf8edbf2d67e5da97f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a141d31bd312477ca41bbedf2c9e55f7": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "dad3a5cdd3b34a5990ec870e26f3aefe": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "244b7a9b004c4fd09e64eb51402f839e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "0eeb73b8b4284488a3e663dec9fdd1ee": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "dec1ce2657d9441887af7c380de39cd1": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "8cdddf5a9ff945dba8ba79fee1ecba15": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "8cf34151c67141cfb0a906fb16d27b4e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_6048519d77514830951a531a7cfd4c39",
              "IPY_MODEL_1b0cd674b3f34967ac694fda35157947",
              "IPY_MODEL_e5736d6a42be4b4c8ca11bab167644bc"
            ],
            "layout": "IPY_MODEL_f2c827799c554d7994dd0e4cfc192e2c"
          }
        },
        "6048519d77514830951a531a7cfd4c39": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_5a08503138304989bb2687403ca6997b",
            "placeholder": "​",
            "style": "IPY_MODEL_a7a811c5d3624689a2aff4d384acbcd8",
            "value": "tokenizer_config.json: 100%"
          }
        },
        "1b0cd674b3f34967ac694fda35157947": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_ec008ac6f10340b4bcb6795d2cd97a9f",
            "max": 350,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_428aae06410342dfae42b27034a2424d",
            "value": 350
          }
        },
        "e5736d6a42be4b4c8ca11bab167644bc": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_71b81da4cf584650b6ec0f2e3fda2924",
            "placeholder": "​",
            "style": "IPY_MODEL_27f2c5da30cf4241875a69f7404ba316",
            "value": " 350/350 [00:00&lt;00:00, 41.6kB/s]"
          }
        },
        "f2c827799c554d7994dd0e4cfc192e2c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "5a08503138304989bb2687403ca6997b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a7a811c5d3624689a2aff4d384acbcd8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "ec008ac6f10340b4bcb6795d2cd97a9f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "428aae06410342dfae42b27034a2424d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "71b81da4cf584650b6ec0f2e3fda2924": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "27f2c5da30cf4241875a69f7404ba316": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "8cf9656ae1ac4b0ab7669482a7b08a47": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_4b4800e95ce241a9a2a28a6aa5658340",
              "IPY_MODEL_3fa9643640e64694a346a2a2ccb366f6",
              "IPY_MODEL_bec475058337465fa25ceae79c2c7496"
            ],
            "layout": "IPY_MODEL_8b8227f5efc54755ae900cbecb98dad8"
          }
        },
        "4b4800e95ce241a9a2a28a6aa5658340": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_22274100b248418b8b8fe92710b21631",
            "placeholder": "​",
            "style": "IPY_MODEL_ac0f8cc9648d47008acdab8e7f4088a9",
            "value": "vocab.txt: "
          }
        },
        "3fa9643640e64694a346a2a2ccb366f6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_2b4952a7636a44a3a1f8d449765310fc",
            "max": 1,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_0a54c2ac7c7545d69fc540ab7c96f2c5",
            "value": 1
          }
        },
        "bec475058337465fa25ceae79c2c7496": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_7d9f1f6d07ed4daf8e0ffd54f97a4368",
            "placeholder": "​",
            "style": "IPY_MODEL_eba8a5e575b84841bcf9840acec516f1",
            "value": " 232k/? [00:00&lt;00:00, 13.7MB/s]"
          }
        },
        "8b8227f5efc54755ae900cbecb98dad8": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "22274100b248418b8b8fe92710b21631": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ac0f8cc9648d47008acdab8e7f4088a9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "2b4952a7636a44a3a1f8d449765310fc": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": "20px"
          }
        },
        "0a54c2ac7c7545d69fc540ab7c96f2c5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "7d9f1f6d07ed4daf8e0ffd54f97a4368": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "eba8a5e575b84841bcf9840acec516f1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "b54434c994a14f7791356a014d9b053a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_931c507e400042479e48a4fd393a82db",
              "IPY_MODEL_3e60bd16e9ba468289c11782c75529b8",
              "IPY_MODEL_dadbc9c3819d487a99c1a86ebf88e48b"
            ],
            "layout": "IPY_MODEL_204dc52d22d94f82b4d3d721e5332533"
          }
        },
        "931c507e400042479e48a4fd393a82db": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_a29b96916ead473fbe1652ac113813dc",
            "placeholder": "​",
            "style": "IPY_MODEL_f274485ec84d45bcbc579a30025f1700",
            "value": "tokenizer.json: "
          }
        },
        "3e60bd16e9ba468289c11782c75529b8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_0c5c587c20ee4a97ba52851922110ed0",
            "max": 1,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_fc08126bfc744e1993a8e7bf954057cf",
            "value": 1
          }
        },
        "dadbc9c3819d487a99c1a86ebf88e48b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_fa2ff76a8b66414790fdf3344cd283a7",
            "placeholder": "​",
            "style": "IPY_MODEL_4024ac0dd9e64815b2cf7e5445d2c292",
            "value": " 466k/? [00:00&lt;00:00, 33.3MB/s]"
          }
        },
        "204dc52d22d94f82b4d3d721e5332533": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a29b96916ead473fbe1652ac113813dc": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f274485ec84d45bcbc579a30025f1700": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "0c5c587c20ee4a97ba52851922110ed0": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": "20px"
          }
        },
        "fc08126bfc744e1993a8e7bf954057cf": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "fa2ff76a8b66414790fdf3344cd283a7": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "4024ac0dd9e64815b2cf7e5445d2c292": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "da85837c44024e1bb3e1474ebe79fc6c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_41655a9077c2418492ea4bc8aaea3242",
              "IPY_MODEL_9090576ba06a48ac856af6ca668b4f80",
              "IPY_MODEL_744a69faa6ee4be0a09f78cdd3892d16"
            ],
            "layout": "IPY_MODEL_9466ed28125942fab7df5ed6ce7fafd7"
          }
        },
        "41655a9077c2418492ea4bc8aaea3242": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_bced22f440754246b27ce73052eb8d18",
            "placeholder": "​",
            "style": "IPY_MODEL_a9465e9ebaf1480fbacab313e042f246",
            "value": "special_tokens_map.json: 100%"
          }
        },
        "9090576ba06a48ac856af6ca668b4f80": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_b87e0e1d680842a9bdbb9c2749158357",
            "max": 112,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_16a532a074e64cb687fe344085998be8",
            "value": 112
          }
        },
        "744a69faa6ee4be0a09f78cdd3892d16": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_edd308a259dc4f5aa32672e179111ec9",
            "placeholder": "​",
            "style": "IPY_MODEL_9c32e6150c5b42858be46f2e182c3811",
            "value": " 112/112 [00:00&lt;00:00, 8.55kB/s]"
          }
        },
        "9466ed28125942fab7df5ed6ce7fafd7": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "bced22f440754246b27ce73052eb8d18": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a9465e9ebaf1480fbacab313e042f246": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "b87e0e1d680842a9bdbb9c2749158357": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "16a532a074e64cb687fe344085998be8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "edd308a259dc4f5aa32672e179111ec9": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "9c32e6150c5b42858be46f2e182c3811": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "aa1c905dde064f2d84a306047605438b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_082df5b537a14a53b66ad86ab1ec4716",
              "IPY_MODEL_791d17b0e56449839d1382eef2bdcdbe",
              "IPY_MODEL_aaded44877bb4089aa3eb4707e988c91"
            ],
            "layout": "IPY_MODEL_1df0f89c4dc04f8baf9b862f209a2cbb"
          }
        },
        "082df5b537a14a53b66ad86ab1ec4716": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_bf2b859a3a9a4e1eb936da3417af7a4f",
            "placeholder": "​",
            "style": "IPY_MODEL_9e8f9e0e24fc4d688006ae5046c3da55",
            "value": "config.json: 100%"
          }
        },
        "791d17b0e56449839d1382eef2bdcdbe": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_9b3f9f07813544699e14ee6752b3a967",
            "max": 190,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_ab19f7a3722c4c4aa3c8ba777cc3fa9a",
            "value": 190
          }
        },
        "aaded44877bb4089aa3eb4707e988c91": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_10f0c3bc74ec4af7b7b2588e9f235495",
            "placeholder": "​",
            "style": "IPY_MODEL_fd439e8b94f14a88aa97f6ee64760e3b",
            "value": " 190/190 [00:00&lt;00:00, 21.8kB/s]"
          }
        },
        "1df0f89c4dc04f8baf9b862f209a2cbb": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "bf2b859a3a9a4e1eb936da3417af7a4f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "9e8f9e0e24fc4d688006ae5046c3da55": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "9b3f9f07813544699e14ee6752b3a967": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ab19f7a3722c4c4aa3c8ba777cc3fa9a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "10f0c3bc74ec4af7b7b2588e9f235495": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "fd439e8b94f14a88aa97f6ee64760e3b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# **Product Matching Model**\n"
      ],
      "metadata": {
        "id": "3g1zcqYk8Djl"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Import Required Libraries**"
      ],
      "metadata": {
        "id": "djGIKlF18TpE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import Dataset, DataLoader, random_split\n",
        "from sentence_transformers import SentenceTransformer\n",
        "import numpy as np\n",
        "from sklearn.metrics import precision_recall_fscore_support\n",
        "import pickle\n",
        "import os\n",
        "# Set random seeds for reproducibility\n",
        "torch.manual_seed(42)\n",
        "np.random.seed(42)"
      ],
      "metadata": {
        "id": "6aD09SNr8bef"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **2: Custom Dataset Class**\n",
        "\n",
        "- Inherits from PyTorch's Dataset class\n",
        "- Stores the DataFrame and implements required methods `(__len__ and __getitem__)`\n",
        "- Returns product title pairs with their match labels\n",
        "- Handles data type conversion for PyTorch compatibility"
      ],
      "metadata": {
        "id": "KVCPf_qi-NWY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class ProductPairDataset(Dataset):\n",
        "    \"\"\"\n",
        "    Custom PyTorch Dataset for product title pairs with pre-computed embeddings\n",
        "    \"\"\"\n",
        "    def __init__(self, dataframe, embedding_map):\n",
        "        \"\"\"\n",
        "        Initialize the dataset\n",
        "        Args:\n",
        "            dataframe: pandas DataFrame with columns ['title1', 'title2', 'match']\n",
        "            embedding_map: dictionary mapping titles to pre-computed embeddings\n",
        "        \"\"\"\n",
        "        self.data = dataframe.reset_index(drop=True)\n",
        "        self.embedding_map = embedding_map\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.data)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        \"\"\"\n",
        "        Get a single sample from the dataset\n",
        "        Returns:\n",
        "            tuple: (embedding1, embedding2, label)\n",
        "        \"\"\"\n",
        "        row = self.data.iloc[idx]\n",
        "\n",
        "        # Look up the pre-computed embeddings\n",
        "        embedding1 = self.embedding_map[row['title1']]\n",
        "        embedding2 = self.embedding_map[row['title2']]\n",
        "        label = float(row['match'])\n",
        "\n",
        "        return embedding1, embedding2, label"
      ],
      "metadata": {
        "id": "pfF6_VMQ-R-M"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **3: Siamese Network Architecture**\n",
        "\n",
        "- Uses pre-trained `all-MiniLM-L6-v2` SentenceTransformer as backbone\n",
        "- Freezes all SentenceTransformer parameters to prevent training\n",
        "- Adds a trainable projection head `(Linear->ReLU->Linear)` that outputs 128-dim embeddings\n",
        "- Implements shared weight architecture through forward_one method\n",
        "- Returns embeddings for both inputs in the pair"
      ],
      "metadata": {
        "id": "2eFQczHT_t7x"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class SiameseNetwork(nn.Module):\n",
        "    \"\"\"\n",
        "    Siamese Network for product matching using pre-computed SBERT embeddings\n",
        "    \"\"\"\n",
        "    def __init__(self, input_dim=384, embedding_dim=128):\n",
        "        \"\"\"\n",
        "        Args:\n",
        "            input_dim: dimension of input SBERT embeddings (384 for all-MiniLM-L6-v2)\n",
        "            embedding_dim: final output embedding dimension\n",
        "        \"\"\"\n",
        "        super(SiameseNetwork, self).__init__()\n",
        "\n",
        "        # The model now ONLY contains the trainable projection head\n",
        "        self.projection_head = nn.Sequential(\n",
        "            nn.Linear(input_dim, 256),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(256, embedding_dim)\n",
        "        )\n",
        "\n",
        "    def forward_one(self, embedding):\n",
        "        \"\"\"\n",
        "        Forward pass for one pre-computed embedding\n",
        "        Args:\n",
        "            embedding: pre-computed SBERT embedding tensor\n",
        "        Returns:\n",
        "            torch.Tensor: projected embedding vector\n",
        "        \"\"\"\n",
        "        return self.projection_head(embedding)\n",
        "\n",
        "    def forward(self, embedding1, embedding2):\n",
        "        \"\"\"\n",
        "        Forward pass for a pair of embeddings\n",
        "        Args:\n",
        "            embedding1: first pre-computed embedding\n",
        "            embedding2: second pre-computed embedding\n",
        "        Returns:\n",
        "            tuple: (projected_embedding1, projected_embedding2)\n",
        "        \"\"\"\n",
        "        output1 = self.forward_one(embedding1)\n",
        "        output2 = self.forward_one(embedding2)\n",
        "        return output1, output2"
      ],
      "metadata": {
        "id": "CQ6Y8K_O-bzV"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **4: Contrastive Loss Implementation**\n",
        "\n",
        "- Takes two embeddings and a label (1 for match, 0 for no match)\n",
        "- Calculates Euclidean distance between embeddings\n",
        "- Applies contrastive loss formula:\n",
        "\n",
        "  - For matching pairs (label=1): penalizes large distances\n",
        "  - For non-matching pairs (label=0): penalizes small distances (below margin)\n",
        "\n",
        "\n",
        "- Uses margin of 1.0 as specified"
      ],
      "metadata": {
        "id": "tPkmoNuPC4fj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class ContrastiveLoss(nn.Module):\n",
        "    \"\"\"\n",
        "    Contrastive Loss for Siamese Networks (Fixed Logic)\n",
        "    \"\"\"\n",
        "    def __init__(self, margin=1.0):\n",
        "        super(ContrastiveLoss, self).__init__()\n",
        "        self.margin = margin\n",
        "\n",
        "    def forward(self, embedding1, embedding2, label):\n",
        "        \"\"\"\n",
        "        Calculate contrastive loss with corrected logic\n",
        "        Args:\n",
        "            embedding1: first embedding vector\n",
        "            embedding2: second embedding vector\n",
        "            label: 1 for similar pairs (should have small distance)\n",
        "                  0 for dissimilar pairs (should have large distance)\n",
        "        Returns:\n",
        "            torch.Tensor: contrastive loss value\n",
        "        \"\"\"\n",
        "        # Calculate Euclidean distance\n",
        "        distance = torch.nn.functional.pairwise_distance(embedding1, embedding2)\n",
        "\n",
        "        # Corrected Contrastive loss formula:\n",
        "        # If match (label=1): penalize large distances (distance^2)\n",
        "        # If no-match (label=0): penalize small distances (margin-distance)^2\n",
        "        loss = (label) * torch.pow(distance, 2) + \\\n",
        "               (1 - label) * torch.pow(torch.clamp(self.margin - distance, min=0.0), 2)\n",
        "\n",
        "        return torch.mean(loss)"
      ],
      "metadata": {
        "id": "LJBxPd0gD6YU"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def precompute_embeddings(df, model_name='all-MiniLM-L6-v2'):\n",
        "    \"\"\"\n",
        "    Pre-compute SBERT embeddings for all unique titles\n",
        "    This dramatically speeds up training by avoiding repeated encoding\n",
        "    \"\"\"\n",
        "    print(\"Loading SentenceTransformer model...\")\n",
        "    text_encoder = SentenceTransformer(model_name)\n",
        "\n",
        "    print(\"Extracting unique titles...\")\n",
        "    # Get all unique titles from both columns\n",
        "    all_titles = pd.concat([df['title1'], df['title2']]).unique()\n",
        "    print(f\"Found {len(all_titles)} unique titles\")\n",
        "\n",
        "    print(\"Pre-computing SBERT embeddings...\")\n",
        "    # Create a dictionary mapping titles to their embeddings\n",
        "    title_to_embedding = {}\n",
        "\n",
        "    # Process in batches for memory efficiency\n",
        "    batch_size = 32\n",
        "    for i in range(0, len(all_titles), batch_size):\n",
        "        batch_titles = all_titles[i:i+batch_size]\n",
        "        batch_embeddings = text_encoder.encode(\n",
        "            batch_titles.tolist(),\n",
        "            convert_to_tensor=True,\n",
        "            show_progress_bar=False\n",
        "        )\n",
        "\n",
        "        # Store embeddings\n",
        "        for title, embedding in zip(batch_titles, batch_embeddings):\n",
        "            title_to_embedding[title] = embedding\n",
        "\n",
        "        if (i // batch_size + 1) % 10 == 0:\n",
        "            print(f\"Processed {i + len(batch_titles)}/{len(all_titles)} titles\")\n",
        "\n",
        "    print(f\"Successfully computed embeddings for {len(all_titles)} unique titles\")\n",
        "    return title_to_embedding"
      ],
      "metadata": {
        "id": "yShXCg_2GfXu"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **5: Data Loading and Preprocessing**\n",
        "\n",
        "- Reads the CSV file with product pairs\n",
        "- Creates the custom Dataset instance\n",
        "- Splits data into 80% training and 20% testing\n",
        "- Uses fixed random seed for reproducible splits\n",
        "- Creates DataLoader objects for batch processing\n",
        "- Prints data distribution statistics"
      ],
      "metadata": {
        "id": "uQUqd8dVE4KZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def load_and_prepare_data(csv_file_path, batch_size=32, test_split=0.2):\n",
        "    \"\"\"\n",
        "    Load data from CSV, pre-compute embeddings, and create train/test DataLoaders\n",
        "    \"\"\"\n",
        "    # Load the CSV file\n",
        "    print(f\"Loading data from {csv_file_path}...\")\n",
        "    df = pd.read_csv(csv_file_path)\n",
        "    print(f\"Loaded {len(df)} product pairs\")\n",
        "\n",
        "    # Display data distribution\n",
        "    print(f\"Matching pairs: {df['match'].sum()}\")\n",
        "    print(f\"Non-matching pairs: {len(df) - df['match'].sum()}\")\n",
        "\n",
        "    # Pre-compute all SBERT embeddings\n",
        "    embedding_map = precompute_embeddings(df)\n",
        "\n",
        "    # Create dataset with embedding map\n",
        "    full_dataset = ProductPairDataset(df, embedding_map)\n",
        "\n",
        "    # Calculate split sizes\n",
        "    test_size = int(len(full_dataset) * test_split)\n",
        "    train_size = len(full_dataset) - test_size\n",
        "\n",
        "    # Split dataset\n",
        "    train_dataset, test_dataset = random_split(\n",
        "        full_dataset,\n",
        "        [train_size, test_size],\n",
        "        generator=torch.Generator().manual_seed(42)  # For reproducibility\n",
        "    )\n",
        "\n",
        "    print(f\"Training samples: {len(train_dataset)}\")\n",
        "    print(f\"Testing samples: {len(test_dataset)}\")\n",
        "\n",
        "    # Create DataLoaders\n",
        "    train_loader = DataLoader(\n",
        "        train_dataset,\n",
        "        batch_size=batch_size,\n",
        "        shuffle=True,\n",
        "        num_workers=0  # Set to 0 to avoid multiprocessing issues\n",
        "    )\n",
        "\n",
        "    test_loader = DataLoader(\n",
        "        test_dataset,\n",
        "        batch_size=batch_size,\n",
        "        shuffle=False,\n",
        "        num_workers=0\n",
        "    )\n",
        "\n",
        "    return train_loader, test_loader, embedding_map"
      ],
      "metadata": {
        "id": "IgpLcWREETnM"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Configuration\n",
        "CSV_FILE = '/content/drive/MyDrive/Product Matching/Data/training_pairs.csv'\n",
        "BATCH_SIZE = 32\n",
        "\n",
        "\n",
        "train_loader, test_loader, embedding_map = load_and_prepare_data(\n",
        "            CSV_FILE,\n",
        "            batch_size=BATCH_SIZE,\n",
        "            test_split=0.2\n",
        ")"
      ],
      "metadata": {
        "id": "8mePFlAzFDMf",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000,
          "referenced_widgets": [
            "6a13d9ab354b4a268ce9e8d466f4292d",
            "24089cc9e47849d0a2edf68791ccbe23",
            "2cb46ebe65974b289916d5146825d186",
            "d672fd43ce734b15a8d67dc69cf9f6ed",
            "3738a43c2dca4375a66e69ce1f83cc99",
            "668d019dc7574d41acf1bbac667fbab5",
            "f5ff15a0877b4df5ab23dc8bec6fa966",
            "b95477ae42564db4a76c93b5633c4e91",
            "d780bf59ce864743833719ca28b4f1db",
            "60e00d43356a4dc0b018bb30be475c72",
            "b935462be84a4a4dbfc91bee7979b095",
            "2ce9ca98834542f88cc718ff3e45d14c",
            "0340fe685af34a36aa8707f69c203f78",
            "6a36a8f4b3d944a9839bb9c29cb15df4",
            "47671fb6cee0439b99e45050e0d50091",
            "1d2562bf68ff4490b5e435df924fcd47",
            "12b15bea1d2b4f6889c181cc8d2d8543",
            "7a3d2507451e400a9764e9d45ff1604c",
            "febb14da97eb498cadb934e1fbbbb204",
            "20c7ace016be472094ce6337d4f56087",
            "4964d752b6d640dfb9c512cbaf6c503f",
            "1ab97b7af2ac4c04b4e162322fb812cd",
            "f2c85fde80c04cda92347dd9b7719a4b",
            "569251917da84fbfa0d4614d82666590",
            "ed1330da7c0c47d781030b0b885a3185",
            "e2650e8ab5784d6d9c009b872bafa686",
            "0742ba8280554ab99043aa369dd122b0",
            "40ea450145a34563b2d1b993c4c759b8",
            "fe5023f9c31f4a689d14532a07cb88db",
            "5352943d3881462d9474cfe63b1c5236",
            "1684dc022f374b48bed94b0ac0ff8d02",
            "68c00567039d489893d4cfd7afdb4333",
            "a1cb897ee2654944919df491803af46e",
            "cfd9a0ebace44b4780f46dae13aeeb9e",
            "b5c9ce9a6f5449f58ededada0c295aef",
            "08184348d24047459470584b94be9e54",
            "6ff7d6672cdc4341827ca87999c3d624",
            "389a8e50d63d481b9438b446618269c8",
            "eb3c37d7b6804ed79033e24900779074",
            "606f25c1e0af4a98bd5eb93804793f6b",
            "f988c885a19d46acb76990eaa7dcdb3f",
            "979b415731764679a1844c86adfdb9f2",
            "0cc923366347446eaf88b173f695f5a1",
            "387791244807446781c0c1d1f6ee5f47",
            "3a103142f6194d95b87218965bc589f2",
            "c8dddfae39014c8180536c102f1f0ce8",
            "39988fee25704caf9f05aee9cd661549",
            "2df64b95ea874d1baaaaaf97ad9d6d37",
            "9ab9c4224870477ca666d4642c3833b8",
            "0ce4b54e439b47a68d4fadfd00806946",
            "9ed0a8a086b04f8f9186a86c95e28c01",
            "f23582aaa73e42398fa1cbb89191fbc0",
            "3ed0f34b29924e58be743e4091463700",
            "ea74e085b016441ba5785a193c31f3af",
            "3aa3b9a34e914e459175be29116c69c0",
            "4836cb77b43841c2b94ff15b593d2a97",
            "bd1ed6b893564a2ca4f06b14403f64e6",
            "a6d5b5357a1b4f7ab0f610eed13101c1",
            "4cd771acee414346bee1c69ed0210347",
            "7512d8ec86874acf8edbf2d67e5da97f",
            "a141d31bd312477ca41bbedf2c9e55f7",
            "dad3a5cdd3b34a5990ec870e26f3aefe",
            "244b7a9b004c4fd09e64eb51402f839e",
            "0eeb73b8b4284488a3e663dec9fdd1ee",
            "dec1ce2657d9441887af7c380de39cd1",
            "8cdddf5a9ff945dba8ba79fee1ecba15",
            "8cf34151c67141cfb0a906fb16d27b4e",
            "6048519d77514830951a531a7cfd4c39",
            "1b0cd674b3f34967ac694fda35157947",
            "e5736d6a42be4b4c8ca11bab167644bc",
            "f2c827799c554d7994dd0e4cfc192e2c",
            "5a08503138304989bb2687403ca6997b",
            "a7a811c5d3624689a2aff4d384acbcd8",
            "ec008ac6f10340b4bcb6795d2cd97a9f",
            "428aae06410342dfae42b27034a2424d",
            "71b81da4cf584650b6ec0f2e3fda2924",
            "27f2c5da30cf4241875a69f7404ba316",
            "8cf9656ae1ac4b0ab7669482a7b08a47",
            "4b4800e95ce241a9a2a28a6aa5658340",
            "3fa9643640e64694a346a2a2ccb366f6",
            "bec475058337465fa25ceae79c2c7496",
            "8b8227f5efc54755ae900cbecb98dad8",
            "22274100b248418b8b8fe92710b21631",
            "ac0f8cc9648d47008acdab8e7f4088a9",
            "2b4952a7636a44a3a1f8d449765310fc",
            "0a54c2ac7c7545d69fc540ab7c96f2c5",
            "7d9f1f6d07ed4daf8e0ffd54f97a4368",
            "eba8a5e575b84841bcf9840acec516f1",
            "b54434c994a14f7791356a014d9b053a",
            "931c507e400042479e48a4fd393a82db",
            "3e60bd16e9ba468289c11782c75529b8",
            "dadbc9c3819d487a99c1a86ebf88e48b",
            "204dc52d22d94f82b4d3d721e5332533",
            "a29b96916ead473fbe1652ac113813dc",
            "f274485ec84d45bcbc579a30025f1700",
            "0c5c587c20ee4a97ba52851922110ed0",
            "fc08126bfc744e1993a8e7bf954057cf",
            "fa2ff76a8b66414790fdf3344cd283a7",
            "4024ac0dd9e64815b2cf7e5445d2c292",
            "da85837c44024e1bb3e1474ebe79fc6c",
            "41655a9077c2418492ea4bc8aaea3242",
            "9090576ba06a48ac856af6ca668b4f80",
            "744a69faa6ee4be0a09f78cdd3892d16",
            "9466ed28125942fab7df5ed6ce7fafd7",
            "bced22f440754246b27ce73052eb8d18",
            "a9465e9ebaf1480fbacab313e042f246",
            "b87e0e1d680842a9bdbb9c2749158357",
            "16a532a074e64cb687fe344085998be8",
            "edd308a259dc4f5aa32672e179111ec9",
            "9c32e6150c5b42858be46f2e182c3811",
            "aa1c905dde064f2d84a306047605438b",
            "082df5b537a14a53b66ad86ab1ec4716",
            "791d17b0e56449839d1382eef2bdcdbe",
            "aaded44877bb4089aa3eb4707e988c91",
            "1df0f89c4dc04f8baf9b862f209a2cbb",
            "bf2b859a3a9a4e1eb936da3417af7a4f",
            "9e8f9e0e24fc4d688006ae5046c3da55",
            "9b3f9f07813544699e14ee6752b3a967",
            "ab19f7a3722c4c4aa3c8ba777cc3fa9a",
            "10f0c3bc74ec4af7b7b2588e9f235495",
            "fd439e8b94f14a88aa97f6ee64760e3b"
          ]
        },
        "outputId": "23cda104-4ad8-427a-834e-543a265a116c"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loading data from /content/drive/MyDrive/Product Matching/Data/training_pairs.csv...\n",
            "Loaded 102882 product pairs\n",
            "Matching pairs: 51441\n",
            "Non-matching pairs: 51441\n",
            "Loading SentenceTransformer model...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/huggingface_hub/utils/_auth.py:94: UserWarning: \n",
            "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
            "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
            "You will be able to reuse this secret in all of your notebooks.\n",
            "Please note that authentication is recommended but still optional to access public models or datasets.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "modules.json:   0%|          | 0.00/349 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "6a13d9ab354b4a268ce9e8d466f4292d"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "config_sentence_transformers.json:   0%|          | 0.00/116 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "2ce9ca98834542f88cc718ff3e45d14c"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "README.md: 0.00B [00:00, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "f2c85fde80c04cda92347dd9b7719a4b"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "sentence_bert_config.json:   0%|          | 0.00/53.0 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "cfd9a0ebace44b4780f46dae13aeeb9e"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "config.json:   0%|          | 0.00/612 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "3a103142f6194d95b87218965bc589f2"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "model.safetensors:   0%|          | 0.00/90.9M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "4836cb77b43841c2b94ff15b593d2a97"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "tokenizer_config.json:   0%|          | 0.00/350 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "8cf34151c67141cfb0a906fb16d27b4e"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "vocab.txt: 0.00B [00:00, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "8cf9656ae1ac4b0ab7669482a7b08a47"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "tokenizer.json: 0.00B [00:00, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "b54434c994a14f7791356a014d9b053a"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "special_tokens_map.json:   0%|          | 0.00/112 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "da85837c44024e1bb3e1474ebe79fc6c"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "config.json:   0%|          | 0.00/190 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "aa1c905dde064f2d84a306047605438b"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting unique titles...\n",
            "Found 30800 unique titles\n",
            "Pre-computing SBERT embeddings...\n",
            "Processed 320/30800 titles\n",
            "Processed 640/30800 titles\n",
            "Processed 960/30800 titles\n",
            "Processed 1280/30800 titles\n",
            "Processed 1600/30800 titles\n",
            "Processed 1920/30800 titles\n",
            "Processed 2240/30800 titles\n",
            "Processed 2560/30800 titles\n",
            "Processed 2880/30800 titles\n",
            "Processed 3200/30800 titles\n",
            "Processed 3520/30800 titles\n",
            "Processed 3840/30800 titles\n",
            "Processed 4160/30800 titles\n",
            "Processed 4480/30800 titles\n",
            "Processed 4800/30800 titles\n",
            "Processed 5120/30800 titles\n",
            "Processed 5440/30800 titles\n",
            "Processed 5760/30800 titles\n",
            "Processed 6080/30800 titles\n",
            "Processed 6400/30800 titles\n",
            "Processed 6720/30800 titles\n",
            "Processed 7040/30800 titles\n",
            "Processed 7360/30800 titles\n",
            "Processed 7680/30800 titles\n",
            "Processed 8000/30800 titles\n",
            "Processed 8320/30800 titles\n",
            "Processed 8640/30800 titles\n",
            "Processed 8960/30800 titles\n",
            "Processed 9280/30800 titles\n",
            "Processed 9600/30800 titles\n",
            "Processed 9920/30800 titles\n",
            "Processed 10240/30800 titles\n",
            "Processed 10560/30800 titles\n",
            "Processed 10880/30800 titles\n",
            "Processed 11200/30800 titles\n",
            "Processed 11520/30800 titles\n",
            "Processed 11840/30800 titles\n",
            "Processed 12160/30800 titles\n",
            "Processed 12480/30800 titles\n",
            "Processed 12800/30800 titles\n",
            "Processed 13120/30800 titles\n",
            "Processed 13440/30800 titles\n",
            "Processed 13760/30800 titles\n",
            "Processed 14080/30800 titles\n",
            "Processed 14400/30800 titles\n",
            "Processed 14720/30800 titles\n",
            "Processed 15040/30800 titles\n",
            "Processed 15360/30800 titles\n",
            "Processed 15680/30800 titles\n",
            "Processed 16000/30800 titles\n",
            "Processed 16320/30800 titles\n",
            "Processed 16640/30800 titles\n",
            "Processed 16960/30800 titles\n",
            "Processed 17280/30800 titles\n",
            "Processed 17600/30800 titles\n",
            "Processed 17920/30800 titles\n",
            "Processed 18240/30800 titles\n",
            "Processed 18560/30800 titles\n",
            "Processed 18880/30800 titles\n",
            "Processed 19200/30800 titles\n",
            "Processed 19520/30800 titles\n",
            "Processed 19840/30800 titles\n",
            "Processed 20160/30800 titles\n",
            "Processed 20480/30800 titles\n",
            "Processed 20800/30800 titles\n",
            "Processed 21120/30800 titles\n",
            "Processed 21440/30800 titles\n",
            "Processed 21760/30800 titles\n",
            "Processed 22080/30800 titles\n",
            "Processed 22400/30800 titles\n",
            "Processed 22720/30800 titles\n",
            "Processed 23040/30800 titles\n",
            "Processed 23360/30800 titles\n",
            "Processed 23680/30800 titles\n",
            "Processed 24000/30800 titles\n",
            "Processed 24320/30800 titles\n",
            "Processed 24640/30800 titles\n",
            "Processed 24960/30800 titles\n",
            "Processed 25280/30800 titles\n",
            "Processed 25600/30800 titles\n",
            "Processed 25920/30800 titles\n",
            "Processed 26240/30800 titles\n",
            "Processed 26560/30800 titles\n",
            "Processed 26880/30800 titles\n",
            "Processed 27200/30800 titles\n",
            "Processed 27520/30800 titles\n",
            "Processed 27840/30800 titles\n",
            "Processed 28160/30800 titles\n",
            "Processed 28480/30800 titles\n",
            "Processed 28800/30800 titles\n",
            "Processed 29120/30800 titles\n",
            "Processed 29440/30800 titles\n",
            "Processed 29760/30800 titles\n",
            "Processed 30080/30800 titles\n",
            "Processed 30400/30800 titles\n",
            "Processed 30720/30800 titles\n",
            "Successfully computed embeddings for 30800 unique titles\n",
            "Training samples: 82306\n",
            "Testing samples: 20576\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **6: Training Function**\n",
        "\n",
        "- Sets up device (GPU if available, otherwise CPU)\n",
        "- Initializes ContrastiveLoss and Adam optimizer with specified parameters\n",
        "- Iterates through epochs and batches\n",
        "- Performs forward pass, loss calculation, and backpropagation\n",
        "- Prints training progress and loss statistics\n",
        "- Returns the trained model"
      ],
      "metadata": {
        "id": "J6V-yUvkIGbT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def train_model(model, train_loader, num_epochs=10, learning_rate=0.001, weight_decay=1e-5):\n",
        "    \"\"\"\n",
        "    Train the Siamese Network with pre-computed embeddings\n",
        "    \"\"\"\n",
        "    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "    print(f\"Training on device: {device}\")\n",
        "\n",
        "    model = model.to(device)\n",
        "\n",
        "    # Loss function and optimizer\n",
        "    criterion = ContrastiveLoss(margin=1.0)\n",
        "    optimizer = optim.Adam(model.parameters(), lr=learning_rate, weight_decay=weight_decay)\n",
        "\n",
        "    model.train()\n",
        "\n",
        "    for epoch in range(num_epochs):\n",
        "        total_loss = 0.0\n",
        "        num_batches = 0\n",
        "\n",
        "        print(f\"\\nEpoch {epoch+1}/{num_epochs}\")\n",
        "        print(\"-\" * 30)\n",
        "\n",
        "        for batch_idx, (embedding1_batch, embedding2_batch, labels_batch) in enumerate(train_loader):\n",
        "            # Move tensors to device\n",
        "            embedding1_batch = embedding1_batch.to(device)\n",
        "            embedding2_batch = embedding2_batch.to(device)\n",
        "            labels_batch = labels_batch.to(device)\n",
        "\n",
        "            # Zero gradients\n",
        "            optimizer.zero_grad()\n",
        "\n",
        "            # Forward pass\n",
        "            output1, output2 = model(embedding1_batch, embedding2_batch)\n",
        "\n",
        "            # Calculate loss\n",
        "            loss = criterion(output1, output2, labels_batch)\n",
        "\n",
        "            # Backward pass\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "\n",
        "            total_loss += loss.item()\n",
        "            num_batches += 1\n",
        "\n",
        "            # Print progress\n",
        "            if (batch_idx + 1) % 10 == 0:\n",
        "                print(f\"Batch {batch_idx+1}/{len(train_loader)}, Loss: {loss.item():.4f}\")\n",
        "\n",
        "        # Print epoch statistics\n",
        "        avg_loss = total_loss / num_batches\n",
        "        print(f\"Epoch {epoch+1} Average Loss: {avg_loss:.4f}\")\n",
        "\n",
        "    return model"
      ],
      "metadata": {
        "id": "bZt3V1TOIBaT"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "NUM_EPOCHS = 20\n",
        "LEARNING_RATE = 0.001\n",
        "WEIGHT_DECAY = 1e-5\n",
        "\n",
        "\n",
        "model = SiameseNetwork(input_dim=384, embedding_dim=128)\n",
        "trainable_params = sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
        "\n",
        "trained_model = train_model(\n",
        "        model,\n",
        "        train_loader,\n",
        "        num_epochs=NUM_EPOCHS,\n",
        "        learning_rate=LEARNING_RATE,\n",
        "        weight_decay=WEIGHT_DECAY\n",
        "    )"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mHk8BqlQM2f2",
        "outputId": "78408651-4bfd-46ab-fe6c-f38c75755088"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1;30;43mStreaming output truncated to the last 5000 lines.\u001b[0m\n",
            "Batch 2180/2573, Loss: 0.0109\n",
            "Batch 2190/2573, Loss: 0.0246\n",
            "Batch 2200/2573, Loss: 0.0322\n",
            "Batch 2210/2573, Loss: 0.0482\n",
            "Batch 2220/2573, Loss: 0.0568\n",
            "Batch 2230/2573, Loss: 0.0297\n",
            "Batch 2240/2573, Loss: 0.0372\n",
            "Batch 2250/2573, Loss: 0.0332\n",
            "Batch 2260/2573, Loss: 0.0279\n",
            "Batch 2270/2573, Loss: 0.0403\n",
            "Batch 2280/2573, Loss: 0.0756\n",
            "Batch 2290/2573, Loss: 0.0566\n",
            "Batch 2300/2573, Loss: 0.0402\n",
            "Batch 2310/2573, Loss: 0.0331\n",
            "Batch 2320/2573, Loss: 0.0204\n",
            "Batch 2330/2573, Loss: 0.0448\n",
            "Batch 2340/2573, Loss: 0.0448\n",
            "Batch 2350/2573, Loss: 0.0286\n",
            "Batch 2360/2573, Loss: 0.0600\n",
            "Batch 2370/2573, Loss: 0.0073\n",
            "Batch 2380/2573, Loss: 0.0424\n",
            "Batch 2390/2573, Loss: 0.0295\n",
            "Batch 2400/2573, Loss: 0.0432\n",
            "Batch 2410/2573, Loss: 0.0358\n",
            "Batch 2420/2573, Loss: 0.0257\n",
            "Batch 2430/2573, Loss: 0.0348\n",
            "Batch 2440/2573, Loss: 0.0276\n",
            "Batch 2450/2573, Loss: 0.0305\n",
            "Batch 2460/2573, Loss: 0.0367\n",
            "Batch 2470/2573, Loss: 0.0556\n",
            "Batch 2480/2573, Loss: 0.0293\n",
            "Batch 2490/2573, Loss: 0.0512\n",
            "Batch 2500/2573, Loss: 0.0444\n",
            "Batch 2510/2573, Loss: 0.0540\n",
            "Batch 2520/2573, Loss: 0.0244\n",
            "Batch 2530/2573, Loss: 0.0347\n",
            "Batch 2540/2573, Loss: 0.0444\n",
            "Batch 2550/2573, Loss: 0.0263\n",
            "Batch 2560/2573, Loss: 0.0234\n",
            "Batch 2570/2573, Loss: 0.0496\n",
            "Epoch 1 Average Loss: 0.0481\n",
            "\n",
            "Epoch 2/20\n",
            "------------------------------\n",
            "Batch 10/2573, Loss: 0.0213\n",
            "Batch 20/2573, Loss: 0.0551\n",
            "Batch 30/2573, Loss: 0.0190\n",
            "Batch 40/2573, Loss: 0.0210\n",
            "Batch 50/2573, Loss: 0.0348\n",
            "Batch 60/2573, Loss: 0.0158\n",
            "Batch 70/2573, Loss: 0.0361\n",
            "Batch 80/2573, Loss: 0.0383\n",
            "Batch 90/2573, Loss: 0.0202\n",
            "Batch 100/2573, Loss: 0.0228\n",
            "Batch 110/2573, Loss: 0.0429\n",
            "Batch 120/2573, Loss: 0.0242\n",
            "Batch 130/2573, Loss: 0.0291\n",
            "Batch 140/2573, Loss: 0.0369\n",
            "Batch 150/2573, Loss: 0.0332\n",
            "Batch 160/2573, Loss: 0.0613\n",
            "Batch 170/2573, Loss: 0.0421\n",
            "Batch 180/2573, Loss: 0.0382\n",
            "Batch 190/2573, Loss: 0.0231\n",
            "Batch 200/2573, Loss: 0.0147\n",
            "Batch 210/2573, Loss: 0.0183\n",
            "Batch 220/2573, Loss: 0.0418\n",
            "Batch 230/2573, Loss: 0.0544\n",
            "Batch 240/2573, Loss: 0.0536\n",
            "Batch 250/2573, Loss: 0.0324\n",
            "Batch 260/2573, Loss: 0.0324\n",
            "Batch 270/2573, Loss: 0.0440\n",
            "Batch 280/2573, Loss: 0.0265\n",
            "Batch 290/2573, Loss: 0.0434\n",
            "Batch 300/2573, Loss: 0.0231\n",
            "Batch 310/2573, Loss: 0.0466\n",
            "Batch 320/2573, Loss: 0.0182\n",
            "Batch 330/2573, Loss: 0.0400\n",
            "Batch 340/2573, Loss: 0.0303\n",
            "Batch 350/2573, Loss: 0.0465\n",
            "Batch 360/2573, Loss: 0.0425\n",
            "Batch 370/2573, Loss: 0.0578\n",
            "Batch 380/2573, Loss: 0.0358\n",
            "Batch 390/2573, Loss: 0.0264\n",
            "Batch 400/2573, Loss: 0.0455\n",
            "Batch 410/2573, Loss: 0.0374\n",
            "Batch 420/2573, Loss: 0.0361\n",
            "Batch 430/2573, Loss: 0.0531\n",
            "Batch 440/2573, Loss: 0.0601\n",
            "Batch 450/2573, Loss: 0.0302\n",
            "Batch 460/2573, Loss: 0.0167\n",
            "Batch 470/2573, Loss: 0.0190\n",
            "Batch 480/2573, Loss: 0.0295\n",
            "Batch 490/2573, Loss: 0.0362\n",
            "Batch 500/2573, Loss: 0.0395\n",
            "Batch 510/2573, Loss: 0.0268\n",
            "Batch 520/2573, Loss: 0.0659\n",
            "Batch 530/2573, Loss: 0.0494\n",
            "Batch 540/2573, Loss: 0.0159\n",
            "Batch 550/2573, Loss: 0.0389\n",
            "Batch 560/2573, Loss: 0.0301\n",
            "Batch 570/2573, Loss: 0.0192\n",
            "Batch 580/2573, Loss: 0.0440\n",
            "Batch 590/2573, Loss: 0.0180\n",
            "Batch 600/2573, Loss: 0.0537\n",
            "Batch 610/2573, Loss: 0.0309\n",
            "Batch 620/2573, Loss: 0.0275\n",
            "Batch 630/2573, Loss: 0.0168\n",
            "Batch 640/2573, Loss: 0.0550\n",
            "Batch 650/2573, Loss: 0.0224\n",
            "Batch 660/2573, Loss: 0.0270\n",
            "Batch 670/2573, Loss: 0.0290\n",
            "Batch 680/2573, Loss: 0.0176\n",
            "Batch 690/2573, Loss: 0.0221\n",
            "Batch 700/2573, Loss: 0.0317\n",
            "Batch 710/2573, Loss: 0.0245\n",
            "Batch 720/2573, Loss: 0.0337\n",
            "Batch 730/2573, Loss: 0.0158\n",
            "Batch 740/2573, Loss: 0.0157\n",
            "Batch 750/2573, Loss: 0.0205\n",
            "Batch 760/2573, Loss: 0.0213\n",
            "Batch 770/2573, Loss: 0.0327\n",
            "Batch 780/2573, Loss: 0.0534\n",
            "Batch 790/2573, Loss: 0.0332\n",
            "Batch 800/2573, Loss: 0.0354\n",
            "Batch 810/2573, Loss: 0.0318\n",
            "Batch 820/2573, Loss: 0.0327\n",
            "Batch 830/2573, Loss: 0.0252\n",
            "Batch 840/2573, Loss: 0.0255\n",
            "Batch 850/2573, Loss: 0.0200\n",
            "Batch 860/2573, Loss: 0.0161\n",
            "Batch 870/2573, Loss: 0.0145\n",
            "Batch 880/2573, Loss: 0.0306\n",
            "Batch 890/2573, Loss: 0.0171\n",
            "Batch 900/2573, Loss: 0.0368\n",
            "Batch 910/2573, Loss: 0.0309\n",
            "Batch 920/2573, Loss: 0.0198\n",
            "Batch 930/2573, Loss: 0.0228\n",
            "Batch 940/2573, Loss: 0.0082\n",
            "Batch 950/2573, Loss: 0.0136\n",
            "Batch 960/2573, Loss: 0.0515\n",
            "Batch 970/2573, Loss: 0.0238\n",
            "Batch 980/2573, Loss: 0.0372\n",
            "Batch 990/2573, Loss: 0.0223\n",
            "Batch 1000/2573, Loss: 0.0240\n",
            "Batch 1010/2573, Loss: 0.0284\n",
            "Batch 1020/2573, Loss: 0.0187\n",
            "Batch 1030/2573, Loss: 0.0287\n",
            "Batch 1040/2573, Loss: 0.0461\n",
            "Batch 1050/2573, Loss: 0.0208\n",
            "Batch 1060/2573, Loss: 0.0214\n",
            "Batch 1070/2573, Loss: 0.0272\n",
            "Batch 1080/2573, Loss: 0.0364\n",
            "Batch 1090/2573, Loss: 0.0398\n",
            "Batch 1100/2573, Loss: 0.0152\n",
            "Batch 1110/2573, Loss: 0.0355\n",
            "Batch 1120/2573, Loss: 0.0266\n",
            "Batch 1130/2573, Loss: 0.0273\n",
            "Batch 1140/2573, Loss: 0.0266\n",
            "Batch 1150/2573, Loss: 0.0137\n",
            "Batch 1160/2573, Loss: 0.0230\n",
            "Batch 1170/2573, Loss: 0.0217\n",
            "Batch 1180/2573, Loss: 0.0211\n",
            "Batch 1190/2573, Loss: 0.0887\n",
            "Batch 1200/2573, Loss: 0.0194\n",
            "Batch 1210/2573, Loss: 0.0356\n",
            "Batch 1220/2573, Loss: 0.0301\n",
            "Batch 1230/2573, Loss: 0.0413\n",
            "Batch 1240/2573, Loss: 0.0453\n",
            "Batch 1250/2573, Loss: 0.0456\n",
            "Batch 1260/2573, Loss: 0.0421\n",
            "Batch 1270/2573, Loss: 0.0340\n",
            "Batch 1280/2573, Loss: 0.0252\n",
            "Batch 1290/2573, Loss: 0.0497\n",
            "Batch 1300/2573, Loss: 0.0212\n",
            "Batch 1310/2573, Loss: 0.0159\n",
            "Batch 1320/2573, Loss: 0.0174\n",
            "Batch 1330/2573, Loss: 0.0252\n",
            "Batch 1340/2573, Loss: 0.0297\n",
            "Batch 1350/2573, Loss: 0.0235\n",
            "Batch 1360/2573, Loss: 0.0319\n",
            "Batch 1370/2573, Loss: 0.0390\n",
            "Batch 1380/2573, Loss: 0.0198\n",
            "Batch 1390/2573, Loss: 0.0272\n",
            "Batch 1400/2573, Loss: 0.0448\n",
            "Batch 1410/2573, Loss: 0.0316\n",
            "Batch 1420/2573, Loss: 0.0220\n",
            "Batch 1430/2573, Loss: 0.0292\n",
            "Batch 1440/2573, Loss: 0.0312\n",
            "Batch 1450/2573, Loss: 0.0175\n",
            "Batch 1460/2573, Loss: 0.0158\n",
            "Batch 1470/2573, Loss: 0.0370\n",
            "Batch 1480/2573, Loss: 0.0229\n",
            "Batch 1490/2573, Loss: 0.0190\n",
            "Batch 1500/2573, Loss: 0.0705\n",
            "Batch 1510/2573, Loss: 0.0490\n",
            "Batch 1520/2573, Loss: 0.0433\n",
            "Batch 1530/2573, Loss: 0.0335\n",
            "Batch 1540/2573, Loss: 0.0891\n",
            "Batch 1550/2573, Loss: 0.0366\n",
            "Batch 1560/2573, Loss: 0.0757\n",
            "Batch 1570/2573, Loss: 0.0257\n",
            "Batch 1580/2573, Loss: 0.0220\n",
            "Batch 1590/2573, Loss: 0.0094\n",
            "Batch 1600/2573, Loss: 0.0251\n",
            "Batch 1610/2573, Loss: 0.0283\n",
            "Batch 1620/2573, Loss: 0.0212\n",
            "Batch 1630/2573, Loss: 0.0419\n",
            "Batch 1640/2573, Loss: 0.0505\n",
            "Batch 1650/2573, Loss: 0.0242\n",
            "Batch 1660/2573, Loss: 0.0207\n",
            "Batch 1670/2573, Loss: 0.0619\n",
            "Batch 1680/2573, Loss: 0.0274\n",
            "Batch 1690/2573, Loss: 0.0368\n",
            "Batch 1700/2573, Loss: 0.0522\n",
            "Batch 1710/2573, Loss: 0.0362\n",
            "Batch 1720/2573, Loss: 0.0163\n",
            "Batch 1730/2573, Loss: 0.0509\n",
            "Batch 1740/2573, Loss: 0.0256\n",
            "Batch 1750/2573, Loss: 0.0154\n",
            "Batch 1760/2573, Loss: 0.0536\n",
            "Batch 1770/2573, Loss: 0.0207\n",
            "Batch 1780/2573, Loss: 0.0422\n",
            "Batch 1790/2573, Loss: 0.0489\n",
            "Batch 1800/2573, Loss: 0.0150\n",
            "Batch 1810/2573, Loss: 0.0235\n",
            "Batch 1820/2573, Loss: 0.0200\n",
            "Batch 1830/2573, Loss: 0.0176\n",
            "Batch 1840/2573, Loss: 0.0309\n",
            "Batch 1850/2573, Loss: 0.0243\n",
            "Batch 1860/2573, Loss: 0.0284\n",
            "Batch 1870/2573, Loss: 0.0183\n",
            "Batch 1880/2573, Loss: 0.0202\n",
            "Batch 1890/2573, Loss: 0.0202\n",
            "Batch 1900/2573, Loss: 0.0350\n",
            "Batch 1910/2573, Loss: 0.0169\n",
            "Batch 1920/2573, Loss: 0.0103\n",
            "Batch 1930/2573, Loss: 0.0559\n",
            "Batch 1940/2573, Loss: 0.0292\n",
            "Batch 1950/2573, Loss: 0.0406\n",
            "Batch 1960/2573, Loss: 0.0157\n",
            "Batch 1970/2573, Loss: 0.0182\n",
            "Batch 1980/2573, Loss: 0.0212\n",
            "Batch 1990/2573, Loss: 0.0303\n",
            "Batch 2000/2573, Loss: 0.0230\n",
            "Batch 2010/2573, Loss: 0.0419\n",
            "Batch 2020/2573, Loss: 0.0240\n",
            "Batch 2030/2573, Loss: 0.0401\n",
            "Batch 2040/2573, Loss: 0.0112\n",
            "Batch 2050/2573, Loss: 0.0117\n",
            "Batch 2060/2573, Loss: 0.0320\n",
            "Batch 2070/2573, Loss: 0.0114\n",
            "Batch 2080/2573, Loss: 0.0135\n",
            "Batch 2090/2573, Loss: 0.0295\n",
            "Batch 2100/2573, Loss: 0.0135\n",
            "Batch 2110/2573, Loss: 0.0221\n",
            "Batch 2120/2573, Loss: 0.0431\n",
            "Batch 2130/2573, Loss: 0.0141\n",
            "Batch 2140/2573, Loss: 0.0400\n",
            "Batch 2150/2573, Loss: 0.0265\n",
            "Batch 2160/2573, Loss: 0.0355\n",
            "Batch 2170/2573, Loss: 0.0303\n",
            "Batch 2180/2573, Loss: 0.0254\n",
            "Batch 2190/2573, Loss: 0.0562\n",
            "Batch 2200/2573, Loss: 0.0249\n",
            "Batch 2210/2573, Loss: 0.0322\n",
            "Batch 2220/2573, Loss: 0.0291\n",
            "Batch 2230/2573, Loss: 0.0204\n",
            "Batch 2240/2573, Loss: 0.0221\n",
            "Batch 2250/2573, Loss: 0.0210\n",
            "Batch 2260/2573, Loss: 0.0169\n",
            "Batch 2270/2573, Loss: 0.0325\n",
            "Batch 2280/2573, Loss: 0.0513\n",
            "Batch 2290/2573, Loss: 0.0443\n",
            "Batch 2300/2573, Loss: 0.0268\n",
            "Batch 2310/2573, Loss: 0.0274\n",
            "Batch 2320/2573, Loss: 0.0354\n",
            "Batch 2330/2573, Loss: 0.0369\n",
            "Batch 2340/2573, Loss: 0.0415\n",
            "Batch 2350/2573, Loss: 0.0256\n",
            "Batch 2360/2573, Loss: 0.0420\n",
            "Batch 2370/2573, Loss: 0.0129\n",
            "Batch 2380/2573, Loss: 0.0228\n",
            "Batch 2390/2573, Loss: 0.0272\n",
            "Batch 2400/2573, Loss: 0.0375\n",
            "Batch 2410/2573, Loss: 0.0188\n",
            "Batch 2420/2573, Loss: 0.0313\n",
            "Batch 2430/2573, Loss: 0.0222\n",
            "Batch 2440/2573, Loss: 0.0251\n",
            "Batch 2450/2573, Loss: 0.0190\n",
            "Batch 2460/2573, Loss: 0.0333\n",
            "Batch 2470/2573, Loss: 0.0185\n",
            "Batch 2480/2573, Loss: 0.0402\n",
            "Batch 2490/2573, Loss: 0.0275\n",
            "Batch 2500/2573, Loss: 0.0411\n",
            "Batch 2510/2573, Loss: 0.0216\n",
            "Batch 2520/2573, Loss: 0.0402\n",
            "Batch 2530/2573, Loss: 0.0223\n",
            "Batch 2540/2573, Loss: 0.0345\n",
            "Batch 2550/2573, Loss: 0.0366\n",
            "Batch 2560/2573, Loss: 0.0162\n",
            "Batch 2570/2573, Loss: 0.0233\n",
            "Epoch 2 Average Loss: 0.0314\n",
            "\n",
            "Epoch 3/20\n",
            "------------------------------\n",
            "Batch 10/2573, Loss: 0.0457\n",
            "Batch 20/2573, Loss: 0.0371\n",
            "Batch 30/2573, Loss: 0.0188\n",
            "Batch 40/2573, Loss: 0.0283\n",
            "Batch 50/2573, Loss: 0.0342\n",
            "Batch 60/2573, Loss: 0.0080\n",
            "Batch 70/2573, Loss: 0.0403\n",
            "Batch 80/2573, Loss: 0.0285\n",
            "Batch 90/2573, Loss: 0.0268\n",
            "Batch 100/2573, Loss: 0.0306\n",
            "Batch 110/2573, Loss: 0.0157\n",
            "Batch 120/2573, Loss: 0.0269\n",
            "Batch 130/2573, Loss: 0.0180\n",
            "Batch 140/2573, Loss: 0.0172\n",
            "Batch 150/2573, Loss: 0.0159\n",
            "Batch 160/2573, Loss: 0.0152\n",
            "Batch 170/2573, Loss: 0.0352\n",
            "Batch 180/2573, Loss: 0.0244\n",
            "Batch 190/2573, Loss: 0.0184\n",
            "Batch 200/2573, Loss: 0.0249\n",
            "Batch 210/2573, Loss: 0.0174\n",
            "Batch 220/2573, Loss: 0.0311\n",
            "Batch 230/2573, Loss: 0.0314\n",
            "Batch 240/2573, Loss: 0.0306\n",
            "Batch 250/2573, Loss: 0.0255\n",
            "Batch 260/2573, Loss: 0.0272\n",
            "Batch 270/2573, Loss: 0.0303\n",
            "Batch 280/2573, Loss: 0.0131\n",
            "Batch 290/2573, Loss: 0.0216\n",
            "Batch 300/2573, Loss: 0.0172\n",
            "Batch 310/2573, Loss: 0.0361\n",
            "Batch 320/2573, Loss: 0.0127\n",
            "Batch 330/2573, Loss: 0.0259\n",
            "Batch 340/2573, Loss: 0.0202\n",
            "Batch 350/2573, Loss: 0.0141\n",
            "Batch 360/2573, Loss: 0.0114\n",
            "Batch 370/2573, Loss: 0.0234\n",
            "Batch 380/2573, Loss: 0.0217\n",
            "Batch 390/2573, Loss: 0.0267\n",
            "Batch 400/2573, Loss: 0.0132\n",
            "Batch 410/2573, Loss: 0.0261\n",
            "Batch 420/2573, Loss: 0.0205\n",
            "Batch 430/2573, Loss: 0.0168\n",
            "Batch 440/2573, Loss: 0.0358\n",
            "Batch 450/2573, Loss: 0.0210\n",
            "Batch 460/2573, Loss: 0.0314\n",
            "Batch 470/2573, Loss: 0.0190\n",
            "Batch 480/2573, Loss: 0.0308\n",
            "Batch 490/2573, Loss: 0.0271\n",
            "Batch 500/2573, Loss: 0.0409\n",
            "Batch 510/2573, Loss: 0.0373\n",
            "Batch 520/2573, Loss: 0.0278\n",
            "Batch 530/2573, Loss: 0.0337\n",
            "Batch 540/2573, Loss: 0.0330\n",
            "Batch 550/2573, Loss: 0.0318\n",
            "Batch 560/2573, Loss: 0.0152\n",
            "Batch 570/2573, Loss: 0.0052\n",
            "Batch 580/2573, Loss: 0.0268\n",
            "Batch 590/2573, Loss: 0.0294\n",
            "Batch 600/2573, Loss: 0.0205\n",
            "Batch 610/2573, Loss: 0.0295\n",
            "Batch 620/2573, Loss: 0.0373\n",
            "Batch 630/2573, Loss: 0.0175\n",
            "Batch 640/2573, Loss: 0.0199\n",
            "Batch 650/2573, Loss: 0.0231\n",
            "Batch 660/2573, Loss: 0.0248\n",
            "Batch 670/2573, Loss: 0.0228\n",
            "Batch 680/2573, Loss: 0.0156\n",
            "Batch 690/2573, Loss: 0.0158\n",
            "Batch 700/2573, Loss: 0.0418\n",
            "Batch 710/2573, Loss: 0.0142\n",
            "Batch 720/2573, Loss: 0.0455\n",
            "Batch 730/2573, Loss: 0.0418\n",
            "Batch 740/2573, Loss: 0.0073\n",
            "Batch 750/2573, Loss: 0.0217\n",
            "Batch 760/2573, Loss: 0.0219\n",
            "Batch 770/2573, Loss: 0.0212\n",
            "Batch 780/2573, Loss: 0.0500\n",
            "Batch 790/2573, Loss: 0.0212\n",
            "Batch 800/2573, Loss: 0.0235\n",
            "Batch 810/2573, Loss: 0.0292\n",
            "Batch 820/2573, Loss: 0.0401\n",
            "Batch 830/2573, Loss: 0.0123\n",
            "Batch 840/2573, Loss: 0.0216\n",
            "Batch 850/2573, Loss: 0.0176\n",
            "Batch 860/2573, Loss: 0.0348\n",
            "Batch 870/2573, Loss: 0.0355\n",
            "Batch 880/2573, Loss: 0.0230\n",
            "Batch 890/2573, Loss: 0.0258\n",
            "Batch 900/2573, Loss: 0.0481\n",
            "Batch 910/2573, Loss: 0.0172\n",
            "Batch 920/2573, Loss: 0.0095\n",
            "Batch 930/2573, Loss: 0.0155\n",
            "Batch 940/2573, Loss: 0.0262\n",
            "Batch 950/2573, Loss: 0.0169\n",
            "Batch 960/2573, Loss: 0.0352\n",
            "Batch 970/2573, Loss: 0.0238\n",
            "Batch 980/2573, Loss: 0.0131\n",
            "Batch 990/2573, Loss: 0.0136\n",
            "Batch 1000/2573, Loss: 0.0097\n",
            "Batch 1010/2573, Loss: 0.0217\n",
            "Batch 1020/2573, Loss: 0.0075\n",
            "Batch 1030/2573, Loss: 0.0380\n",
            "Batch 1040/2573, Loss: 0.0213\n",
            "Batch 1050/2573, Loss: 0.0311\n",
            "Batch 1060/2573, Loss: 0.0374\n",
            "Batch 1070/2573, Loss: 0.0306\n",
            "Batch 1080/2573, Loss: 0.0178\n",
            "Batch 1090/2573, Loss: 0.0186\n",
            "Batch 1100/2573, Loss: 0.0486\n",
            "Batch 1110/2573, Loss: 0.0264\n",
            "Batch 1120/2573, Loss: 0.0327\n",
            "Batch 1130/2573, Loss: 0.0221\n",
            "Batch 1140/2573, Loss: 0.0144\n",
            "Batch 1150/2573, Loss: 0.0639\n",
            "Batch 1160/2573, Loss: 0.0452\n",
            "Batch 1170/2573, Loss: 0.0166\n",
            "Batch 1180/2573, Loss: 0.0232\n",
            "Batch 1190/2573, Loss: 0.0319\n",
            "Batch 1200/2573, Loss: 0.0466\n",
            "Batch 1210/2573, Loss: 0.0146\n",
            "Batch 1220/2573, Loss: 0.0146\n",
            "Batch 1230/2573, Loss: 0.0140\n",
            "Batch 1240/2573, Loss: 0.0363\n",
            "Batch 1250/2573, Loss: 0.0560\n",
            "Batch 1260/2573, Loss: 0.0330\n",
            "Batch 1270/2573, Loss: 0.0188\n",
            "Batch 1280/2573, Loss: 0.0232\n",
            "Batch 1290/2573, Loss: 0.0355\n",
            "Batch 1300/2573, Loss: 0.0111\n",
            "Batch 1310/2573, Loss: 0.0335\n",
            "Batch 1320/2573, Loss: 0.0441\n",
            "Batch 1330/2573, Loss: 0.0611\n",
            "Batch 1340/2573, Loss: 0.0385\n",
            "Batch 1350/2573, Loss: 0.0386\n",
            "Batch 1360/2573, Loss: 0.0142\n",
            "Batch 1370/2573, Loss: 0.0096\n",
            "Batch 1380/2573, Loss: 0.0451\n",
            "Batch 1390/2573, Loss: 0.0266\n",
            "Batch 1400/2573, Loss: 0.0140\n",
            "Batch 1410/2573, Loss: 0.0089\n",
            "Batch 1420/2573, Loss: 0.0364\n",
            "Batch 1430/2573, Loss: 0.0200\n",
            "Batch 1440/2573, Loss: 0.0239\n",
            "Batch 1450/2573, Loss: 0.0207\n",
            "Batch 1460/2573, Loss: 0.0320\n",
            "Batch 1470/2573, Loss: 0.0193\n",
            "Batch 1480/2573, Loss: 0.0178\n",
            "Batch 1490/2573, Loss: 0.0130\n",
            "Batch 1500/2573, Loss: 0.0375\n",
            "Batch 1510/2573, Loss: 0.0092\n",
            "Batch 1520/2573, Loss: 0.0342\n",
            "Batch 1530/2573, Loss: 0.0133\n",
            "Batch 1540/2573, Loss: 0.0331\n",
            "Batch 1550/2573, Loss: 0.0181\n",
            "Batch 1560/2573, Loss: 0.0326\n",
            "Batch 1570/2573, Loss: 0.0393\n",
            "Batch 1580/2573, Loss: 0.0254\n",
            "Batch 1590/2573, Loss: 0.0532\n",
            "Batch 1600/2573, Loss: 0.0215\n",
            "Batch 1610/2573, Loss: 0.0204\n",
            "Batch 1620/2573, Loss: 0.0271\n",
            "Batch 1630/2573, Loss: 0.0371\n",
            "Batch 1640/2573, Loss: 0.0187\n",
            "Batch 1650/2573, Loss: 0.0193\n",
            "Batch 1660/2573, Loss: 0.0239\n",
            "Batch 1670/2573, Loss: 0.0145\n",
            "Batch 1680/2573, Loss: 0.0181\n",
            "Batch 1690/2573, Loss: 0.0504\n",
            "Batch 1700/2573, Loss: 0.0184\n",
            "Batch 1710/2573, Loss: 0.0261\n",
            "Batch 1720/2573, Loss: 0.0177\n",
            "Batch 1730/2573, Loss: 0.0227\n",
            "Batch 1740/2573, Loss: 0.0163\n",
            "Batch 1750/2573, Loss: 0.0199\n",
            "Batch 1760/2573, Loss: 0.0173\n",
            "Batch 1770/2573, Loss: 0.0118\n",
            "Batch 1780/2573, Loss: 0.0223\n",
            "Batch 1790/2573, Loss: 0.0176\n",
            "Batch 1800/2573, Loss: 0.0256\n",
            "Batch 1810/2573, Loss: 0.0222\n",
            "Batch 1820/2573, Loss: 0.0171\n",
            "Batch 1830/2573, Loss: 0.0429\n",
            "Batch 1840/2573, Loss: 0.0184\n",
            "Batch 1850/2573, Loss: 0.0328\n",
            "Batch 1860/2573, Loss: 0.0066\n",
            "Batch 1870/2573, Loss: 0.0196\n",
            "Batch 1880/2573, Loss: 0.0422\n",
            "Batch 1890/2573, Loss: 0.0497\n",
            "Batch 1900/2573, Loss: 0.0221\n",
            "Batch 1910/2573, Loss: 0.0262\n",
            "Batch 1920/2573, Loss: 0.0189\n",
            "Batch 1930/2573, Loss: 0.0137\n",
            "Batch 1940/2573, Loss: 0.0251\n",
            "Batch 1950/2573, Loss: 0.0499\n",
            "Batch 1960/2573, Loss: 0.0236\n",
            "Batch 1970/2573, Loss: 0.0502\n",
            "Batch 1980/2573, Loss: 0.0308\n",
            "Batch 1990/2573, Loss: 0.0119\n",
            "Batch 2000/2573, Loss: 0.0142\n",
            "Batch 2010/2573, Loss: 0.0406\n",
            "Batch 2020/2573, Loss: 0.0325\n",
            "Batch 2030/2573, Loss: 0.0209\n",
            "Batch 2040/2573, Loss: 0.0111\n",
            "Batch 2050/2573, Loss: 0.0289\n",
            "Batch 2060/2573, Loss: 0.0215\n",
            "Batch 2070/2573, Loss: 0.0166\n",
            "Batch 2080/2573, Loss: 0.0259\n",
            "Batch 2090/2573, Loss: 0.0415\n",
            "Batch 2100/2573, Loss: 0.0204\n",
            "Batch 2110/2573, Loss: 0.0330\n",
            "Batch 2120/2573, Loss: 0.0357\n",
            "Batch 2130/2573, Loss: 0.0374\n",
            "Batch 2140/2573, Loss: 0.0271\n",
            "Batch 2150/2573, Loss: 0.0262\n",
            "Batch 2160/2573, Loss: 0.0221\n",
            "Batch 2170/2573, Loss: 0.0208\n",
            "Batch 2180/2573, Loss: 0.0255\n",
            "Batch 2190/2573, Loss: 0.0463\n",
            "Batch 2200/2573, Loss: 0.0173\n",
            "Batch 2210/2573, Loss: 0.0227\n",
            "Batch 2220/2573, Loss: 0.0382\n",
            "Batch 2230/2573, Loss: 0.0276\n",
            "Batch 2240/2573, Loss: 0.0180\n",
            "Batch 2250/2573, Loss: 0.0230\n",
            "Batch 2260/2573, Loss: 0.0283\n",
            "Batch 2270/2573, Loss: 0.0170\n",
            "Batch 2280/2573, Loss: 0.0220\n",
            "Batch 2290/2573, Loss: 0.0285\n",
            "Batch 2300/2573, Loss: 0.0222\n",
            "Batch 2310/2573, Loss: 0.0175\n",
            "Batch 2320/2573, Loss: 0.0347\n",
            "Batch 2330/2573, Loss: 0.0214\n",
            "Batch 2340/2573, Loss: 0.0303\n",
            "Batch 2350/2573, Loss: 0.0128\n",
            "Batch 2360/2573, Loss: 0.0153\n",
            "Batch 2370/2573, Loss: 0.0300\n",
            "Batch 2380/2573, Loss: 0.0094\n",
            "Batch 2390/2573, Loss: 0.0400\n",
            "Batch 2400/2573, Loss: 0.0312\n",
            "Batch 2410/2573, Loss: 0.0179\n",
            "Batch 2420/2573, Loss: 0.0229\n",
            "Batch 2430/2573, Loss: 0.0104\n",
            "Batch 2440/2573, Loss: 0.0207\n",
            "Batch 2450/2573, Loss: 0.0187\n",
            "Batch 2460/2573, Loss: 0.0376\n",
            "Batch 2470/2573, Loss: 0.0257\n",
            "Batch 2480/2573, Loss: 0.0808\n",
            "Batch 2490/2573, Loss: 0.0181\n",
            "Batch 2500/2573, Loss: 0.0427\n",
            "Batch 2510/2573, Loss: 0.0108\n",
            "Batch 2520/2573, Loss: 0.0273\n",
            "Batch 2530/2573, Loss: 0.0202\n",
            "Batch 2540/2573, Loss: 0.0354\n",
            "Batch 2550/2573, Loss: 0.0616\n",
            "Batch 2560/2573, Loss: 0.0239\n",
            "Batch 2570/2573, Loss: 0.0221\n",
            "Epoch 3 Average Loss: 0.0266\n",
            "\n",
            "Epoch 4/20\n",
            "------------------------------\n",
            "Batch 10/2573, Loss: 0.0246\n",
            "Batch 20/2573, Loss: 0.0341\n",
            "Batch 30/2573, Loss: 0.0327\n",
            "Batch 40/2573, Loss: 0.0168\n",
            "Batch 50/2573, Loss: 0.0221\n",
            "Batch 60/2573, Loss: 0.0357\n",
            "Batch 70/2573, Loss: 0.0311\n",
            "Batch 80/2573, Loss: 0.0388\n",
            "Batch 90/2573, Loss: 0.0155\n",
            "Batch 100/2573, Loss: 0.0302\n",
            "Batch 110/2573, Loss: 0.0250\n",
            "Batch 120/2573, Loss: 0.0282\n",
            "Batch 130/2573, Loss: 0.0243\n",
            "Batch 140/2573, Loss: 0.0133\n",
            "Batch 150/2573, Loss: 0.0244\n",
            "Batch 160/2573, Loss: 0.0206\n",
            "Batch 170/2573, Loss: 0.0165\n",
            "Batch 180/2573, Loss: 0.0290\n",
            "Batch 190/2573, Loss: 0.0315\n",
            "Batch 200/2573, Loss: 0.0253\n",
            "Batch 210/2573, Loss: 0.0193\n",
            "Batch 220/2573, Loss: 0.0223\n",
            "Batch 230/2573, Loss: 0.0096\n",
            "Batch 240/2573, Loss: 0.0126\n",
            "Batch 250/2573, Loss: 0.0101\n",
            "Batch 260/2573, Loss: 0.0177\n",
            "Batch 270/2573, Loss: 0.0289\n",
            "Batch 280/2573, Loss: 0.0415\n",
            "Batch 290/2573, Loss: 0.0234\n",
            "Batch 300/2573, Loss: 0.0265\n",
            "Batch 310/2573, Loss: 0.0377\n",
            "Batch 320/2573, Loss: 0.0434\n",
            "Batch 330/2573, Loss: 0.0403\n",
            "Batch 340/2573, Loss: 0.0183\n",
            "Batch 350/2573, Loss: 0.0170\n",
            "Batch 360/2573, Loss: 0.0373\n",
            "Batch 370/2573, Loss: 0.0091\n",
            "Batch 380/2573, Loss: 0.0351\n",
            "Batch 390/2573, Loss: 0.0296\n",
            "Batch 400/2573, Loss: 0.0201\n",
            "Batch 410/2573, Loss: 0.0318\n",
            "Batch 420/2573, Loss: 0.0346\n",
            "Batch 430/2573, Loss: 0.0196\n",
            "Batch 440/2573, Loss: 0.0246\n",
            "Batch 450/2573, Loss: 0.0305\n",
            "Batch 460/2573, Loss: 0.0057\n",
            "Batch 470/2573, Loss: 0.0196\n",
            "Batch 480/2573, Loss: 0.0127\n",
            "Batch 490/2573, Loss: 0.0152\n",
            "Batch 500/2573, Loss: 0.0209\n",
            "Batch 510/2573, Loss: 0.0357\n",
            "Batch 520/2573, Loss: 0.0190\n",
            "Batch 530/2573, Loss: 0.0322\n",
            "Batch 540/2573, Loss: 0.0281\n",
            "Batch 550/2573, Loss: 0.0257\n",
            "Batch 560/2573, Loss: 0.0108\n",
            "Batch 570/2573, Loss: 0.0088\n",
            "Batch 580/2573, Loss: 0.0188\n",
            "Batch 590/2573, Loss: 0.0242\n",
            "Batch 600/2573, Loss: 0.0188\n",
            "Batch 610/2573, Loss: 0.0242\n",
            "Batch 620/2573, Loss: 0.0319\n",
            "Batch 630/2573, Loss: 0.0422\n",
            "Batch 640/2573, Loss: 0.0149\n",
            "Batch 650/2573, Loss: 0.0348\n",
            "Batch 660/2573, Loss: 0.0495\n",
            "Batch 670/2573, Loss: 0.0275\n",
            "Batch 680/2573, Loss: 0.0160\n",
            "Batch 690/2573, Loss: 0.0242\n",
            "Batch 700/2573, Loss: 0.0156\n",
            "Batch 710/2573, Loss: 0.0312\n",
            "Batch 720/2573, Loss: 0.0176\n",
            "Batch 730/2573, Loss: 0.0286\n",
            "Batch 740/2573, Loss: 0.0168\n",
            "Batch 750/2573, Loss: 0.0435\n",
            "Batch 760/2573, Loss: 0.0221\n",
            "Batch 770/2573, Loss: 0.0100\n",
            "Batch 780/2573, Loss: 0.0261\n",
            "Batch 790/2573, Loss: 0.0424\n",
            "Batch 800/2573, Loss: 0.0094\n",
            "Batch 810/2573, Loss: 0.0107\n",
            "Batch 820/2573, Loss: 0.0174\n",
            "Batch 830/2573, Loss: 0.0286\n",
            "Batch 840/2573, Loss: 0.0327\n",
            "Batch 850/2573, Loss: 0.0143\n",
            "Batch 860/2573, Loss: 0.0403\n",
            "Batch 870/2573, Loss: 0.0282\n",
            "Batch 880/2573, Loss: 0.0214\n",
            "Batch 890/2573, Loss: 0.0205\n",
            "Batch 900/2573, Loss: 0.0179\n",
            "Batch 910/2573, Loss: 0.0201\n",
            "Batch 920/2573, Loss: 0.0223\n",
            "Batch 930/2573, Loss: 0.0184\n",
            "Batch 940/2573, Loss: 0.0224\n",
            "Batch 950/2573, Loss: 0.0265\n",
            "Batch 960/2573, Loss: 0.0302\n",
            "Batch 970/2573, Loss: 0.0168\n",
            "Batch 980/2573, Loss: 0.0353\n",
            "Batch 990/2573, Loss: 0.0103\n",
            "Batch 1000/2573, Loss: 0.0207\n",
            "Batch 1010/2573, Loss: 0.0210\n",
            "Batch 1020/2573, Loss: 0.0142\n",
            "Batch 1030/2573, Loss: 0.0309\n",
            "Batch 1040/2573, Loss: 0.0210\n",
            "Batch 1050/2573, Loss: 0.0328\n",
            "Batch 1060/2573, Loss: 0.0372\n",
            "Batch 1070/2573, Loss: 0.0282\n",
            "Batch 1080/2573, Loss: 0.0208\n",
            "Batch 1090/2573, Loss: 0.0194\n",
            "Batch 1100/2573, Loss: 0.0174\n",
            "Batch 1110/2573, Loss: 0.0148\n",
            "Batch 1120/2573, Loss: 0.0372\n",
            "Batch 1130/2573, Loss: 0.0211\n",
            "Batch 1140/2573, Loss: 0.0158\n",
            "Batch 1150/2573, Loss: 0.0183\n",
            "Batch 1160/2573, Loss: 0.0325\n",
            "Batch 1170/2573, Loss: 0.0338\n",
            "Batch 1180/2573, Loss: 0.0307\n",
            "Batch 1190/2573, Loss: 0.0171\n",
            "Batch 1200/2573, Loss: 0.0185\n",
            "Batch 1210/2573, Loss: 0.0256\n",
            "Batch 1220/2573, Loss: 0.0201\n",
            "Batch 1230/2573, Loss: 0.0099\n",
            "Batch 1240/2573, Loss: 0.0184\n",
            "Batch 1250/2573, Loss: 0.0331\n",
            "Batch 1260/2573, Loss: 0.0234\n",
            "Batch 1270/2573, Loss: 0.0225\n",
            "Batch 1280/2573, Loss: 0.0153\n",
            "Batch 1290/2573, Loss: 0.0299\n",
            "Batch 1300/2573, Loss: 0.0400\n",
            "Batch 1310/2573, Loss: 0.0115\n",
            "Batch 1320/2573, Loss: 0.0385\n",
            "Batch 1330/2573, Loss: 0.0212\n",
            "Batch 1340/2573, Loss: 0.0211\n",
            "Batch 1350/2573, Loss: 0.0189\n",
            "Batch 1360/2573, Loss: 0.0119\n",
            "Batch 1370/2573, Loss: 0.0134\n",
            "Batch 1380/2573, Loss: 0.0267\n",
            "Batch 1390/2573, Loss: 0.0103\n",
            "Batch 1400/2573, Loss: 0.0104\n",
            "Batch 1410/2573, Loss: 0.0053\n",
            "Batch 1420/2573, Loss: 0.0218\n",
            "Batch 1430/2573, Loss: 0.0267\n",
            "Batch 1440/2573, Loss: 0.0175\n",
            "Batch 1450/2573, Loss: 0.0154\n",
            "Batch 1460/2573, Loss: 0.0392\n",
            "Batch 1470/2573, Loss: 0.0556\n",
            "Batch 1480/2573, Loss: 0.0259\n",
            "Batch 1490/2573, Loss: 0.0435\n",
            "Batch 1500/2573, Loss: 0.0095\n",
            "Batch 1510/2573, Loss: 0.0294\n",
            "Batch 1520/2573, Loss: 0.0174\n",
            "Batch 1530/2573, Loss: 0.0224\n",
            "Batch 1540/2573, Loss: 0.0277\n",
            "Batch 1550/2573, Loss: 0.0112\n",
            "Batch 1560/2573, Loss: 0.0152\n",
            "Batch 1570/2573, Loss: 0.0382\n",
            "Batch 1580/2573, Loss: 0.0430\n",
            "Batch 1590/2573, Loss: 0.0154\n",
            "Batch 1600/2573, Loss: 0.0207\n",
            "Batch 1610/2573, Loss: 0.0192\n",
            "Batch 1620/2573, Loss: 0.0290\n",
            "Batch 1630/2573, Loss: 0.0236\n",
            "Batch 1640/2573, Loss: 0.0154\n",
            "Batch 1650/2573, Loss: 0.0142\n",
            "Batch 1660/2573, Loss: 0.0238\n",
            "Batch 1670/2573, Loss: 0.0331\n",
            "Batch 1680/2573, Loss: 0.0263\n",
            "Batch 1690/2573, Loss: 0.0153\n",
            "Batch 1700/2573, Loss: 0.0211\n",
            "Batch 1710/2573, Loss: 0.0287\n",
            "Batch 1720/2573, Loss: 0.0152\n",
            "Batch 1730/2573, Loss: 0.0161\n",
            "Batch 1740/2573, Loss: 0.0245\n",
            "Batch 1750/2573, Loss: 0.0484\n",
            "Batch 1760/2573, Loss: 0.0460\n",
            "Batch 1770/2573, Loss: 0.0146\n",
            "Batch 1780/2573, Loss: 0.0181\n",
            "Batch 1790/2573, Loss: 0.0309\n",
            "Batch 1800/2573, Loss: 0.0358\n",
            "Batch 1810/2573, Loss: 0.0439\n",
            "Batch 1820/2573, Loss: 0.0172\n",
            "Batch 1830/2573, Loss: 0.0283\n",
            "Batch 1840/2573, Loss: 0.0294\n",
            "Batch 1850/2573, Loss: 0.0326\n",
            "Batch 1860/2573, Loss: 0.0208\n",
            "Batch 1870/2573, Loss: 0.0160\n",
            "Batch 1880/2573, Loss: 0.0103\n",
            "Batch 1890/2573, Loss: 0.0361\n",
            "Batch 1900/2573, Loss: 0.0536\n",
            "Batch 1910/2573, Loss: 0.0545\n",
            "Batch 1920/2573, Loss: 0.0271\n",
            "Batch 1930/2573, Loss: 0.0114\n",
            "Batch 1940/2573, Loss: 0.0146\n",
            "Batch 1950/2573, Loss: 0.0125\n",
            "Batch 1960/2573, Loss: 0.0151\n",
            "Batch 1970/2573, Loss: 0.0098\n",
            "Batch 1980/2573, Loss: 0.0204\n",
            "Batch 1990/2573, Loss: 0.0185\n",
            "Batch 2000/2573, Loss: 0.0354\n",
            "Batch 2010/2573, Loss: 0.0218\n",
            "Batch 2020/2573, Loss: 0.0201\n",
            "Batch 2030/2573, Loss: 0.0389\n",
            "Batch 2040/2573, Loss: 0.0233\n",
            "Batch 2050/2573, Loss: 0.0234\n",
            "Batch 2060/2573, Loss: 0.0250\n",
            "Batch 2070/2573, Loss: 0.0182\n",
            "Batch 2080/2573, Loss: 0.0259\n",
            "Batch 2090/2573, Loss: 0.0295\n",
            "Batch 2100/2573, Loss: 0.0152\n",
            "Batch 2110/2573, Loss: 0.0330\n",
            "Batch 2120/2573, Loss: 0.0201\n",
            "Batch 2130/2573, Loss: 0.0274\n",
            "Batch 2140/2573, Loss: 0.0188\n",
            "Batch 2150/2573, Loss: 0.0426\n",
            "Batch 2160/2573, Loss: 0.0201\n",
            "Batch 2170/2573, Loss: 0.0212\n",
            "Batch 2180/2573, Loss: 0.0255\n",
            "Batch 2190/2573, Loss: 0.0263\n",
            "Batch 2200/2573, Loss: 0.0188\n",
            "Batch 2210/2573, Loss: 0.0167\n",
            "Batch 2220/2573, Loss: 0.0205\n",
            "Batch 2230/2573, Loss: 0.0187\n",
            "Batch 2240/2573, Loss: 0.0179\n",
            "Batch 2250/2573, Loss: 0.0362\n",
            "Batch 2260/2573, Loss: 0.0369\n",
            "Batch 2270/2573, Loss: 0.0103\n",
            "Batch 2280/2573, Loss: 0.0362\n",
            "Batch 2290/2573, Loss: 0.0110\n",
            "Batch 2300/2573, Loss: 0.0117\n",
            "Batch 2310/2573, Loss: 0.0126\n",
            "Batch 2320/2573, Loss: 0.0228\n",
            "Batch 2330/2573, Loss: 0.0552\n",
            "Batch 2340/2573, Loss: 0.0125\n",
            "Batch 2350/2573, Loss: 0.0165\n",
            "Batch 2360/2573, Loss: 0.0269\n",
            "Batch 2370/2573, Loss: 0.0184\n",
            "Batch 2380/2573, Loss: 0.0219\n",
            "Batch 2390/2573, Loss: 0.0209\n",
            "Batch 2400/2573, Loss: 0.0197\n",
            "Batch 2410/2573, Loss: 0.0246\n",
            "Batch 2420/2573, Loss: 0.0113\n",
            "Batch 2430/2573, Loss: 0.0313\n",
            "Batch 2440/2573, Loss: 0.0246\n",
            "Batch 2450/2573, Loss: 0.0332\n",
            "Batch 2460/2573, Loss: 0.0277\n",
            "Batch 2470/2573, Loss: 0.0334\n",
            "Batch 2480/2573, Loss: 0.0226\n",
            "Batch 2490/2573, Loss: 0.0225\n",
            "Batch 2500/2573, Loss: 0.0232\n",
            "Batch 2510/2573, Loss: 0.0171\n",
            "Batch 2520/2573, Loss: 0.0183\n",
            "Batch 2530/2573, Loss: 0.0183\n",
            "Batch 2540/2573, Loss: 0.0241\n",
            "Batch 2550/2573, Loss: 0.0201\n",
            "Batch 2560/2573, Loss: 0.0153\n",
            "Batch 2570/2573, Loss: 0.0389\n",
            "Epoch 4 Average Loss: 0.0240\n",
            "\n",
            "Epoch 5/20\n",
            "------------------------------\n",
            "Batch 10/2573, Loss: 0.0103\n",
            "Batch 20/2573, Loss: 0.0540\n",
            "Batch 30/2573, Loss: 0.0293\n",
            "Batch 40/2573, Loss: 0.0129\n",
            "Batch 50/2573, Loss: 0.0118\n",
            "Batch 60/2573, Loss: 0.0400\n",
            "Batch 70/2573, Loss: 0.0125\n",
            "Batch 80/2573, Loss: 0.0302\n",
            "Batch 90/2573, Loss: 0.0321\n",
            "Batch 100/2573, Loss: 0.0123\n",
            "Batch 110/2573, Loss: 0.0242\n",
            "Batch 120/2573, Loss: 0.0205\n",
            "Batch 130/2573, Loss: 0.0219\n",
            "Batch 140/2573, Loss: 0.0142\n",
            "Batch 150/2573, Loss: 0.0099\n",
            "Batch 160/2573, Loss: 0.0296\n",
            "Batch 170/2573, Loss: 0.0299\n",
            "Batch 180/2573, Loss: 0.0195\n",
            "Batch 190/2573, Loss: 0.0185\n",
            "Batch 200/2573, Loss: 0.0202\n",
            "Batch 210/2573, Loss: 0.0101\n",
            "Batch 220/2573, Loss: 0.0174\n",
            "Batch 230/2573, Loss: 0.0472\n",
            "Batch 240/2573, Loss: 0.0095\n",
            "Batch 250/2573, Loss: 0.0182\n",
            "Batch 260/2573, Loss: 0.0251\n",
            "Batch 270/2573, Loss: 0.0395\n",
            "Batch 280/2573, Loss: 0.0161\n",
            "Batch 290/2573, Loss: 0.0347\n",
            "Batch 300/2573, Loss: 0.0251\n",
            "Batch 310/2573, Loss: 0.0235\n",
            "Batch 320/2573, Loss: 0.0229\n",
            "Batch 330/2573, Loss: 0.0185\n",
            "Batch 340/2573, Loss: 0.0144\n",
            "Batch 350/2573, Loss: 0.0109\n",
            "Batch 360/2573, Loss: 0.0191\n",
            "Batch 370/2573, Loss: 0.0234\n",
            "Batch 380/2573, Loss: 0.0199\n",
            "Batch 390/2573, Loss: 0.0176\n",
            "Batch 400/2573, Loss: 0.0102\n",
            "Batch 410/2573, Loss: 0.0130\n",
            "Batch 420/2573, Loss: 0.0471\n",
            "Batch 430/2573, Loss: 0.0186\n",
            "Batch 440/2573, Loss: 0.0143\n",
            "Batch 450/2573, Loss: 0.0346\n",
            "Batch 460/2573, Loss: 0.0084\n",
            "Batch 470/2573, Loss: 0.0305\n",
            "Batch 480/2573, Loss: 0.0107\n",
            "Batch 490/2573, Loss: 0.0180\n",
            "Batch 500/2573, Loss: 0.0239\n",
            "Batch 510/2573, Loss: 0.0211\n",
            "Batch 520/2573, Loss: 0.0157\n",
            "Batch 530/2573, Loss: 0.0090\n",
            "Batch 540/2573, Loss: 0.0154\n",
            "Batch 550/2573, Loss: 0.0099\n",
            "Batch 560/2573, Loss: 0.0168\n",
            "Batch 570/2573, Loss: 0.0290\n",
            "Batch 580/2573, Loss: 0.0240\n",
            "Batch 590/2573, Loss: 0.0162\n",
            "Batch 600/2573, Loss: 0.0184\n",
            "Batch 610/2573, Loss: 0.0190\n",
            "Batch 620/2573, Loss: 0.0250\n",
            "Batch 630/2573, Loss: 0.0116\n",
            "Batch 640/2573, Loss: 0.0146\n",
            "Batch 650/2573, Loss: 0.0165\n",
            "Batch 660/2573, Loss: 0.0491\n",
            "Batch 670/2573, Loss: 0.0153\n",
            "Batch 680/2573, Loss: 0.0310\n",
            "Batch 690/2573, Loss: 0.0139\n",
            "Batch 700/2573, Loss: 0.0207\n",
            "Batch 710/2573, Loss: 0.0333\n",
            "Batch 720/2573, Loss: 0.0161\n",
            "Batch 730/2573, Loss: 0.0227\n",
            "Batch 740/2573, Loss: 0.0102\n",
            "Batch 750/2573, Loss: 0.0143\n",
            "Batch 760/2573, Loss: 0.0212\n",
            "Batch 770/2573, Loss: 0.0199\n",
            "Batch 780/2573, Loss: 0.0325\n",
            "Batch 790/2573, Loss: 0.0188\n",
            "Batch 800/2573, Loss: 0.0248\n",
            "Batch 810/2573, Loss: 0.0333\n",
            "Batch 820/2573, Loss: 0.0364\n",
            "Batch 830/2573, Loss: 0.0182\n",
            "Batch 840/2573, Loss: 0.0155\n",
            "Batch 850/2573, Loss: 0.0195\n",
            "Batch 860/2573, Loss: 0.0105\n",
            "Batch 870/2573, Loss: 0.0288\n",
            "Batch 880/2573, Loss: 0.0111\n",
            "Batch 890/2573, Loss: 0.0316\n",
            "Batch 900/2573, Loss: 0.0293\n",
            "Batch 910/2573, Loss: 0.0253\n",
            "Batch 920/2573, Loss: 0.0250\n",
            "Batch 930/2573, Loss: 0.0266\n",
            "Batch 940/2573, Loss: 0.0087\n",
            "Batch 950/2573, Loss: 0.0187\n",
            "Batch 960/2573, Loss: 0.0132\n",
            "Batch 970/2573, Loss: 0.0278\n",
            "Batch 980/2573, Loss: 0.0310\n",
            "Batch 990/2573, Loss: 0.0159\n",
            "Batch 1000/2573, Loss: 0.0186\n",
            "Batch 1010/2573, Loss: 0.0175\n",
            "Batch 1020/2573, Loss: 0.0447\n",
            "Batch 1030/2573, Loss: 0.0189\n",
            "Batch 1040/2573, Loss: 0.0102\n",
            "Batch 1050/2573, Loss: 0.0164\n",
            "Batch 1060/2573, Loss: 0.0485\n",
            "Batch 1070/2573, Loss: 0.0292\n",
            "Batch 1080/2573, Loss: 0.0136\n",
            "Batch 1090/2573, Loss: 0.0203\n",
            "Batch 1100/2573, Loss: 0.0133\n",
            "Batch 1110/2573, Loss: 0.0369\n",
            "Batch 1120/2573, Loss: 0.0184\n",
            "Batch 1130/2573, Loss: 0.0326\n",
            "Batch 1140/2573, Loss: 0.0175\n",
            "Batch 1150/2573, Loss: 0.0172\n",
            "Batch 1160/2573, Loss: 0.0296\n",
            "Batch 1170/2573, Loss: 0.0223\n",
            "Batch 1180/2573, Loss: 0.0255\n",
            "Batch 1190/2573, Loss: 0.0383\n",
            "Batch 1200/2573, Loss: 0.0425\n",
            "Batch 1210/2573, Loss: 0.0303\n",
            "Batch 1220/2573, Loss: 0.0275\n",
            "Batch 1230/2573, Loss: 0.0139\n",
            "Batch 1240/2573, Loss: 0.0446\n",
            "Batch 1250/2573, Loss: 0.0148\n",
            "Batch 1260/2573, Loss: 0.0332\n",
            "Batch 1270/2573, Loss: 0.0167\n",
            "Batch 1280/2573, Loss: 0.0133\n",
            "Batch 1290/2573, Loss: 0.0391\n",
            "Batch 1300/2573, Loss: 0.0387\n",
            "Batch 1310/2573, Loss: 0.0232\n",
            "Batch 1320/2573, Loss: 0.0168\n",
            "Batch 1330/2573, Loss: 0.0481\n",
            "Batch 1340/2573, Loss: 0.0311\n",
            "Batch 1350/2573, Loss: 0.0196\n",
            "Batch 1360/2573, Loss: 0.0230\n",
            "Batch 1370/2573, Loss: 0.0216\n",
            "Batch 1380/2573, Loss: 0.0318\n",
            "Batch 1390/2573, Loss: 0.0152\n",
            "Batch 1400/2573, Loss: 0.0233\n",
            "Batch 1410/2573, Loss: 0.0225\n",
            "Batch 1420/2573, Loss: 0.0084\n",
            "Batch 1430/2573, Loss: 0.0242\n",
            "Batch 1440/2573, Loss: 0.0339\n",
            "Batch 1450/2573, Loss: 0.0165\n",
            "Batch 1460/2573, Loss: 0.0142\n",
            "Batch 1470/2573, Loss: 0.0118\n",
            "Batch 1480/2573, Loss: 0.0135\n",
            "Batch 1490/2573, Loss: 0.0138\n",
            "Batch 1500/2573, Loss: 0.0349\n",
            "Batch 1510/2573, Loss: 0.0174\n",
            "Batch 1520/2573, Loss: 0.0260\n",
            "Batch 1530/2573, Loss: 0.0248\n",
            "Batch 1540/2573, Loss: 0.0091\n",
            "Batch 1550/2573, Loss: 0.0261\n",
            "Batch 1560/2573, Loss: 0.0224\n",
            "Batch 1570/2573, Loss: 0.0341\n",
            "Batch 1580/2573, Loss: 0.0184\n",
            "Batch 1590/2573, Loss: 0.0302\n",
            "Batch 1600/2573, Loss: 0.0563\n",
            "Batch 1610/2573, Loss: 0.0131\n",
            "Batch 1620/2573, Loss: 0.0149\n",
            "Batch 1630/2573, Loss: 0.0159\n",
            "Batch 1640/2573, Loss: 0.0217\n",
            "Batch 1650/2573, Loss: 0.0219\n",
            "Batch 1660/2573, Loss: 0.0096\n",
            "Batch 1670/2573, Loss: 0.0198\n",
            "Batch 1680/2573, Loss: 0.0189\n",
            "Batch 1690/2573, Loss: 0.0215\n",
            "Batch 1700/2573, Loss: 0.0098\n",
            "Batch 1710/2573, Loss: 0.0195\n",
            "Batch 1720/2573, Loss: 0.0173\n",
            "Batch 1730/2573, Loss: 0.0113\n",
            "Batch 1740/2573, Loss: 0.0159\n",
            "Batch 1750/2573, Loss: 0.0184\n",
            "Batch 1760/2573, Loss: 0.0327\n",
            "Batch 1770/2573, Loss: 0.0211\n",
            "Batch 1780/2573, Loss: 0.0222\n",
            "Batch 1790/2573, Loss: 0.0195\n",
            "Batch 1800/2573, Loss: 0.0123\n",
            "Batch 1810/2573, Loss: 0.0147\n",
            "Batch 1820/2573, Loss: 0.0191\n",
            "Batch 1830/2573, Loss: 0.0503\n",
            "Batch 1840/2573, Loss: 0.0192\n",
            "Batch 1850/2573, Loss: 0.0206\n",
            "Batch 1860/2573, Loss: 0.0106\n",
            "Batch 1870/2573, Loss: 0.0301\n",
            "Batch 1880/2573, Loss: 0.0045\n",
            "Batch 1890/2573, Loss: 0.0161\n",
            "Batch 1900/2573, Loss: 0.0450\n",
            "Batch 1910/2573, Loss: 0.0180\n",
            "Batch 1920/2573, Loss: 0.0094\n",
            "Batch 1930/2573, Loss: 0.0266\n",
            "Batch 1940/2573, Loss: 0.0233\n",
            "Batch 1950/2573, Loss: 0.0109\n",
            "Batch 1960/2573, Loss: 0.0247\n",
            "Batch 1970/2573, Loss: 0.0255\n",
            "Batch 1980/2573, Loss: 0.0199\n",
            "Batch 1990/2573, Loss: 0.0269\n",
            "Batch 2000/2573, Loss: 0.0235\n",
            "Batch 2010/2573, Loss: 0.0293\n",
            "Batch 2020/2573, Loss: 0.0158\n",
            "Batch 2030/2573, Loss: 0.0113\n",
            "Batch 2040/2573, Loss: 0.0226\n",
            "Batch 2050/2573, Loss: 0.0067\n",
            "Batch 2060/2573, Loss: 0.0093\n",
            "Batch 2070/2573, Loss: 0.0072\n",
            "Batch 2080/2573, Loss: 0.0192\n",
            "Batch 2090/2573, Loss: 0.0406\n",
            "Batch 2100/2573, Loss: 0.0087\n",
            "Batch 2110/2573, Loss: 0.0234\n",
            "Batch 2120/2573, Loss: 0.0152\n",
            "Batch 2130/2573, Loss: 0.0150\n",
            "Batch 2140/2573, Loss: 0.0535\n",
            "Batch 2150/2573, Loss: 0.0239\n",
            "Batch 2160/2573, Loss: 0.0251\n",
            "Batch 2170/2573, Loss: 0.0217\n",
            "Batch 2180/2573, Loss: 0.0300\n",
            "Batch 2190/2573, Loss: 0.0228\n",
            "Batch 2200/2573, Loss: 0.0136\n",
            "Batch 2210/2573, Loss: 0.0272\n",
            "Batch 2220/2573, Loss: 0.0115\n",
            "Batch 2230/2573, Loss: 0.0126\n",
            "Batch 2240/2573, Loss: 0.0209\n",
            "Batch 2250/2573, Loss: 0.0443\n",
            "Batch 2260/2573, Loss: 0.0195\n",
            "Batch 2270/2573, Loss: 0.0301\n",
            "Batch 2280/2573, Loss: 0.0375\n",
            "Batch 2290/2573, Loss: 0.0094\n",
            "Batch 2300/2573, Loss: 0.0342\n",
            "Batch 2310/2573, Loss: 0.0092\n",
            "Batch 2320/2573, Loss: 0.0267\n",
            "Batch 2330/2573, Loss: 0.0380\n",
            "Batch 2340/2573, Loss: 0.0490\n",
            "Batch 2350/2573, Loss: 0.0148\n",
            "Batch 2360/2573, Loss: 0.0150\n",
            "Batch 2370/2573, Loss: 0.0166\n",
            "Batch 2380/2573, Loss: 0.0238\n",
            "Batch 2390/2573, Loss: 0.0069\n",
            "Batch 2400/2573, Loss: 0.0176\n",
            "Batch 2410/2573, Loss: 0.0295\n",
            "Batch 2420/2573, Loss: 0.0434\n",
            "Batch 2430/2573, Loss: 0.0355\n",
            "Batch 2440/2573, Loss: 0.0078\n",
            "Batch 2450/2573, Loss: 0.0518\n",
            "Batch 2460/2573, Loss: 0.0670\n",
            "Batch 2470/2573, Loss: 0.0188\n",
            "Batch 2480/2573, Loss: 0.0185\n",
            "Batch 2490/2573, Loss: 0.0158\n",
            "Batch 2500/2573, Loss: 0.0216\n",
            "Batch 2510/2573, Loss: 0.0127\n",
            "Batch 2520/2573, Loss: 0.0329\n",
            "Batch 2530/2573, Loss: 0.0288\n",
            "Batch 2540/2573, Loss: 0.0126\n",
            "Batch 2550/2573, Loss: 0.0191\n",
            "Batch 2560/2573, Loss: 0.0200\n",
            "Batch 2570/2573, Loss: 0.0175\n",
            "Epoch 5 Average Loss: 0.0222\n",
            "\n",
            "Epoch 6/20\n",
            "------------------------------\n",
            "Batch 10/2573, Loss: 0.0136\n",
            "Batch 20/2573, Loss: 0.0186\n",
            "Batch 30/2573, Loss: 0.0425\n",
            "Batch 40/2573, Loss: 0.0112\n",
            "Batch 50/2573, Loss: 0.0131\n",
            "Batch 60/2573, Loss: 0.0120\n",
            "Batch 70/2573, Loss: 0.0285\n",
            "Batch 80/2573, Loss: 0.0185\n",
            "Batch 90/2573, Loss: 0.0152\n",
            "Batch 100/2573, Loss: 0.0270\n",
            "Batch 110/2573, Loss: 0.0210\n",
            "Batch 120/2573, Loss: 0.0113\n",
            "Batch 130/2573, Loss: 0.0226\n",
            "Batch 140/2573, Loss: 0.0330\n",
            "Batch 150/2573, Loss: 0.0208\n",
            "Batch 160/2573, Loss: 0.0101\n",
            "Batch 170/2573, Loss: 0.0255\n",
            "Batch 180/2573, Loss: 0.0292\n",
            "Batch 190/2573, Loss: 0.0179\n",
            "Batch 200/2573, Loss: 0.0238\n",
            "Batch 210/2573, Loss: 0.0301\n",
            "Batch 220/2573, Loss: 0.0072\n",
            "Batch 230/2573, Loss: 0.0066\n",
            "Batch 240/2573, Loss: 0.0195\n",
            "Batch 250/2573, Loss: 0.0113\n",
            "Batch 260/2573, Loss: 0.0195\n",
            "Batch 270/2573, Loss: 0.0097\n",
            "Batch 280/2573, Loss: 0.0109\n",
            "Batch 290/2573, Loss: 0.0287\n",
            "Batch 300/2573, Loss: 0.0335\n",
            "Batch 310/2573, Loss: 0.0335\n",
            "Batch 320/2573, Loss: 0.0228\n",
            "Batch 330/2573, Loss: 0.0220\n",
            "Batch 340/2573, Loss: 0.0273\n",
            "Batch 350/2573, Loss: 0.0311\n",
            "Batch 360/2573, Loss: 0.0235\n",
            "Batch 370/2573, Loss: 0.0112\n",
            "Batch 380/2573, Loss: 0.0295\n",
            "Batch 390/2573, Loss: 0.0281\n",
            "Batch 400/2573, Loss: 0.0228\n",
            "Batch 410/2573, Loss: 0.0146\n",
            "Batch 420/2573, Loss: 0.0183\n",
            "Batch 430/2573, Loss: 0.0190\n",
            "Batch 440/2573, Loss: 0.0222\n",
            "Batch 450/2573, Loss: 0.0235\n",
            "Batch 460/2573, Loss: 0.0212\n",
            "Batch 470/2573, Loss: 0.0303\n",
            "Batch 480/2573, Loss: 0.0180\n",
            "Batch 490/2573, Loss: 0.0151\n",
            "Batch 500/2573, Loss: 0.0167\n",
            "Batch 510/2573, Loss: 0.0127\n",
            "Batch 520/2573, Loss: 0.0198\n",
            "Batch 530/2573, Loss: 0.0383\n",
            "Batch 540/2573, Loss: 0.0114\n",
            "Batch 550/2573, Loss: 0.0112\n",
            "Batch 560/2573, Loss: 0.0220\n",
            "Batch 570/2573, Loss: 0.0209\n",
            "Batch 580/2573, Loss: 0.0348\n",
            "Batch 590/2573, Loss: 0.0122\n",
            "Batch 600/2573, Loss: 0.0199\n",
            "Batch 610/2573, Loss: 0.0189\n",
            "Batch 620/2573, Loss: 0.0302\n",
            "Batch 630/2573, Loss: 0.0253\n",
            "Batch 640/2573, Loss: 0.0120\n",
            "Batch 650/2573, Loss: 0.0187\n",
            "Batch 660/2573, Loss: 0.0131\n",
            "Batch 670/2573, Loss: 0.0313\n",
            "Batch 680/2573, Loss: 0.0262\n",
            "Batch 690/2573, Loss: 0.0181\n",
            "Batch 700/2573, Loss: 0.0146\n",
            "Batch 710/2573, Loss: 0.0182\n",
            "Batch 720/2573, Loss: 0.0318\n",
            "Batch 730/2573, Loss: 0.0147\n",
            "Batch 740/2573, Loss: 0.0355\n",
            "Batch 750/2573, Loss: 0.0175\n",
            "Batch 760/2573, Loss: 0.0162\n",
            "Batch 770/2573, Loss: 0.0304\n",
            "Batch 780/2573, Loss: 0.0224\n",
            "Batch 790/2573, Loss: 0.0284\n",
            "Batch 800/2573, Loss: 0.0187\n",
            "Batch 810/2573, Loss: 0.0139\n",
            "Batch 820/2573, Loss: 0.0090\n",
            "Batch 830/2573, Loss: 0.0184\n",
            "Batch 840/2573, Loss: 0.0203\n",
            "Batch 850/2573, Loss: 0.0135\n",
            "Batch 860/2573, Loss: 0.0392\n",
            "Batch 870/2573, Loss: 0.0171\n",
            "Batch 880/2573, Loss: 0.0376\n",
            "Batch 890/2573, Loss: 0.0173\n",
            "Batch 900/2573, Loss: 0.0364\n",
            "Batch 910/2573, Loss: 0.0109\n",
            "Batch 920/2573, Loss: 0.0212\n",
            "Batch 930/2573, Loss: 0.0358\n",
            "Batch 940/2573, Loss: 0.0325\n",
            "Batch 950/2573, Loss: 0.0124\n",
            "Batch 960/2573, Loss: 0.0062\n",
            "Batch 970/2573, Loss: 0.0351\n",
            "Batch 980/2573, Loss: 0.0198\n",
            "Batch 990/2573, Loss: 0.0230\n",
            "Batch 1000/2573, Loss: 0.0196\n",
            "Batch 1010/2573, Loss: 0.0095\n",
            "Batch 1020/2573, Loss: 0.0138\n",
            "Batch 1030/2573, Loss: 0.0303\n",
            "Batch 1040/2573, Loss: 0.0242\n",
            "Batch 1050/2573, Loss: 0.0160\n",
            "Batch 1060/2573, Loss: 0.0616\n",
            "Batch 1070/2573, Loss: 0.0260\n",
            "Batch 1080/2573, Loss: 0.0143\n",
            "Batch 1090/2573, Loss: 0.0228\n",
            "Batch 1100/2573, Loss: 0.0229\n",
            "Batch 1110/2573, Loss: 0.0155\n",
            "Batch 1120/2573, Loss: 0.0302\n",
            "Batch 1130/2573, Loss: 0.0219\n",
            "Batch 1140/2573, Loss: 0.0112\n",
            "Batch 1150/2573, Loss: 0.0074\n",
            "Batch 1160/2573, Loss: 0.0198\n",
            "Batch 1170/2573, Loss: 0.0405\n",
            "Batch 1180/2573, Loss: 0.0532\n",
            "Batch 1190/2573, Loss: 0.0344\n",
            "Batch 1200/2573, Loss: 0.0267\n",
            "Batch 1210/2573, Loss: 0.0295\n",
            "Batch 1220/2573, Loss: 0.0222\n",
            "Batch 1230/2573, Loss: 0.0254\n",
            "Batch 1240/2573, Loss: 0.0130\n",
            "Batch 1250/2573, Loss: 0.0231\n",
            "Batch 1260/2573, Loss: 0.0167\n",
            "Batch 1270/2573, Loss: 0.0323\n",
            "Batch 1280/2573, Loss: 0.0165\n",
            "Batch 1290/2573, Loss: 0.0243\n",
            "Batch 1300/2573, Loss: 0.0487\n",
            "Batch 1310/2573, Loss: 0.0245\n",
            "Batch 1320/2573, Loss: 0.0391\n",
            "Batch 1330/2573, Loss: 0.0132\n",
            "Batch 1340/2573, Loss: 0.0186\n",
            "Batch 1350/2573, Loss: 0.0107\n",
            "Batch 1360/2573, Loss: 0.0116\n",
            "Batch 1370/2573, Loss: 0.0219\n",
            "Batch 1380/2573, Loss: 0.0227\n",
            "Batch 1390/2573, Loss: 0.0110\n",
            "Batch 1400/2573, Loss: 0.0122\n",
            "Batch 1410/2573, Loss: 0.0149\n",
            "Batch 1420/2573, Loss: 0.0252\n",
            "Batch 1430/2573, Loss: 0.0344\n",
            "Batch 1440/2573, Loss: 0.0132\n",
            "Batch 1450/2573, Loss: 0.0355\n",
            "Batch 1460/2573, Loss: 0.0114\n",
            "Batch 1470/2573, Loss: 0.0279\n",
            "Batch 1480/2573, Loss: 0.0076\n",
            "Batch 1490/2573, Loss: 0.0189\n",
            "Batch 1500/2573, Loss: 0.0158\n",
            "Batch 1510/2573, Loss: 0.0136\n",
            "Batch 1520/2573, Loss: 0.0179\n",
            "Batch 1530/2573, Loss: 0.0136\n",
            "Batch 1540/2573, Loss: 0.0165\n",
            "Batch 1550/2573, Loss: 0.0435\n",
            "Batch 1560/2573, Loss: 0.0301\n",
            "Batch 1570/2573, Loss: 0.0227\n",
            "Batch 1580/2573, Loss: 0.0222\n",
            "Batch 1590/2573, Loss: 0.0127\n",
            "Batch 1600/2573, Loss: 0.0284\n",
            "Batch 1610/2573, Loss: 0.0087\n",
            "Batch 1620/2573, Loss: 0.0281\n",
            "Batch 1630/2573, Loss: 0.0140\n",
            "Batch 1640/2573, Loss: 0.0257\n",
            "Batch 1650/2573, Loss: 0.0140\n",
            "Batch 1660/2573, Loss: 0.0402\n",
            "Batch 1670/2573, Loss: 0.0225\n",
            "Batch 1680/2573, Loss: 0.0092\n",
            "Batch 1690/2573, Loss: 0.0158\n",
            "Batch 1700/2573, Loss: 0.0195\n",
            "Batch 1710/2573, Loss: 0.0068\n",
            "Batch 1720/2573, Loss: 0.0112\n",
            "Batch 1730/2573, Loss: 0.0140\n",
            "Batch 1740/2573, Loss: 0.0612\n",
            "Batch 1750/2573, Loss: 0.0321\n",
            "Batch 1760/2573, Loss: 0.0208\n",
            "Batch 1770/2573, Loss: 0.0447\n",
            "Batch 1780/2573, Loss: 0.0483\n",
            "Batch 1790/2573, Loss: 0.0341\n",
            "Batch 1800/2573, Loss: 0.0093\n",
            "Batch 1810/2573, Loss: 0.0290\n",
            "Batch 1820/2573, Loss: 0.0140\n",
            "Batch 1830/2573, Loss: 0.0201\n",
            "Batch 1840/2573, Loss: 0.0299\n",
            "Batch 1850/2573, Loss: 0.0144\n",
            "Batch 1860/2573, Loss: 0.0312\n",
            "Batch 1870/2573, Loss: 0.0427\n",
            "Batch 1880/2573, Loss: 0.0512\n",
            "Batch 1890/2573, Loss: 0.0366\n",
            "Batch 1900/2573, Loss: 0.0146\n",
            "Batch 1910/2573, Loss: 0.0194\n",
            "Batch 1920/2573, Loss: 0.0135\n",
            "Batch 1930/2573, Loss: 0.0171\n",
            "Batch 1940/2573, Loss: 0.0169\n",
            "Batch 1950/2573, Loss: 0.0186\n",
            "Batch 1960/2573, Loss: 0.0120\n",
            "Batch 1970/2573, Loss: 0.0131\n",
            "Batch 1980/2573, Loss: 0.0122\n",
            "Batch 1990/2573, Loss: 0.0265\n",
            "Batch 2000/2573, Loss: 0.0105\n",
            "Batch 2010/2573, Loss: 0.0198\n",
            "Batch 2020/2573, Loss: 0.0213\n",
            "Batch 2030/2573, Loss: 0.0209\n",
            "Batch 2040/2573, Loss: 0.0248\n",
            "Batch 2050/2573, Loss: 0.0176\n",
            "Batch 2060/2573, Loss: 0.0229\n",
            "Batch 2070/2573, Loss: 0.0334\n",
            "Batch 2080/2573, Loss: 0.0283\n",
            "Batch 2090/2573, Loss: 0.0315\n",
            "Batch 2100/2573, Loss: 0.0305\n",
            "Batch 2110/2573, Loss: 0.0245\n",
            "Batch 2120/2573, Loss: 0.0258\n",
            "Batch 2130/2573, Loss: 0.0204\n",
            "Batch 2140/2573, Loss: 0.0302\n",
            "Batch 2150/2573, Loss: 0.0186\n",
            "Batch 2160/2573, Loss: 0.0070\n",
            "Batch 2170/2573, Loss: 0.0039\n",
            "Batch 2180/2573, Loss: 0.0147\n",
            "Batch 2190/2573, Loss: 0.0158\n",
            "Batch 2200/2573, Loss: 0.0130\n",
            "Batch 2210/2573, Loss: 0.0223\n",
            "Batch 2220/2573, Loss: 0.0291\n",
            "Batch 2230/2573, Loss: 0.0384\n",
            "Batch 2240/2573, Loss: 0.0135\n",
            "Batch 2250/2573, Loss: 0.0124\n",
            "Batch 2260/2573, Loss: 0.0243\n",
            "Batch 2270/2573, Loss: 0.0097\n",
            "Batch 2280/2573, Loss: 0.0336\n",
            "Batch 2290/2573, Loss: 0.0220\n",
            "Batch 2300/2573, Loss: 0.0201\n",
            "Batch 2310/2573, Loss: 0.0195\n",
            "Batch 2320/2573, Loss: 0.0256\n",
            "Batch 2330/2573, Loss: 0.0048\n",
            "Batch 2340/2573, Loss: 0.0225\n",
            "Batch 2350/2573, Loss: 0.0275\n",
            "Batch 2360/2573, Loss: 0.0194\n",
            "Batch 2370/2573, Loss: 0.0455\n",
            "Batch 2380/2573, Loss: 0.0278\n",
            "Batch 2390/2573, Loss: 0.0337\n",
            "Batch 2400/2573, Loss: 0.0214\n",
            "Batch 2410/2573, Loss: 0.0126\n",
            "Batch 2420/2573, Loss: 0.0088\n",
            "Batch 2430/2573, Loss: 0.0295\n",
            "Batch 2440/2573, Loss: 0.0196\n",
            "Batch 2450/2573, Loss: 0.0137\n",
            "Batch 2460/2573, Loss: 0.0373\n",
            "Batch 2470/2573, Loss: 0.0206\n",
            "Batch 2480/2573, Loss: 0.0111\n",
            "Batch 2490/2573, Loss: 0.0232\n",
            "Batch 2500/2573, Loss: 0.0280\n",
            "Batch 2510/2573, Loss: 0.0110\n",
            "Batch 2520/2573, Loss: 0.0086\n",
            "Batch 2530/2573, Loss: 0.0133\n",
            "Batch 2540/2573, Loss: 0.0319\n",
            "Batch 2550/2573, Loss: 0.0098\n",
            "Batch 2560/2573, Loss: 0.0177\n",
            "Batch 2570/2573, Loss: 0.0090\n",
            "Epoch 6 Average Loss: 0.0209\n",
            "\n",
            "Epoch 7/20\n",
            "------------------------------\n",
            "Batch 10/2573, Loss: 0.0164\n",
            "Batch 20/2573, Loss: 0.0334\n",
            "Batch 30/2573, Loss: 0.0349\n",
            "Batch 40/2573, Loss: 0.0189\n",
            "Batch 50/2573, Loss: 0.0247\n",
            "Batch 60/2573, Loss: 0.0075\n",
            "Batch 70/2573, Loss: 0.0367\n",
            "Batch 80/2573, Loss: 0.0377\n",
            "Batch 90/2573, Loss: 0.0073\n",
            "Batch 100/2573, Loss: 0.0204\n",
            "Batch 110/2573, Loss: 0.0194\n",
            "Batch 120/2573, Loss: 0.0136\n",
            "Batch 130/2573, Loss: 0.0071\n",
            "Batch 140/2573, Loss: 0.0231\n",
            "Batch 150/2573, Loss: 0.0429\n",
            "Batch 160/2573, Loss: 0.0135\n",
            "Batch 170/2573, Loss: 0.0311\n",
            "Batch 180/2573, Loss: 0.0116\n",
            "Batch 190/2573, Loss: 0.0182\n",
            "Batch 200/2573, Loss: 0.0070\n",
            "Batch 210/2573, Loss: 0.0110\n",
            "Batch 220/2573, Loss: 0.0189\n",
            "Batch 230/2573, Loss: 0.0123\n",
            "Batch 240/2573, Loss: 0.0113\n",
            "Batch 250/2573, Loss: 0.0326\n",
            "Batch 260/2573, Loss: 0.0148\n",
            "Batch 270/2573, Loss: 0.0274\n",
            "Batch 280/2573, Loss: 0.0282\n",
            "Batch 290/2573, Loss: 0.0193\n",
            "Batch 300/2573, Loss: 0.0180\n",
            "Batch 310/2573, Loss: 0.0217\n",
            "Batch 320/2573, Loss: 0.0378\n",
            "Batch 330/2573, Loss: 0.0111\n",
            "Batch 340/2573, Loss: 0.0157\n",
            "Batch 350/2573, Loss: 0.0180\n",
            "Batch 360/2573, Loss: 0.0180\n",
            "Batch 370/2573, Loss: 0.0073\n",
            "Batch 380/2573, Loss: 0.0293\n",
            "Batch 390/2573, Loss: 0.0074\n",
            "Batch 400/2573, Loss: 0.0077\n",
            "Batch 410/2573, Loss: 0.0118\n",
            "Batch 420/2573, Loss: 0.0234\n",
            "Batch 430/2573, Loss: 0.0093\n",
            "Batch 440/2573, Loss: 0.0107\n",
            "Batch 450/2573, Loss: 0.0098\n",
            "Batch 460/2573, Loss: 0.0136\n",
            "Batch 470/2573, Loss: 0.0198\n",
            "Batch 480/2573, Loss: 0.0236\n",
            "Batch 490/2573, Loss: 0.0356\n",
            "Batch 500/2573, Loss: 0.0077\n",
            "Batch 510/2573, Loss: 0.0153\n",
            "Batch 520/2573, Loss: 0.0182\n",
            "Batch 530/2573, Loss: 0.0167\n",
            "Batch 540/2573, Loss: 0.0548\n",
            "Batch 550/2573, Loss: 0.0166\n",
            "Batch 560/2573, Loss: 0.0161\n",
            "Batch 570/2573, Loss: 0.0123\n",
            "Batch 580/2573, Loss: 0.0207\n",
            "Batch 590/2573, Loss: 0.0118\n",
            "Batch 600/2573, Loss: 0.0428\n",
            "Batch 610/2573, Loss: 0.0244\n",
            "Batch 620/2573, Loss: 0.0236\n",
            "Batch 630/2573, Loss: 0.0204\n",
            "Batch 640/2573, Loss: 0.0247\n",
            "Batch 650/2573, Loss: 0.0166\n",
            "Batch 660/2573, Loss: 0.0289\n",
            "Batch 670/2573, Loss: 0.0129\n",
            "Batch 680/2573, Loss: 0.0061\n",
            "Batch 690/2573, Loss: 0.0052\n",
            "Batch 700/2573, Loss: 0.0293\n",
            "Batch 710/2573, Loss: 0.0210\n",
            "Batch 720/2573, Loss: 0.0259\n",
            "Batch 730/2573, Loss: 0.0200\n",
            "Batch 740/2573, Loss: 0.0185\n",
            "Batch 750/2573, Loss: 0.0065\n",
            "Batch 760/2573, Loss: 0.0181\n",
            "Batch 770/2573, Loss: 0.0136\n",
            "Batch 780/2573, Loss: 0.0131\n",
            "Batch 790/2573, Loss: 0.0135\n",
            "Batch 800/2573, Loss: 0.0264\n",
            "Batch 810/2573, Loss: 0.0173\n",
            "Batch 820/2573, Loss: 0.0361\n",
            "Batch 830/2573, Loss: 0.0129\n",
            "Batch 840/2573, Loss: 0.0272\n",
            "Batch 850/2573, Loss: 0.0270\n",
            "Batch 860/2573, Loss: 0.0157\n",
            "Batch 870/2573, Loss: 0.0274\n",
            "Batch 880/2573, Loss: 0.0366\n",
            "Batch 890/2573, Loss: 0.0077\n",
            "Batch 900/2573, Loss: 0.0094\n",
            "Batch 910/2573, Loss: 0.0203\n",
            "Batch 920/2573, Loss: 0.0140\n",
            "Batch 930/2573, Loss: 0.0158\n",
            "Batch 940/2573, Loss: 0.0143\n",
            "Batch 950/2573, Loss: 0.0311\n",
            "Batch 960/2573, Loss: 0.0311\n",
            "Batch 970/2573, Loss: 0.0149\n",
            "Batch 980/2573, Loss: 0.0155\n",
            "Batch 990/2573, Loss: 0.0100\n",
            "Batch 1000/2573, Loss: 0.0267\n",
            "Batch 1010/2573, Loss: 0.0248\n",
            "Batch 1020/2573, Loss: 0.0186\n",
            "Batch 1030/2573, Loss: 0.0072\n",
            "Batch 1040/2573, Loss: 0.0348\n",
            "Batch 1050/2573, Loss: 0.0186\n",
            "Batch 1060/2573, Loss: 0.0210\n",
            "Batch 1070/2573, Loss: 0.0094\n",
            "Batch 1080/2573, Loss: 0.0137\n",
            "Batch 1090/2573, Loss: 0.0108\n",
            "Batch 1100/2573, Loss: 0.0300\n",
            "Batch 1110/2573, Loss: 0.0127\n",
            "Batch 1120/2573, Loss: 0.0271\n",
            "Batch 1130/2573, Loss: 0.0216\n",
            "Batch 1140/2573, Loss: 0.0304\n",
            "Batch 1150/2573, Loss: 0.0183\n",
            "Batch 1160/2573, Loss: 0.0149\n",
            "Batch 1170/2573, Loss: 0.0190\n",
            "Batch 1180/2573, Loss: 0.0122\n",
            "Batch 1190/2573, Loss: 0.0072\n",
            "Batch 1200/2573, Loss: 0.0209\n",
            "Batch 1210/2573, Loss: 0.0178\n",
            "Batch 1220/2573, Loss: 0.0293\n",
            "Batch 1230/2573, Loss: 0.0106\n",
            "Batch 1240/2573, Loss: 0.0295\n",
            "Batch 1250/2573, Loss: 0.0279\n",
            "Batch 1260/2573, Loss: 0.0255\n",
            "Batch 1270/2573, Loss: 0.0198\n",
            "Batch 1280/2573, Loss: 0.0217\n",
            "Batch 1290/2573, Loss: 0.0036\n",
            "Batch 1300/2573, Loss: 0.0273\n",
            "Batch 1310/2573, Loss: 0.0213\n",
            "Batch 1320/2573, Loss: 0.0230\n",
            "Batch 1330/2573, Loss: 0.0103\n",
            "Batch 1340/2573, Loss: 0.0210\n",
            "Batch 1350/2573, Loss: 0.0235\n",
            "Batch 1360/2573, Loss: 0.0248\n",
            "Batch 1370/2573, Loss: 0.0103\n",
            "Batch 1380/2573, Loss: 0.0535\n",
            "Batch 1390/2573, Loss: 0.0183\n",
            "Batch 1400/2573, Loss: 0.0130\n",
            "Batch 1410/2573, Loss: 0.0195\n",
            "Batch 1420/2573, Loss: 0.0144\n",
            "Batch 1430/2573, Loss: 0.0196\n",
            "Batch 1440/2573, Loss: 0.0150\n",
            "Batch 1450/2573, Loss: 0.0124\n",
            "Batch 1460/2573, Loss: 0.0365\n",
            "Batch 1470/2573, Loss: 0.0075\n",
            "Batch 1480/2573, Loss: 0.0150\n",
            "Batch 1490/2573, Loss: 0.0159\n",
            "Batch 1500/2573, Loss: 0.0294\n",
            "Batch 1510/2573, Loss: 0.0248\n",
            "Batch 1520/2573, Loss: 0.0153\n",
            "Batch 1530/2573, Loss: 0.0291\n",
            "Batch 1540/2573, Loss: 0.0125\n",
            "Batch 1550/2573, Loss: 0.0154\n",
            "Batch 1560/2573, Loss: 0.0141\n",
            "Batch 1570/2573, Loss: 0.0285\n",
            "Batch 1580/2573, Loss: 0.0094\n",
            "Batch 1590/2573, Loss: 0.0135\n",
            "Batch 1600/2573, Loss: 0.0202\n",
            "Batch 1610/2573, Loss: 0.0087\n",
            "Batch 1620/2573, Loss: 0.0091\n",
            "Batch 1630/2573, Loss: 0.0059\n",
            "Batch 1640/2573, Loss: 0.0172\n",
            "Batch 1650/2573, Loss: 0.0418\n",
            "Batch 1660/2573, Loss: 0.0167\n",
            "Batch 1670/2573, Loss: 0.0173\n",
            "Batch 1680/2573, Loss: 0.0466\n",
            "Batch 1690/2573, Loss: 0.0177\n",
            "Batch 1700/2573, Loss: 0.0205\n",
            "Batch 1710/2573, Loss: 0.0174\n",
            "Batch 1720/2573, Loss: 0.0078\n",
            "Batch 1730/2573, Loss: 0.0270\n",
            "Batch 1740/2573, Loss: 0.0308\n",
            "Batch 1750/2573, Loss: 0.0148\n",
            "Batch 1760/2573, Loss: 0.0316\n",
            "Batch 1770/2573, Loss: 0.0080\n",
            "Batch 1780/2573, Loss: 0.0167\n",
            "Batch 1790/2573, Loss: 0.0076\n",
            "Batch 1800/2573, Loss: 0.0331\n",
            "Batch 1810/2573, Loss: 0.0205\n",
            "Batch 1820/2573, Loss: 0.0102\n",
            "Batch 1830/2573, Loss: 0.0131\n",
            "Batch 1840/2573, Loss: 0.0227\n",
            "Batch 1850/2573, Loss: 0.0222\n",
            "Batch 1860/2573, Loss: 0.0192\n",
            "Batch 1870/2573, Loss: 0.0228\n",
            "Batch 1880/2573, Loss: 0.0136\n",
            "Batch 1890/2573, Loss: 0.0174\n",
            "Batch 1900/2573, Loss: 0.0155\n",
            "Batch 1910/2573, Loss: 0.0169\n",
            "Batch 1920/2573, Loss: 0.0206\n",
            "Batch 1930/2573, Loss: 0.0234\n",
            "Batch 1940/2573, Loss: 0.0157\n",
            "Batch 1950/2573, Loss: 0.0101\n",
            "Batch 1960/2573, Loss: 0.0139\n",
            "Batch 1970/2573, Loss: 0.0261\n",
            "Batch 1980/2573, Loss: 0.0164\n",
            "Batch 1990/2573, Loss: 0.0163\n",
            "Batch 2000/2573, Loss: 0.0109\n",
            "Batch 2010/2573, Loss: 0.0104\n",
            "Batch 2020/2573, Loss: 0.0173\n",
            "Batch 2030/2573, Loss: 0.0111\n",
            "Batch 2040/2573, Loss: 0.0167\n",
            "Batch 2050/2573, Loss: 0.0244\n",
            "Batch 2060/2573, Loss: 0.0381\n",
            "Batch 2070/2573, Loss: 0.0053\n",
            "Batch 2080/2573, Loss: 0.0117\n",
            "Batch 2090/2573, Loss: 0.0060\n",
            "Batch 2100/2573, Loss: 0.0223\n",
            "Batch 2110/2573, Loss: 0.0310\n",
            "Batch 2120/2573, Loss: 0.0273\n",
            "Batch 2130/2573, Loss: 0.0434\n",
            "Batch 2140/2573, Loss: 0.0146\n",
            "Batch 2150/2573, Loss: 0.0122\n",
            "Batch 2160/2573, Loss: 0.0270\n",
            "Batch 2170/2573, Loss: 0.0552\n",
            "Batch 2180/2573, Loss: 0.0235\n",
            "Batch 2190/2573, Loss: 0.0215\n",
            "Batch 2200/2573, Loss: 0.0163\n",
            "Batch 2210/2573, Loss: 0.0195\n",
            "Batch 2220/2573, Loss: 0.0221\n",
            "Batch 2230/2573, Loss: 0.0263\n",
            "Batch 2240/2573, Loss: 0.0179\n",
            "Batch 2250/2573, Loss: 0.0196\n",
            "Batch 2260/2573, Loss: 0.0095\n",
            "Batch 2270/2573, Loss: 0.0154\n",
            "Batch 2280/2573, Loss: 0.0344\n",
            "Batch 2290/2573, Loss: 0.0180\n",
            "Batch 2300/2573, Loss: 0.0274\n",
            "Batch 2310/2573, Loss: 0.0376\n",
            "Batch 2320/2573, Loss: 0.0131\n",
            "Batch 2330/2573, Loss: 0.0226\n",
            "Batch 2340/2573, Loss: 0.0221\n",
            "Batch 2350/2573, Loss: 0.0146\n",
            "Batch 2360/2573, Loss: 0.0257\n",
            "Batch 2370/2573, Loss: 0.0520\n",
            "Batch 2380/2573, Loss: 0.0279\n",
            "Batch 2390/2573, Loss: 0.0064\n",
            "Batch 2400/2573, Loss: 0.0187\n",
            "Batch 2410/2573, Loss: 0.0202\n",
            "Batch 2420/2573, Loss: 0.0179\n",
            "Batch 2430/2573, Loss: 0.0101\n",
            "Batch 2440/2573, Loss: 0.0268\n",
            "Batch 2450/2573, Loss: 0.0127\n",
            "Batch 2460/2573, Loss: 0.0323\n",
            "Batch 2470/2573, Loss: 0.0275\n",
            "Batch 2480/2573, Loss: 0.0310\n",
            "Batch 2490/2573, Loss: 0.0174\n",
            "Batch 2500/2573, Loss: 0.0163\n",
            "Batch 2510/2573, Loss: 0.0255\n",
            "Batch 2520/2573, Loss: 0.0082\n",
            "Batch 2530/2573, Loss: 0.0140\n",
            "Batch 2540/2573, Loss: 0.0130\n",
            "Batch 2550/2573, Loss: 0.0156\n",
            "Batch 2560/2573, Loss: 0.0357\n",
            "Batch 2570/2573, Loss: 0.0297\n",
            "Epoch 7 Average Loss: 0.0199\n",
            "\n",
            "Epoch 8/20\n",
            "------------------------------\n",
            "Batch 10/2573, Loss: 0.0260\n",
            "Batch 20/2573, Loss: 0.0144\n",
            "Batch 30/2573, Loss: 0.0069\n",
            "Batch 40/2573, Loss: 0.0349\n",
            "Batch 50/2573, Loss: 0.0156\n",
            "Batch 60/2573, Loss: 0.0157\n",
            "Batch 70/2573, Loss: 0.0127\n",
            "Batch 80/2573, Loss: 0.0199\n",
            "Batch 90/2573, Loss: 0.0098\n",
            "Batch 100/2573, Loss: 0.0247\n",
            "Batch 110/2573, Loss: 0.0103\n",
            "Batch 120/2573, Loss: 0.0144\n",
            "Batch 130/2573, Loss: 0.0086\n",
            "Batch 140/2573, Loss: 0.0148\n",
            "Batch 150/2573, Loss: 0.0189\n",
            "Batch 160/2573, Loss: 0.0143\n",
            "Batch 170/2573, Loss: 0.0189\n",
            "Batch 180/2573, Loss: 0.0070\n",
            "Batch 190/2573, Loss: 0.0076\n",
            "Batch 200/2573, Loss: 0.0144\n",
            "Batch 210/2573, Loss: 0.0086\n",
            "Batch 220/2573, Loss: 0.0070\n",
            "Batch 230/2573, Loss: 0.0178\n",
            "Batch 240/2573, Loss: 0.0099\n",
            "Batch 250/2573, Loss: 0.0236\n",
            "Batch 260/2573, Loss: 0.0056\n",
            "Batch 270/2573, Loss: 0.0349\n",
            "Batch 280/2573, Loss: 0.0103\n",
            "Batch 290/2573, Loss: 0.0075\n",
            "Batch 300/2573, Loss: 0.0410\n",
            "Batch 310/2573, Loss: 0.0183\n",
            "Batch 320/2573, Loss: 0.0177\n",
            "Batch 330/2573, Loss: 0.0129\n",
            "Batch 340/2573, Loss: 0.0415\n",
            "Batch 350/2573, Loss: 0.0228\n",
            "Batch 360/2573, Loss: 0.0423\n",
            "Batch 370/2573, Loss: 0.0318\n",
            "Batch 380/2573, Loss: 0.0410\n",
            "Batch 390/2573, Loss: 0.0077\n",
            "Batch 400/2573, Loss: 0.0223\n",
            "Batch 410/2573, Loss: 0.0305\n",
            "Batch 420/2573, Loss: 0.0113\n",
            "Batch 430/2573, Loss: 0.0107\n",
            "Batch 440/2573, Loss: 0.0273\n",
            "Batch 450/2573, Loss: 0.0068\n",
            "Batch 460/2573, Loss: 0.0150\n",
            "Batch 470/2573, Loss: 0.0121\n",
            "Batch 480/2573, Loss: 0.0234\n",
            "Batch 490/2573, Loss: 0.0131\n",
            "Batch 500/2573, Loss: 0.0080\n",
            "Batch 510/2573, Loss: 0.0155\n",
            "Batch 520/2573, Loss: 0.0131\n",
            "Batch 530/2573, Loss: 0.0143\n",
            "Batch 540/2573, Loss: 0.0104\n",
            "Batch 550/2573, Loss: 0.0115\n",
            "Batch 560/2573, Loss: 0.0096\n",
            "Batch 570/2573, Loss: 0.0117\n",
            "Batch 580/2573, Loss: 0.0152\n",
            "Batch 590/2573, Loss: 0.0130\n",
            "Batch 600/2573, Loss: 0.0284\n",
            "Batch 610/2573, Loss: 0.0149\n",
            "Batch 620/2573, Loss: 0.0198\n",
            "Batch 630/2573, Loss: 0.0145\n",
            "Batch 640/2573, Loss: 0.0136\n",
            "Batch 650/2573, Loss: 0.0198\n",
            "Batch 660/2573, Loss: 0.0088\n",
            "Batch 670/2573, Loss: 0.0080\n",
            "Batch 680/2573, Loss: 0.0148\n",
            "Batch 690/2573, Loss: 0.0324\n",
            "Batch 700/2573, Loss: 0.0202\n",
            "Batch 710/2573, Loss: 0.0194\n",
            "Batch 720/2573, Loss: 0.0264\n",
            "Batch 730/2573, Loss: 0.0131\n",
            "Batch 740/2573, Loss: 0.0096\n",
            "Batch 750/2573, Loss: 0.0176\n",
            "Batch 760/2573, Loss: 0.0113\n",
            "Batch 770/2573, Loss: 0.0083\n",
            "Batch 780/2573, Loss: 0.0307\n",
            "Batch 790/2573, Loss: 0.0130\n",
            "Batch 800/2573, Loss: 0.0360\n",
            "Batch 810/2573, Loss: 0.0111\n",
            "Batch 820/2573, Loss: 0.0190\n",
            "Batch 830/2573, Loss: 0.0117\n",
            "Batch 840/2573, Loss: 0.0107\n",
            "Batch 850/2573, Loss: 0.0118\n",
            "Batch 860/2573, Loss: 0.0176\n",
            "Batch 870/2573, Loss: 0.0116\n",
            "Batch 880/2573, Loss: 0.0271\n",
            "Batch 890/2573, Loss: 0.0263\n",
            "Batch 900/2573, Loss: 0.0176\n",
            "Batch 910/2573, Loss: 0.0091\n",
            "Batch 920/2573, Loss: 0.0704\n",
            "Batch 930/2573, Loss: 0.0098\n",
            "Batch 940/2573, Loss: 0.0780\n",
            "Batch 950/2573, Loss: 0.0232\n",
            "Batch 960/2573, Loss: 0.0126\n",
            "Batch 970/2573, Loss: 0.0258\n",
            "Batch 980/2573, Loss: 0.0143\n",
            "Batch 990/2573, Loss: 0.0177\n",
            "Batch 1000/2573, Loss: 0.0108\n",
            "Batch 1010/2573, Loss: 0.0161\n",
            "Batch 1020/2573, Loss: 0.0344\n",
            "Batch 1030/2573, Loss: 0.0162\n",
            "Batch 1040/2573, Loss: 0.0144\n",
            "Batch 1050/2573, Loss: 0.0087\n",
            "Batch 1060/2573, Loss: 0.0211\n",
            "Batch 1070/2573, Loss: 0.0088\n",
            "Batch 1080/2573, Loss: 0.0254\n",
            "Batch 1090/2573, Loss: 0.0079\n",
            "Batch 1100/2573, Loss: 0.0116\n",
            "Batch 1110/2573, Loss: 0.0118\n",
            "Batch 1120/2573, Loss: 0.0154\n",
            "Batch 1130/2573, Loss: 0.0132\n",
            "Batch 1140/2573, Loss: 0.0187\n",
            "Batch 1150/2573, Loss: 0.0194\n",
            "Batch 1160/2573, Loss: 0.0152\n",
            "Batch 1170/2573, Loss: 0.0129\n",
            "Batch 1180/2573, Loss: 0.0353\n",
            "Batch 1190/2573, Loss: 0.0090\n",
            "Batch 1200/2573, Loss: 0.0115\n",
            "Batch 1210/2573, Loss: 0.0085\n",
            "Batch 1220/2573, Loss: 0.0360\n",
            "Batch 1230/2573, Loss: 0.0243\n",
            "Batch 1240/2573, Loss: 0.0172\n",
            "Batch 1250/2573, Loss: 0.0063\n",
            "Batch 1260/2573, Loss: 0.0370\n",
            "Batch 1270/2573, Loss: 0.0281\n",
            "Batch 1280/2573, Loss: 0.0177\n",
            "Batch 1290/2573, Loss: 0.0092\n",
            "Batch 1300/2573, Loss: 0.0123\n",
            "Batch 1310/2573, Loss: 0.0300\n",
            "Batch 1320/2573, Loss: 0.0182\n",
            "Batch 1330/2573, Loss: 0.0375\n",
            "Batch 1340/2573, Loss: 0.0139\n",
            "Batch 1350/2573, Loss: 0.0223\n",
            "Batch 1360/2573, Loss: 0.0129\n",
            "Batch 1370/2573, Loss: 0.0125\n",
            "Batch 1380/2573, Loss: 0.0159\n",
            "Batch 1390/2573, Loss: 0.0152\n",
            "Batch 1400/2573, Loss: 0.0170\n",
            "Batch 1410/2573, Loss: 0.0255\n",
            "Batch 1420/2573, Loss: 0.0124\n",
            "Batch 1430/2573, Loss: 0.0237\n",
            "Batch 1440/2573, Loss: 0.0138\n",
            "Batch 1450/2573, Loss: 0.0230\n",
            "Batch 1460/2573, Loss: 0.0194\n",
            "Batch 1470/2573, Loss: 0.0124\n",
            "Batch 1480/2573, Loss: 0.0132\n",
            "Batch 1490/2573, Loss: 0.0143\n",
            "Batch 1500/2573, Loss: 0.0344\n",
            "Batch 1510/2573, Loss: 0.0213\n",
            "Batch 1520/2573, Loss: 0.0067\n",
            "Batch 1530/2573, Loss: 0.0274\n",
            "Batch 1540/2573, Loss: 0.0290\n",
            "Batch 1550/2573, Loss: 0.0171\n",
            "Batch 1560/2573, Loss: 0.0407\n",
            "Batch 1570/2573, Loss: 0.0177\n",
            "Batch 1580/2573, Loss: 0.0085\n",
            "Batch 1590/2573, Loss: 0.0106\n",
            "Batch 1600/2573, Loss: 0.0201\n",
            "Batch 1610/2573, Loss: 0.0166\n",
            "Batch 1620/2573, Loss: 0.0163\n",
            "Batch 1630/2573, Loss: 0.0109\n",
            "Batch 1640/2573, Loss: 0.0126\n",
            "Batch 1650/2573, Loss: 0.0125\n",
            "Batch 1660/2573, Loss: 0.0171\n",
            "Batch 1670/2573, Loss: 0.0183\n",
            "Batch 1680/2573, Loss: 0.0344\n",
            "Batch 1690/2573, Loss: 0.0205\n",
            "Batch 1700/2573, Loss: 0.0172\n",
            "Batch 1710/2573, Loss: 0.0129\n",
            "Batch 1720/2573, Loss: 0.0078\n",
            "Batch 1730/2573, Loss: 0.0378\n",
            "Batch 1740/2573, Loss: 0.0192\n",
            "Batch 1750/2573, Loss: 0.0235\n",
            "Batch 1760/2573, Loss: 0.0177\n",
            "Batch 1770/2573, Loss: 0.0178\n",
            "Batch 1780/2573, Loss: 0.0120\n",
            "Batch 1790/2573, Loss: 0.0517\n",
            "Batch 1800/2573, Loss: 0.0184\n",
            "Batch 1810/2573, Loss: 0.0093\n",
            "Batch 1820/2573, Loss: 0.0263\n",
            "Batch 1830/2573, Loss: 0.0181\n",
            "Batch 1840/2573, Loss: 0.0264\n",
            "Batch 1850/2573, Loss: 0.0109\n",
            "Batch 1860/2573, Loss: 0.0044\n",
            "Batch 1870/2573, Loss: 0.0133\n",
            "Batch 1880/2573, Loss: 0.0421\n",
            "Batch 1890/2573, Loss: 0.0074\n",
            "Batch 1900/2573, Loss: 0.0139\n",
            "Batch 1910/2573, Loss: 0.0197\n",
            "Batch 1920/2573, Loss: 0.0190\n",
            "Batch 1930/2573, Loss: 0.0098\n",
            "Batch 1940/2573, Loss: 0.0230\n",
            "Batch 1950/2573, Loss: 0.0092\n",
            "Batch 1960/2573, Loss: 0.0087\n",
            "Batch 1970/2573, Loss: 0.0117\n",
            "Batch 1980/2573, Loss: 0.0207\n",
            "Batch 1990/2573, Loss: 0.0167\n",
            "Batch 2000/2573, Loss: 0.0199\n",
            "Batch 2010/2573, Loss: 0.0419\n",
            "Batch 2020/2573, Loss: 0.0104\n",
            "Batch 2030/2573, Loss: 0.0277\n",
            "Batch 2040/2573, Loss: 0.0165\n",
            "Batch 2050/2573, Loss: 0.0348\n",
            "Batch 2060/2573, Loss: 0.0095\n",
            "Batch 2070/2573, Loss: 0.0168\n",
            "Batch 2080/2573, Loss: 0.0320\n",
            "Batch 2090/2573, Loss: 0.0116\n",
            "Batch 2100/2573, Loss: 0.0335\n",
            "Batch 2110/2573, Loss: 0.0089\n",
            "Batch 2120/2573, Loss: 0.0164\n",
            "Batch 2130/2573, Loss: 0.0145\n",
            "Batch 2140/2573, Loss: 0.0078\n",
            "Batch 2150/2573, Loss: 0.0263\n",
            "Batch 2160/2573, Loss: 0.0171\n",
            "Batch 2170/2573, Loss: 0.0186\n",
            "Batch 2180/2573, Loss: 0.0347\n",
            "Batch 2190/2573, Loss: 0.0463\n",
            "Batch 2200/2573, Loss: 0.0153\n",
            "Batch 2210/2573, Loss: 0.0237\n",
            "Batch 2220/2573, Loss: 0.0122\n",
            "Batch 2230/2573, Loss: 0.0135\n",
            "Batch 2240/2573, Loss: 0.0265\n",
            "Batch 2250/2573, Loss: 0.0072\n",
            "Batch 2260/2573, Loss: 0.0228\n",
            "Batch 2270/2573, Loss: 0.0341\n",
            "Batch 2280/2573, Loss: 0.0106\n",
            "Batch 2290/2573, Loss: 0.0193\n",
            "Batch 2300/2573, Loss: 0.0064\n",
            "Batch 2310/2573, Loss: 0.0111\n",
            "Batch 2320/2573, Loss: 0.0201\n",
            "Batch 2330/2573, Loss: 0.0222\n",
            "Batch 2340/2573, Loss: 0.0329\n",
            "Batch 2350/2573, Loss: 0.0190\n",
            "Batch 2360/2573, Loss: 0.0215\n",
            "Batch 2370/2573, Loss: 0.0069\n",
            "Batch 2380/2573, Loss: 0.0270\n",
            "Batch 2390/2573, Loss: 0.0280\n",
            "Batch 2400/2573, Loss: 0.0073\n",
            "Batch 2410/2573, Loss: 0.0230\n",
            "Batch 2420/2573, Loss: 0.0166\n",
            "Batch 2430/2573, Loss: 0.0251\n",
            "Batch 2440/2573, Loss: 0.0086\n",
            "Batch 2450/2573, Loss: 0.0379\n",
            "Batch 2460/2573, Loss: 0.0199\n",
            "Batch 2470/2573, Loss: 0.0123\n",
            "Batch 2480/2573, Loss: 0.0241\n",
            "Batch 2490/2573, Loss: 0.0077\n",
            "Batch 2500/2573, Loss: 0.0491\n",
            "Batch 2510/2573, Loss: 0.0301\n",
            "Batch 2520/2573, Loss: 0.0153\n",
            "Batch 2530/2573, Loss: 0.0213\n",
            "Batch 2540/2573, Loss: 0.0084\n",
            "Batch 2550/2573, Loss: 0.0259\n",
            "Batch 2560/2573, Loss: 0.0233\n",
            "Batch 2570/2573, Loss: 0.0196\n",
            "Epoch 8 Average Loss: 0.0190\n",
            "\n",
            "Epoch 9/20\n",
            "------------------------------\n",
            "Batch 10/2573, Loss: 0.0068\n",
            "Batch 20/2573, Loss: 0.0039\n",
            "Batch 30/2573, Loss: 0.0066\n",
            "Batch 40/2573, Loss: 0.0087\n",
            "Batch 50/2573, Loss: 0.0121\n",
            "Batch 60/2573, Loss: 0.0202\n",
            "Batch 70/2573, Loss: 0.0236\n",
            "Batch 80/2573, Loss: 0.0126\n",
            "Batch 90/2573, Loss: 0.0059\n",
            "Batch 100/2573, Loss: 0.0111\n",
            "Batch 110/2573, Loss: 0.0200\n",
            "Batch 120/2573, Loss: 0.0086\n",
            "Batch 130/2573, Loss: 0.0124\n",
            "Batch 140/2573, Loss: 0.0125\n",
            "Batch 150/2573, Loss: 0.0137\n",
            "Batch 160/2573, Loss: 0.0284\n",
            "Batch 170/2573, Loss: 0.0090\n",
            "Batch 180/2573, Loss: 0.0080\n",
            "Batch 190/2573, Loss: 0.0105\n",
            "Batch 200/2573, Loss: 0.0253\n",
            "Batch 210/2573, Loss: 0.0294\n",
            "Batch 220/2573, Loss: 0.0116\n",
            "Batch 230/2573, Loss: 0.0258\n",
            "Batch 240/2573, Loss: 0.0575\n",
            "Batch 250/2573, Loss: 0.0153\n",
            "Batch 260/2573, Loss: 0.0350\n",
            "Batch 270/2573, Loss: 0.0250\n",
            "Batch 280/2573, Loss: 0.0122\n",
            "Batch 290/2573, Loss: 0.0251\n",
            "Batch 300/2573, Loss: 0.0088\n",
            "Batch 310/2573, Loss: 0.0353\n",
            "Batch 320/2573, Loss: 0.0105\n",
            "Batch 330/2573, Loss: 0.0145\n",
            "Batch 340/2573, Loss: 0.0238\n",
            "Batch 350/2573, Loss: 0.0295\n",
            "Batch 360/2573, Loss: 0.0189\n",
            "Batch 370/2573, Loss: 0.0105\n",
            "Batch 380/2573, Loss: 0.0184\n",
            "Batch 390/2573, Loss: 0.0116\n",
            "Batch 400/2573, Loss: 0.0076\n",
            "Batch 410/2573, Loss: 0.0129\n",
            "Batch 420/2573, Loss: 0.0133\n",
            "Batch 430/2573, Loss: 0.0163\n",
            "Batch 440/2573, Loss: 0.0306\n",
            "Batch 450/2573, Loss: 0.0105\n",
            "Batch 460/2573, Loss: 0.0104\n",
            "Batch 470/2573, Loss: 0.0186\n",
            "Batch 480/2573, Loss: 0.0270\n",
            "Batch 490/2573, Loss: 0.0142\n",
            "Batch 500/2573, Loss: 0.0280\n",
            "Batch 510/2573, Loss: 0.0102\n",
            "Batch 520/2573, Loss: 0.0247\n",
            "Batch 530/2573, Loss: 0.0187\n",
            "Batch 540/2573, Loss: 0.0407\n",
            "Batch 550/2573, Loss: 0.0185\n",
            "Batch 560/2573, Loss: 0.0133\n",
            "Batch 570/2573, Loss: 0.0163\n",
            "Batch 580/2573, Loss: 0.0091\n",
            "Batch 590/2573, Loss: 0.0440\n",
            "Batch 600/2573, Loss: 0.0243\n",
            "Batch 610/2573, Loss: 0.0123\n",
            "Batch 620/2573, Loss: 0.0182\n",
            "Batch 630/2573, Loss: 0.0068\n",
            "Batch 640/2573, Loss: 0.0145\n",
            "Batch 650/2573, Loss: 0.0130\n",
            "Batch 660/2573, Loss: 0.0152\n",
            "Batch 670/2573, Loss: 0.0110\n",
            "Batch 680/2573, Loss: 0.0233\n",
            "Batch 690/2573, Loss: 0.0121\n",
            "Batch 700/2573, Loss: 0.0162\n",
            "Batch 710/2573, Loss: 0.0189\n",
            "Batch 720/2573, Loss: 0.0164\n",
            "Batch 730/2573, Loss: 0.0505\n",
            "Batch 740/2573, Loss: 0.0189\n",
            "Batch 750/2573, Loss: 0.0115\n",
            "Batch 760/2573, Loss: 0.0284\n",
            "Batch 770/2573, Loss: 0.0226\n",
            "Batch 780/2573, Loss: 0.0165\n",
            "Batch 790/2573, Loss: 0.0298\n",
            "Batch 800/2573, Loss: 0.0092\n",
            "Batch 810/2573, Loss: 0.0091\n",
            "Batch 820/2573, Loss: 0.0241\n",
            "Batch 830/2573, Loss: 0.0167\n",
            "Batch 840/2573, Loss: 0.0104\n",
            "Batch 850/2573, Loss: 0.0152\n",
            "Batch 860/2573, Loss: 0.0125\n",
            "Batch 870/2573, Loss: 0.0158\n",
            "Batch 880/2573, Loss: 0.0230\n",
            "Batch 890/2573, Loss: 0.0116\n",
            "Batch 900/2573, Loss: 0.0088\n",
            "Batch 910/2573, Loss: 0.0258\n",
            "Batch 920/2573, Loss: 0.0171\n",
            "Batch 930/2573, Loss: 0.0081\n",
            "Batch 940/2573, Loss: 0.0210\n",
            "Batch 950/2573, Loss: 0.0246\n",
            "Batch 960/2573, Loss: 0.0156\n",
            "Batch 970/2573, Loss: 0.0168\n",
            "Batch 980/2573, Loss: 0.0196\n",
            "Batch 990/2573, Loss: 0.0166\n",
            "Batch 1000/2573, Loss: 0.0217\n",
            "Batch 1010/2573, Loss: 0.0167\n",
            "Batch 1020/2573, Loss: 0.0090\n",
            "Batch 1030/2573, Loss: 0.0168\n",
            "Batch 1040/2573, Loss: 0.0106\n",
            "Batch 1050/2573, Loss: 0.0256\n",
            "Batch 1060/2573, Loss: 0.0186\n",
            "Batch 1070/2573, Loss: 0.0165\n",
            "Batch 1080/2573, Loss: 0.0211\n",
            "Batch 1090/2573, Loss: 0.0194\n",
            "Batch 1100/2573, Loss: 0.0175\n",
            "Batch 1110/2573, Loss: 0.0202\n",
            "Batch 1120/2573, Loss: 0.0109\n",
            "Batch 1130/2573, Loss: 0.0156\n",
            "Batch 1140/2573, Loss: 0.0070\n",
            "Batch 1150/2573, Loss: 0.0114\n",
            "Batch 1160/2573, Loss: 0.0143\n",
            "Batch 1170/2573, Loss: 0.0122\n",
            "Batch 1180/2573, Loss: 0.0294\n",
            "Batch 1190/2573, Loss: 0.0182\n",
            "Batch 1200/2573, Loss: 0.0318\n",
            "Batch 1210/2573, Loss: 0.0068\n",
            "Batch 1220/2573, Loss: 0.0240\n",
            "Batch 1230/2573, Loss: 0.0184\n",
            "Batch 1240/2573, Loss: 0.0162\n",
            "Batch 1250/2573, Loss: 0.0120\n",
            "Batch 1260/2573, Loss: 0.0094\n",
            "Batch 1270/2573, Loss: 0.0127\n",
            "Batch 1280/2573, Loss: 0.0246\n",
            "Batch 1290/2573, Loss: 0.0223\n",
            "Batch 1300/2573, Loss: 0.0054\n",
            "Batch 1310/2573, Loss: 0.0148\n",
            "Batch 1320/2573, Loss: 0.0220\n",
            "Batch 1330/2573, Loss: 0.0193\n",
            "Batch 1340/2573, Loss: 0.0105\n",
            "Batch 1350/2573, Loss: 0.0103\n",
            "Batch 1360/2573, Loss: 0.0087\n",
            "Batch 1370/2573, Loss: 0.0233\n",
            "Batch 1380/2573, Loss: 0.0393\n",
            "Batch 1390/2573, Loss: 0.0156\n",
            "Batch 1400/2573, Loss: 0.0171\n",
            "Batch 1410/2573, Loss: 0.0054\n",
            "Batch 1420/2573, Loss: 0.0051\n",
            "Batch 1430/2573, Loss: 0.0383\n",
            "Batch 1440/2573, Loss: 0.0226\n",
            "Batch 1450/2573, Loss: 0.0194\n",
            "Batch 1460/2573, Loss: 0.0147\n",
            "Batch 1470/2573, Loss: 0.0099\n",
            "Batch 1480/2573, Loss: 0.0152\n",
            "Batch 1490/2573, Loss: 0.0110\n",
            "Batch 1500/2573, Loss: 0.0223\n",
            "Batch 1510/2573, Loss: 0.0249\n",
            "Batch 1520/2573, Loss: 0.0354\n",
            "Batch 1530/2573, Loss: 0.0161\n",
            "Batch 1540/2573, Loss: 0.0223\n",
            "Batch 1550/2573, Loss: 0.0197\n",
            "Batch 1560/2573, Loss: 0.0139\n",
            "Batch 1570/2573, Loss: 0.0334\n",
            "Batch 1580/2573, Loss: 0.0116\n",
            "Batch 1590/2573, Loss: 0.0080\n",
            "Batch 1600/2573, Loss: 0.0122\n",
            "Batch 1610/2573, Loss: 0.0128\n",
            "Batch 1620/2573, Loss: 0.0176\n",
            "Batch 1630/2573, Loss: 0.0075\n",
            "Batch 1640/2573, Loss: 0.0378\n",
            "Batch 1650/2573, Loss: 0.0140\n",
            "Batch 1660/2573, Loss: 0.0271\n",
            "Batch 1670/2573, Loss: 0.0095\n",
            "Batch 1680/2573, Loss: 0.0115\n",
            "Batch 1690/2573, Loss: 0.0144\n",
            "Batch 1700/2573, Loss: 0.0123\n",
            "Batch 1710/2573, Loss: 0.0144\n",
            "Batch 1720/2573, Loss: 0.0203\n",
            "Batch 1730/2573, Loss: 0.0094\n",
            "Batch 1740/2573, Loss: 0.0090\n",
            "Batch 1750/2573, Loss: 0.0172\n",
            "Batch 1760/2573, Loss: 0.0117\n",
            "Batch 1770/2573, Loss: 0.0212\n",
            "Batch 1780/2573, Loss: 0.0134\n",
            "Batch 1790/2573, Loss: 0.0342\n",
            "Batch 1800/2573, Loss: 0.0099\n",
            "Batch 1810/2573, Loss: 0.0162\n",
            "Batch 1820/2573, Loss: 0.0151\n",
            "Batch 1830/2573, Loss: 0.0220\n",
            "Batch 1840/2573, Loss: 0.0139\n",
            "Batch 1850/2573, Loss: 0.0148\n",
            "Batch 1860/2573, Loss: 0.0341\n",
            "Batch 1870/2573, Loss: 0.0115\n",
            "Batch 1880/2573, Loss: 0.0246\n",
            "Batch 1890/2573, Loss: 0.0180\n",
            "Batch 1900/2573, Loss: 0.0326\n",
            "Batch 1910/2573, Loss: 0.0089\n",
            "Batch 1920/2573, Loss: 0.0089\n",
            "Batch 1930/2573, Loss: 0.0163\n",
            "Batch 1940/2573, Loss: 0.0145\n",
            "Batch 1950/2573, Loss: 0.0128\n",
            "Batch 1960/2573, Loss: 0.0138\n",
            "Batch 1970/2573, Loss: 0.0175\n",
            "Batch 1980/2573, Loss: 0.0183\n",
            "Batch 1990/2573, Loss: 0.0419\n",
            "Batch 2000/2573, Loss: 0.0353\n",
            "Batch 2010/2573, Loss: 0.0203\n",
            "Batch 2020/2573, Loss: 0.0152\n",
            "Batch 2030/2573, Loss: 0.0257\n",
            "Batch 2040/2573, Loss: 0.0219\n",
            "Batch 2050/2573, Loss: 0.0076\n",
            "Batch 2060/2573, Loss: 0.0293\n",
            "Batch 2070/2573, Loss: 0.0250\n",
            "Batch 2080/2573, Loss: 0.0119\n",
            "Batch 2090/2573, Loss: 0.0077\n",
            "Batch 2100/2573, Loss: 0.0148\n",
            "Batch 2110/2573, Loss: 0.0327\n",
            "Batch 2120/2573, Loss: 0.0064\n",
            "Batch 2130/2573, Loss: 0.0464\n",
            "Batch 2140/2573, Loss: 0.0236\n",
            "Batch 2150/2573, Loss: 0.0249\n",
            "Batch 2160/2573, Loss: 0.0135\n",
            "Batch 2170/2573, Loss: 0.0109\n",
            "Batch 2180/2573, Loss: 0.0317\n",
            "Batch 2190/2573, Loss: 0.0061\n",
            "Batch 2200/2573, Loss: 0.0212\n",
            "Batch 2210/2573, Loss: 0.0126\n",
            "Batch 2220/2573, Loss: 0.0176\n",
            "Batch 2230/2573, Loss: 0.0167\n",
            "Batch 2240/2573, Loss: 0.0148\n",
            "Batch 2250/2573, Loss: 0.0088\n",
            "Batch 2260/2573, Loss: 0.0271\n",
            "Batch 2270/2573, Loss: 0.0183\n",
            "Batch 2280/2573, Loss: 0.0282\n",
            "Batch 2290/2573, Loss: 0.0104\n",
            "Batch 2300/2573, Loss: 0.0318\n",
            "Batch 2310/2573, Loss: 0.0171\n",
            "Batch 2320/2573, Loss: 0.0056\n",
            "Batch 2330/2573, Loss: 0.0195\n",
            "Batch 2340/2573, Loss: 0.0239\n",
            "Batch 2350/2573, Loss: 0.0128\n",
            "Batch 2360/2573, Loss: 0.0060\n",
            "Batch 2370/2573, Loss: 0.0167\n",
            "Batch 2380/2573, Loss: 0.0339\n",
            "Batch 2390/2573, Loss: 0.0109\n",
            "Batch 2400/2573, Loss: 0.0176\n",
            "Batch 2410/2573, Loss: 0.0179\n",
            "Batch 2420/2573, Loss: 0.0155\n",
            "Batch 2430/2573, Loss: 0.0187\n",
            "Batch 2440/2573, Loss: 0.0156\n",
            "Batch 2450/2573, Loss: 0.0154\n",
            "Batch 2460/2573, Loss: 0.0158\n",
            "Batch 2470/2573, Loss: 0.0244\n",
            "Batch 2480/2573, Loss: 0.0374\n",
            "Batch 2490/2573, Loss: 0.0148\n",
            "Batch 2500/2573, Loss: 0.0094\n",
            "Batch 2510/2573, Loss: 0.0214\n",
            "Batch 2520/2573, Loss: 0.0287\n",
            "Batch 2530/2573, Loss: 0.0397\n",
            "Batch 2540/2573, Loss: 0.0163\n",
            "Batch 2550/2573, Loss: 0.0094\n",
            "Batch 2560/2573, Loss: 0.0078\n",
            "Batch 2570/2573, Loss: 0.0089\n",
            "Epoch 9 Average Loss: 0.0184\n",
            "\n",
            "Epoch 10/20\n",
            "------------------------------\n",
            "Batch 10/2573, Loss: 0.0163\n",
            "Batch 20/2573, Loss: 0.0143\n",
            "Batch 30/2573, Loss: 0.0319\n",
            "Batch 40/2573, Loss: 0.0282\n",
            "Batch 50/2573, Loss: 0.0073\n",
            "Batch 60/2573, Loss: 0.0135\n",
            "Batch 70/2573, Loss: 0.0121\n",
            "Batch 80/2573, Loss: 0.0092\n",
            "Batch 90/2573, Loss: 0.0400\n",
            "Batch 100/2573, Loss: 0.0074\n",
            "Batch 110/2573, Loss: 0.0138\n",
            "Batch 120/2573, Loss: 0.0133\n",
            "Batch 130/2573, Loss: 0.0170\n",
            "Batch 140/2573, Loss: 0.0193\n",
            "Batch 150/2573, Loss: 0.0078\n",
            "Batch 160/2573, Loss: 0.0134\n",
            "Batch 170/2573, Loss: 0.0235\n",
            "Batch 180/2573, Loss: 0.0072\n",
            "Batch 190/2573, Loss: 0.0118\n",
            "Batch 200/2573, Loss: 0.0333\n",
            "Batch 210/2573, Loss: 0.0125\n",
            "Batch 220/2573, Loss: 0.0087\n",
            "Batch 230/2573, Loss: 0.0137\n",
            "Batch 240/2573, Loss: 0.0247\n",
            "Batch 250/2573, Loss: 0.0152\n",
            "Batch 260/2573, Loss: 0.0159\n",
            "Batch 270/2573, Loss: 0.0111\n",
            "Batch 280/2573, Loss: 0.0133\n",
            "Batch 290/2573, Loss: 0.0112\n",
            "Batch 300/2573, Loss: 0.0180\n",
            "Batch 310/2573, Loss: 0.0202\n",
            "Batch 320/2573, Loss: 0.0285\n",
            "Batch 330/2573, Loss: 0.0110\n",
            "Batch 340/2573, Loss: 0.0095\n",
            "Batch 350/2573, Loss: 0.0366\n",
            "Batch 360/2573, Loss: 0.0433\n",
            "Batch 370/2573, Loss: 0.0116\n",
            "Batch 380/2573, Loss: 0.0090\n",
            "Batch 390/2573, Loss: 0.0167\n",
            "Batch 400/2573, Loss: 0.0294\n",
            "Batch 410/2573, Loss: 0.0177\n",
            "Batch 420/2573, Loss: 0.0214\n",
            "Batch 430/2573, Loss: 0.0163\n",
            "Batch 440/2573, Loss: 0.0190\n",
            "Batch 450/2573, Loss: 0.0212\n",
            "Batch 460/2573, Loss: 0.0282\n",
            "Batch 470/2573, Loss: 0.0148\n",
            "Batch 480/2573, Loss: 0.0118\n",
            "Batch 490/2573, Loss: 0.0073\n",
            "Batch 500/2573, Loss: 0.0126\n",
            "Batch 510/2573, Loss: 0.0171\n",
            "Batch 520/2573, Loss: 0.0181\n",
            "Batch 530/2573, Loss: 0.0175\n",
            "Batch 540/2573, Loss: 0.0120\n",
            "Batch 550/2573, Loss: 0.0079\n",
            "Batch 560/2573, Loss: 0.0154\n",
            "Batch 570/2573, Loss: 0.0063\n",
            "Batch 580/2573, Loss: 0.0095\n",
            "Batch 590/2573, Loss: 0.0098\n",
            "Batch 600/2573, Loss: 0.0107\n",
            "Batch 610/2573, Loss: 0.0058\n",
            "Batch 620/2573, Loss: 0.0074\n",
            "Batch 630/2573, Loss: 0.0253\n",
            "Batch 640/2573, Loss: 0.0259\n",
            "Batch 650/2573, Loss: 0.0329\n",
            "Batch 660/2573, Loss: 0.0278\n",
            "Batch 670/2573, Loss: 0.0226\n",
            "Batch 680/2573, Loss: 0.0110\n",
            "Batch 690/2573, Loss: 0.0123\n",
            "Batch 700/2573, Loss: 0.0198\n",
            "Batch 710/2573, Loss: 0.0089\n",
            "Batch 720/2573, Loss: 0.0096\n",
            "Batch 730/2573, Loss: 0.0147\n",
            "Batch 740/2573, Loss: 0.0126\n",
            "Batch 750/2573, Loss: 0.0197\n",
            "Batch 760/2573, Loss: 0.0170\n",
            "Batch 770/2573, Loss: 0.0053\n",
            "Batch 780/2573, Loss: 0.0124\n",
            "Batch 790/2573, Loss: 0.0097\n",
            "Batch 800/2573, Loss: 0.0139\n",
            "Batch 810/2573, Loss: 0.0170\n",
            "Batch 820/2573, Loss: 0.0164\n",
            "Batch 830/2573, Loss: 0.0160\n",
            "Batch 840/2573, Loss: 0.0298\n",
            "Batch 850/2573, Loss: 0.0158\n",
            "Batch 860/2573, Loss: 0.0078\n",
            "Batch 870/2573, Loss: 0.0301\n",
            "Batch 880/2573, Loss: 0.0166\n",
            "Batch 890/2573, Loss: 0.0072\n",
            "Batch 900/2573, Loss: 0.0157\n",
            "Batch 910/2573, Loss: 0.0097\n",
            "Batch 920/2573, Loss: 0.0220\n",
            "Batch 930/2573, Loss: 0.0232\n",
            "Batch 940/2573, Loss: 0.0081\n",
            "Batch 950/2573, Loss: 0.0422\n",
            "Batch 960/2573, Loss: 0.0114\n",
            "Batch 970/2573, Loss: 0.0131\n",
            "Batch 980/2573, Loss: 0.0121\n",
            "Batch 990/2573, Loss: 0.0329\n",
            "Batch 1000/2573, Loss: 0.0270\n",
            "Batch 1010/2573, Loss: 0.0106\n",
            "Batch 1020/2573, Loss: 0.0201\n",
            "Batch 1030/2573, Loss: 0.0180\n",
            "Batch 1040/2573, Loss: 0.0159\n",
            "Batch 1050/2573, Loss: 0.0115\n",
            "Batch 1060/2573, Loss: 0.0159\n",
            "Batch 1070/2573, Loss: 0.0092\n",
            "Batch 1080/2573, Loss: 0.0166\n",
            "Batch 1090/2573, Loss: 0.0146\n",
            "Batch 1100/2573, Loss: 0.0192\n",
            "Batch 1110/2573, Loss: 0.0300\n",
            "Batch 1120/2573, Loss: 0.0107\n",
            "Batch 1130/2573, Loss: 0.0214\n",
            "Batch 1140/2573, Loss: 0.0383\n",
            "Batch 1150/2573, Loss: 0.0054\n",
            "Batch 1160/2573, Loss: 0.0475\n",
            "Batch 1170/2573, Loss: 0.0168\n",
            "Batch 1180/2573, Loss: 0.0192\n",
            "Batch 1190/2573, Loss: 0.0113\n",
            "Batch 1200/2573, Loss: 0.0254\n",
            "Batch 1210/2573, Loss: 0.0238\n",
            "Batch 1220/2573, Loss: 0.0077\n",
            "Batch 1230/2573, Loss: 0.0454\n",
            "Batch 1240/2573, Loss: 0.0217\n",
            "Batch 1250/2573, Loss: 0.0123\n",
            "Batch 1260/2573, Loss: 0.0109\n",
            "Batch 1270/2573, Loss: 0.0262\n",
            "Batch 1280/2573, Loss: 0.0138\n",
            "Batch 1290/2573, Loss: 0.0378\n",
            "Batch 1300/2573, Loss: 0.0127\n",
            "Batch 1310/2573, Loss: 0.0249\n",
            "Batch 1320/2573, Loss: 0.0110\n",
            "Batch 1330/2573, Loss: 0.0139\n",
            "Batch 1340/2573, Loss: 0.0065\n",
            "Batch 1350/2573, Loss: 0.0135\n",
            "Batch 1360/2573, Loss: 0.0302\n",
            "Batch 1370/2573, Loss: 0.0139\n",
            "Batch 1380/2573, Loss: 0.0148\n",
            "Batch 1390/2573, Loss: 0.0139\n",
            "Batch 1400/2573, Loss: 0.0904\n",
            "Batch 1410/2573, Loss: 0.0372\n",
            "Batch 1420/2573, Loss: 0.0170\n",
            "Batch 1430/2573, Loss: 0.0291\n",
            "Batch 1440/2573, Loss: 0.0108\n",
            "Batch 1450/2573, Loss: 0.0107\n",
            "Batch 1460/2573, Loss: 0.0211\n",
            "Batch 1470/2573, Loss: 0.0148\n",
            "Batch 1480/2573, Loss: 0.0112\n",
            "Batch 1490/2573, Loss: 0.0137\n",
            "Batch 1500/2573, Loss: 0.0161\n",
            "Batch 1510/2573, Loss: 0.0165\n",
            "Batch 1520/2573, Loss: 0.0085\n",
            "Batch 1530/2573, Loss: 0.0130\n",
            "Batch 1540/2573, Loss: 0.0152\n",
            "Batch 1550/2573, Loss: 0.0200\n",
            "Batch 1560/2573, Loss: 0.0153\n",
            "Batch 1570/2573, Loss: 0.0153\n",
            "Batch 1580/2573, Loss: 0.0145\n",
            "Batch 1590/2573, Loss: 0.0235\n",
            "Batch 1600/2573, Loss: 0.0211\n",
            "Batch 1610/2573, Loss: 0.0108\n",
            "Batch 1620/2573, Loss: 0.0108\n",
            "Batch 1630/2573, Loss: 0.0083\n",
            "Batch 1640/2573, Loss: 0.0113\n",
            "Batch 1650/2573, Loss: 0.0165\n",
            "Batch 1660/2573, Loss: 0.0384\n",
            "Batch 1670/2573, Loss: 0.0418\n",
            "Batch 1680/2573, Loss: 0.0212\n",
            "Batch 1690/2573, Loss: 0.0208\n",
            "Batch 1700/2573, Loss: 0.0101\n",
            "Batch 1710/2573, Loss: 0.0040\n",
            "Batch 1720/2573, Loss: 0.0097\n",
            "Batch 1730/2573, Loss: 0.0147\n",
            "Batch 1740/2573, Loss: 0.0103\n",
            "Batch 1750/2573, Loss: 0.0097\n",
            "Batch 1760/2573, Loss: 0.0131\n",
            "Batch 1770/2573, Loss: 0.0068\n",
            "Batch 1780/2573, Loss: 0.0118\n",
            "Batch 1790/2573, Loss: 0.0250\n",
            "Batch 1800/2573, Loss: 0.0172\n",
            "Batch 1810/2573, Loss: 0.0230\n",
            "Batch 1820/2573, Loss: 0.0158\n",
            "Batch 1830/2573, Loss: 0.0199\n",
            "Batch 1840/2573, Loss: 0.0218\n",
            "Batch 1850/2573, Loss: 0.0140\n",
            "Batch 1860/2573, Loss: 0.0232\n",
            "Batch 1870/2573, Loss: 0.0076\n",
            "Batch 1880/2573, Loss: 0.0191\n",
            "Batch 1890/2573, Loss: 0.0230\n",
            "Batch 1900/2573, Loss: 0.0160\n",
            "Batch 1910/2573, Loss: 0.0122\n",
            "Batch 1920/2573, Loss: 0.0464\n",
            "Batch 1930/2573, Loss: 0.0314\n",
            "Batch 1940/2573, Loss: 0.0091\n",
            "Batch 1950/2573, Loss: 0.0134\n",
            "Batch 1960/2573, Loss: 0.0181\n",
            "Batch 1970/2573, Loss: 0.0241\n",
            "Batch 1980/2573, Loss: 0.0210\n",
            "Batch 1990/2573, Loss: 0.0543\n",
            "Batch 2000/2573, Loss: 0.0157\n",
            "Batch 2010/2573, Loss: 0.0277\n",
            "Batch 2020/2573, Loss: 0.0109\n",
            "Batch 2030/2573, Loss: 0.0068\n",
            "Batch 2040/2573, Loss: 0.0183\n",
            "Batch 2050/2573, Loss: 0.0129\n",
            "Batch 2060/2573, Loss: 0.0086\n",
            "Batch 2070/2573, Loss: 0.0202\n",
            "Batch 2080/2573, Loss: 0.0133\n",
            "Batch 2090/2573, Loss: 0.0221\n",
            "Batch 2100/2573, Loss: 0.0250\n",
            "Batch 2110/2573, Loss: 0.0195\n",
            "Batch 2120/2573, Loss: 0.0219\n",
            "Batch 2130/2573, Loss: 0.0272\n",
            "Batch 2140/2573, Loss: 0.0304\n",
            "Batch 2150/2573, Loss: 0.0110\n",
            "Batch 2160/2573, Loss: 0.0101\n",
            "Batch 2170/2573, Loss: 0.0104\n",
            "Batch 2180/2573, Loss: 0.0174\n",
            "Batch 2190/2573, Loss: 0.0179\n",
            "Batch 2200/2573, Loss: 0.0134\n",
            "Batch 2210/2573, Loss: 0.0125\n",
            "Batch 2220/2573, Loss: 0.0209\n",
            "Batch 2230/2573, Loss: 0.0149\n",
            "Batch 2240/2573, Loss: 0.0193\n",
            "Batch 2250/2573, Loss: 0.0095\n",
            "Batch 2260/2573, Loss: 0.0102\n",
            "Batch 2270/2573, Loss: 0.0325\n",
            "Batch 2280/2573, Loss: 0.0238\n",
            "Batch 2290/2573, Loss: 0.0157\n",
            "Batch 2300/2573, Loss: 0.0098\n",
            "Batch 2310/2573, Loss: 0.0207\n",
            "Batch 2320/2573, Loss: 0.0454\n",
            "Batch 2330/2573, Loss: 0.0357\n",
            "Batch 2340/2573, Loss: 0.0209\n",
            "Batch 2350/2573, Loss: 0.0334\n",
            "Batch 2360/2573, Loss: 0.0165\n",
            "Batch 2370/2573, Loss: 0.0096\n",
            "Batch 2380/2573, Loss: 0.0124\n",
            "Batch 2390/2573, Loss: 0.0073\n",
            "Batch 2400/2573, Loss: 0.0147\n",
            "Batch 2410/2573, Loss: 0.0073\n",
            "Batch 2420/2573, Loss: 0.0088\n",
            "Batch 2430/2573, Loss: 0.0222\n",
            "Batch 2440/2573, Loss: 0.0294\n",
            "Batch 2450/2573, Loss: 0.0129\n",
            "Batch 2460/2573, Loss: 0.0176\n",
            "Batch 2470/2573, Loss: 0.0326\n",
            "Batch 2480/2573, Loss: 0.0234\n",
            "Batch 2490/2573, Loss: 0.0133\n",
            "Batch 2500/2573, Loss: 0.0090\n",
            "Batch 2510/2573, Loss: 0.0183\n",
            "Batch 2520/2573, Loss: 0.0164\n",
            "Batch 2530/2573, Loss: 0.0165\n",
            "Batch 2540/2573, Loss: 0.0094\n",
            "Batch 2550/2573, Loss: 0.0285\n",
            "Batch 2560/2573, Loss: 0.0064\n",
            "Batch 2570/2573, Loss: 0.0219\n",
            "Epoch 10 Average Loss: 0.0178\n",
            "\n",
            "Epoch 11/20\n",
            "------------------------------\n",
            "Batch 10/2573, Loss: 0.0097\n",
            "Batch 20/2573, Loss: 0.0214\n",
            "Batch 30/2573, Loss: 0.0140\n",
            "Batch 40/2573, Loss: 0.0090\n",
            "Batch 50/2573, Loss: 0.0115\n",
            "Batch 60/2573, Loss: 0.0159\n",
            "Batch 70/2573, Loss: 0.0209\n",
            "Batch 80/2573, Loss: 0.0269\n",
            "Batch 90/2573, Loss: 0.0213\n",
            "Batch 100/2573, Loss: 0.0170\n",
            "Batch 110/2573, Loss: 0.0099\n",
            "Batch 120/2573, Loss: 0.0078\n",
            "Batch 130/2573, Loss: 0.0187\n",
            "Batch 140/2573, Loss: 0.0159\n",
            "Batch 150/2573, Loss: 0.0160\n",
            "Batch 160/2573, Loss: 0.0189\n",
            "Batch 170/2573, Loss: 0.0134\n",
            "Batch 180/2573, Loss: 0.0249\n",
            "Batch 190/2573, Loss: 0.0145\n",
            "Batch 200/2573, Loss: 0.0252\n",
            "Batch 210/2573, Loss: 0.0313\n",
            "Batch 220/2573, Loss: 0.0229\n",
            "Batch 230/2573, Loss: 0.0148\n",
            "Batch 240/2573, Loss: 0.0180\n",
            "Batch 250/2573, Loss: 0.0063\n",
            "Batch 260/2573, Loss: 0.0316\n",
            "Batch 270/2573, Loss: 0.0307\n",
            "Batch 280/2573, Loss: 0.0110\n",
            "Batch 290/2573, Loss: 0.0140\n",
            "Batch 300/2573, Loss: 0.0139\n",
            "Batch 310/2573, Loss: 0.0322\n",
            "Batch 320/2573, Loss: 0.0283\n",
            "Batch 330/2573, Loss: 0.0286\n",
            "Batch 340/2573, Loss: 0.0476\n",
            "Batch 350/2573, Loss: 0.0195\n",
            "Batch 360/2573, Loss: 0.0167\n",
            "Batch 370/2573, Loss: 0.0108\n",
            "Batch 380/2573, Loss: 0.0218\n",
            "Batch 390/2573, Loss: 0.0172\n",
            "Batch 400/2573, Loss: 0.0271\n",
            "Batch 410/2573, Loss: 0.0105\n",
            "Batch 420/2573, Loss: 0.0118\n",
            "Batch 430/2573, Loss: 0.0106\n",
            "Batch 440/2573, Loss: 0.0123\n",
            "Batch 450/2573, Loss: 0.0124\n",
            "Batch 460/2573, Loss: 0.0134\n",
            "Batch 470/2573, Loss: 0.0138\n",
            "Batch 480/2573, Loss: 0.0152\n",
            "Batch 490/2573, Loss: 0.0174\n",
            "Batch 500/2573, Loss: 0.0082\n",
            "Batch 510/2573, Loss: 0.0098\n",
            "Batch 520/2573, Loss: 0.0292\n",
            "Batch 530/2573, Loss: 0.0169\n",
            "Batch 540/2573, Loss: 0.0231\n",
            "Batch 550/2573, Loss: 0.0055\n",
            "Batch 560/2573, Loss: 0.0188\n",
            "Batch 570/2573, Loss: 0.0313\n",
            "Batch 580/2573, Loss: 0.0173\n",
            "Batch 590/2573, Loss: 0.0200\n",
            "Batch 600/2573, Loss: 0.0060\n",
            "Batch 610/2573, Loss: 0.0125\n",
            "Batch 620/2573, Loss: 0.0206\n",
            "Batch 630/2573, Loss: 0.0164\n",
            "Batch 640/2573, Loss: 0.0210\n",
            "Batch 650/2573, Loss: 0.0160\n",
            "Batch 660/2573, Loss: 0.0092\n",
            "Batch 670/2573, Loss: 0.0247\n",
            "Batch 680/2573, Loss: 0.0181\n",
            "Batch 690/2573, Loss: 0.0158\n",
            "Batch 700/2573, Loss: 0.0148\n",
            "Batch 710/2573, Loss: 0.0413\n",
            "Batch 720/2573, Loss: 0.0128\n",
            "Batch 730/2573, Loss: 0.0052\n",
            "Batch 740/2573, Loss: 0.0060\n",
            "Batch 750/2573, Loss: 0.0263\n",
            "Batch 760/2573, Loss: 0.0091\n",
            "Batch 770/2573, Loss: 0.0141\n",
            "Batch 780/2573, Loss: 0.0128\n",
            "Batch 790/2573, Loss: 0.0167\n",
            "Batch 800/2573, Loss: 0.0126\n",
            "Batch 810/2573, Loss: 0.0092\n",
            "Batch 820/2573, Loss: 0.0130\n",
            "Batch 830/2573, Loss: 0.0126\n",
            "Batch 840/2573, Loss: 0.0052\n",
            "Batch 850/2573, Loss: 0.0074\n",
            "Batch 860/2573, Loss: 0.0124\n",
            "Batch 870/2573, Loss: 0.0104\n",
            "Batch 880/2573, Loss: 0.0253\n",
            "Batch 890/2573, Loss: 0.0121\n",
            "Batch 900/2573, Loss: 0.0159\n",
            "Batch 910/2573, Loss: 0.0100\n",
            "Batch 920/2573, Loss: 0.0221\n",
            "Batch 930/2573, Loss: 0.0062\n",
            "Batch 940/2573, Loss: 0.0210\n",
            "Batch 950/2573, Loss: 0.0194\n",
            "Batch 960/2573, Loss: 0.0225\n",
            "Batch 970/2573, Loss: 0.0175\n",
            "Batch 980/2573, Loss: 0.0124\n",
            "Batch 990/2573, Loss: 0.0176\n",
            "Batch 1000/2573, Loss: 0.0462\n",
            "Batch 1010/2573, Loss: 0.0489\n",
            "Batch 1020/2573, Loss: 0.0325\n",
            "Batch 1030/2573, Loss: 0.0145\n",
            "Batch 1040/2573, Loss: 0.0169\n",
            "Batch 1050/2573, Loss: 0.0173\n",
            "Batch 1060/2573, Loss: 0.0092\n",
            "Batch 1070/2573, Loss: 0.0214\n",
            "Batch 1080/2573, Loss: 0.0128\n",
            "Batch 1090/2573, Loss: 0.0165\n",
            "Batch 1100/2573, Loss: 0.0366\n",
            "Batch 1110/2573, Loss: 0.0113\n",
            "Batch 1120/2573, Loss: 0.0172\n",
            "Batch 1130/2573, Loss: 0.0154\n",
            "Batch 1140/2573, Loss: 0.0189\n",
            "Batch 1150/2573, Loss: 0.0092\n",
            "Batch 1160/2573, Loss: 0.0173\n",
            "Batch 1170/2573, Loss: 0.0198\n",
            "Batch 1180/2573, Loss: 0.0303\n",
            "Batch 1190/2573, Loss: 0.0292\n",
            "Batch 1200/2573, Loss: 0.0382\n",
            "Batch 1210/2573, Loss: 0.0198\n",
            "Batch 1220/2573, Loss: 0.0119\n",
            "Batch 1230/2573, Loss: 0.0197\n",
            "Batch 1240/2573, Loss: 0.0171\n",
            "Batch 1250/2573, Loss: 0.0146\n",
            "Batch 1260/2573, Loss: 0.0046\n",
            "Batch 1270/2573, Loss: 0.0124\n",
            "Batch 1280/2573, Loss: 0.0306\n",
            "Batch 1290/2573, Loss: 0.0429\n",
            "Batch 1300/2573, Loss: 0.0091\n",
            "Batch 1310/2573, Loss: 0.0144\n",
            "Batch 1320/2573, Loss: 0.0135\n",
            "Batch 1330/2573, Loss: 0.0084\n",
            "Batch 1340/2573, Loss: 0.0211\n",
            "Batch 1350/2573, Loss: 0.0124\n",
            "Batch 1360/2573, Loss: 0.0086\n",
            "Batch 1370/2573, Loss: 0.0124\n",
            "Batch 1380/2573, Loss: 0.0119\n",
            "Batch 1390/2573, Loss: 0.0254\n",
            "Batch 1400/2573, Loss: 0.0132\n",
            "Batch 1410/2573, Loss: 0.0105\n",
            "Batch 1420/2573, Loss: 0.0096\n",
            "Batch 1430/2573, Loss: 0.0182\n",
            "Batch 1440/2573, Loss: 0.0363\n",
            "Batch 1450/2573, Loss: 0.0302\n",
            "Batch 1460/2573, Loss: 0.0420\n",
            "Batch 1470/2573, Loss: 0.0379\n",
            "Batch 1480/2573, Loss: 0.0264\n",
            "Batch 1490/2573, Loss: 0.0118\n",
            "Batch 1500/2573, Loss: 0.0074\n",
            "Batch 1510/2573, Loss: 0.0147\n",
            "Batch 1520/2573, Loss: 0.0091\n",
            "Batch 1530/2573, Loss: 0.0174\n",
            "Batch 1540/2573, Loss: 0.0152\n",
            "Batch 1550/2573, Loss: 0.0199\n",
            "Batch 1560/2573, Loss: 0.0330\n",
            "Batch 1570/2573, Loss: 0.0118\n",
            "Batch 1580/2573, Loss: 0.0212\n",
            "Batch 1590/2573, Loss: 0.0183\n",
            "Batch 1600/2573, Loss: 0.0144\n",
            "Batch 1610/2573, Loss: 0.0188\n",
            "Batch 1620/2573, Loss: 0.0147\n",
            "Batch 1630/2573, Loss: 0.0094\n",
            "Batch 1640/2573, Loss: 0.0388\n",
            "Batch 1650/2573, Loss: 0.0230\n",
            "Batch 1660/2573, Loss: 0.0179\n",
            "Batch 1670/2573, Loss: 0.0175\n",
            "Batch 1680/2573, Loss: 0.0095\n",
            "Batch 1690/2573, Loss: 0.0077\n",
            "Batch 1700/2573, Loss: 0.0101\n",
            "Batch 1710/2573, Loss: 0.0109\n",
            "Batch 1720/2573, Loss: 0.0118\n",
            "Batch 1730/2573, Loss: 0.0196\n",
            "Batch 1740/2573, Loss: 0.0054\n",
            "Batch 1750/2573, Loss: 0.0156\n",
            "Batch 1760/2573, Loss: 0.0120\n",
            "Batch 1770/2573, Loss: 0.0080\n",
            "Batch 1780/2573, Loss: 0.0233\n",
            "Batch 1790/2573, Loss: 0.0136\n",
            "Batch 1800/2573, Loss: 0.0105\n",
            "Batch 1810/2573, Loss: 0.0240\n",
            "Batch 1820/2573, Loss: 0.0098\n",
            "Batch 1830/2573, Loss: 0.0328\n",
            "Batch 1840/2573, Loss: 0.0143\n",
            "Batch 1850/2573, Loss: 0.0103\n",
            "Batch 1860/2573, Loss: 0.0100\n",
            "Batch 1870/2573, Loss: 0.0323\n",
            "Batch 1880/2573, Loss: 0.0073\n",
            "Batch 1890/2573, Loss: 0.0135\n",
            "Batch 1900/2573, Loss: 0.0271\n",
            "Batch 1910/2573, Loss: 0.0423\n",
            "Batch 1920/2573, Loss: 0.0245\n",
            "Batch 1930/2573, Loss: 0.0134\n",
            "Batch 1940/2573, Loss: 0.0085\n",
            "Batch 1950/2573, Loss: 0.0194\n",
            "Batch 1960/2573, Loss: 0.0157\n",
            "Batch 1970/2573, Loss: 0.0418\n",
            "Batch 1980/2573, Loss: 0.0157\n",
            "Batch 1990/2573, Loss: 0.0112\n",
            "Batch 2000/2573, Loss: 0.0105\n",
            "Batch 2010/2573, Loss: 0.0125\n",
            "Batch 2020/2573, Loss: 0.0181\n",
            "Batch 2030/2573, Loss: 0.0194\n",
            "Batch 2040/2573, Loss: 0.0138\n",
            "Batch 2050/2573, Loss: 0.0117\n",
            "Batch 2060/2573, Loss: 0.0068\n",
            "Batch 2070/2573, Loss: 0.0099\n",
            "Batch 2080/2573, Loss: 0.0128\n",
            "Batch 2090/2573, Loss: 0.0181\n",
            "Batch 2100/2573, Loss: 0.0039\n",
            "Batch 2110/2573, Loss: 0.0131\n",
            "Batch 2120/2573, Loss: 0.0116\n",
            "Batch 2130/2573, Loss: 0.0157\n",
            "Batch 2140/2573, Loss: 0.0087\n",
            "Batch 2150/2573, Loss: 0.0180\n",
            "Batch 2160/2573, Loss: 0.0086\n",
            "Batch 2170/2573, Loss: 0.0130\n",
            "Batch 2180/2573, Loss: 0.0158\n",
            "Batch 2190/2573, Loss: 0.0130\n",
            "Batch 2200/2573, Loss: 0.0126\n",
            "Batch 2210/2573, Loss: 0.0197\n",
            "Batch 2220/2573, Loss: 0.0136\n",
            "Batch 2230/2573, Loss: 0.0178\n",
            "Batch 2240/2573, Loss: 0.0123\n",
            "Batch 2250/2573, Loss: 0.0190\n",
            "Batch 2260/2573, Loss: 0.0164\n",
            "Batch 2270/2573, Loss: 0.0220\n",
            "Batch 2280/2573, Loss: 0.0471\n",
            "Batch 2290/2573, Loss: 0.0228\n",
            "Batch 2300/2573, Loss: 0.0174\n",
            "Batch 2310/2573, Loss: 0.0175\n",
            "Batch 2320/2573, Loss: 0.0180\n",
            "Batch 2330/2573, Loss: 0.0116\n",
            "Batch 2340/2573, Loss: 0.0177\n",
            "Batch 2350/2573, Loss: 0.0240\n",
            "Batch 2360/2573, Loss: 0.0237\n",
            "Batch 2370/2573, Loss: 0.0268\n",
            "Batch 2380/2573, Loss: 0.0059\n",
            "Batch 2390/2573, Loss: 0.0063\n",
            "Batch 2400/2573, Loss: 0.0276\n",
            "Batch 2410/2573, Loss: 0.0448\n",
            "Batch 2420/2573, Loss: 0.0060\n",
            "Batch 2430/2573, Loss: 0.0216\n",
            "Batch 2440/2573, Loss: 0.0141\n",
            "Batch 2450/2573, Loss: 0.0040\n",
            "Batch 2460/2573, Loss: 0.0333\n",
            "Batch 2470/2573, Loss: 0.0230\n",
            "Batch 2480/2573, Loss: 0.0125\n",
            "Batch 2490/2573, Loss: 0.0100\n",
            "Batch 2500/2573, Loss: 0.0186\n",
            "Batch 2510/2573, Loss: 0.0113\n",
            "Batch 2520/2573, Loss: 0.0245\n",
            "Batch 2530/2573, Loss: 0.0194\n",
            "Batch 2540/2573, Loss: 0.0067\n",
            "Batch 2550/2573, Loss: 0.0148\n",
            "Batch 2560/2573, Loss: 0.0164\n",
            "Batch 2570/2573, Loss: 0.0182\n",
            "Epoch 11 Average Loss: 0.0172\n",
            "\n",
            "Epoch 12/20\n",
            "------------------------------\n",
            "Batch 10/2573, Loss: 0.0068\n",
            "Batch 20/2573, Loss: 0.0214\n",
            "Batch 30/2573, Loss: 0.0097\n",
            "Batch 40/2573, Loss: 0.0101\n",
            "Batch 50/2573, Loss: 0.0125\n",
            "Batch 60/2573, Loss: 0.0166\n",
            "Batch 70/2573, Loss: 0.0144\n",
            "Batch 80/2573, Loss: 0.0239\n",
            "Batch 90/2573, Loss: 0.0068\n",
            "Batch 100/2573, Loss: 0.0262\n",
            "Batch 110/2573, Loss: 0.0065\n",
            "Batch 120/2573, Loss: 0.0250\n",
            "Batch 130/2573, Loss: 0.0108\n",
            "Batch 140/2573, Loss: 0.0101\n",
            "Batch 150/2573, Loss: 0.0186\n",
            "Batch 160/2573, Loss: 0.0076\n",
            "Batch 170/2573, Loss: 0.0092\n",
            "Batch 180/2573, Loss: 0.0088\n",
            "Batch 190/2573, Loss: 0.0102\n",
            "Batch 200/2573, Loss: 0.0114\n",
            "Batch 210/2573, Loss: 0.0140\n",
            "Batch 220/2573, Loss: 0.0153\n",
            "Batch 230/2573, Loss: 0.0215\n",
            "Batch 240/2573, Loss: 0.0172\n",
            "Batch 250/2573, Loss: 0.0068\n",
            "Batch 260/2573, Loss: 0.0150\n",
            "Batch 270/2573, Loss: 0.0123\n",
            "Batch 280/2573, Loss: 0.0137\n",
            "Batch 290/2573, Loss: 0.0134\n",
            "Batch 300/2573, Loss: 0.0447\n",
            "Batch 310/2573, Loss: 0.0103\n",
            "Batch 320/2573, Loss: 0.0167\n",
            "Batch 330/2573, Loss: 0.0094\n",
            "Batch 340/2573, Loss: 0.0180\n",
            "Batch 350/2573, Loss: 0.0153\n",
            "Batch 360/2573, Loss: 0.0115\n",
            "Batch 370/2573, Loss: 0.0135\n",
            "Batch 380/2573, Loss: 0.0144\n",
            "Batch 390/2573, Loss: 0.0142\n",
            "Batch 400/2573, Loss: 0.0120\n",
            "Batch 410/2573, Loss: 0.0099\n",
            "Batch 420/2573, Loss: 0.0164\n",
            "Batch 430/2573, Loss: 0.0247\n",
            "Batch 440/2573, Loss: 0.0103\n",
            "Batch 450/2573, Loss: 0.0269\n",
            "Batch 460/2573, Loss: 0.0538\n",
            "Batch 470/2573, Loss: 0.0128\n",
            "Batch 480/2573, Loss: 0.0185\n",
            "Batch 490/2573, Loss: 0.0104\n",
            "Batch 500/2573, Loss: 0.0574\n",
            "Batch 510/2573, Loss: 0.0195\n",
            "Batch 520/2573, Loss: 0.0112\n",
            "Batch 530/2573, Loss: 0.0174\n",
            "Batch 540/2573, Loss: 0.0298\n",
            "Batch 550/2573, Loss: 0.0125\n",
            "Batch 560/2573, Loss: 0.0144\n",
            "Batch 570/2573, Loss: 0.0124\n",
            "Batch 580/2573, Loss: 0.0089\n",
            "Batch 590/2573, Loss: 0.0093\n",
            "Batch 600/2573, Loss: 0.0304\n",
            "Batch 610/2573, Loss: 0.0077\n",
            "Batch 620/2573, Loss: 0.0112\n",
            "Batch 630/2573, Loss: 0.0041\n",
            "Batch 640/2573, Loss: 0.0159\n",
            "Batch 650/2573, Loss: 0.0283\n",
            "Batch 660/2573, Loss: 0.0175\n",
            "Batch 670/2573, Loss: 0.0225\n",
            "Batch 680/2573, Loss: 0.0218\n",
            "Batch 690/2573, Loss: 0.0130\n",
            "Batch 700/2573, Loss: 0.0140\n",
            "Batch 710/2573, Loss: 0.0151\n",
            "Batch 720/2573, Loss: 0.0102\n",
            "Batch 730/2573, Loss: 0.0134\n",
            "Batch 740/2573, Loss: 0.0086\n",
            "Batch 750/2573, Loss: 0.0267\n",
            "Batch 760/2573, Loss: 0.0078\n",
            "Batch 770/2573, Loss: 0.0231\n",
            "Batch 780/2573, Loss: 0.0150\n",
            "Batch 790/2573, Loss: 0.0140\n",
            "Batch 800/2573, Loss: 0.0247\n",
            "Batch 810/2573, Loss: 0.0167\n",
            "Batch 820/2573, Loss: 0.0194\n",
            "Batch 830/2573, Loss: 0.0164\n",
            "Batch 840/2573, Loss: 0.0166\n",
            "Batch 850/2573, Loss: 0.0248\n",
            "Batch 860/2573, Loss: 0.0157\n",
            "Batch 870/2573, Loss: 0.0375\n",
            "Batch 880/2573, Loss: 0.0228\n",
            "Batch 890/2573, Loss: 0.0070\n",
            "Batch 900/2573, Loss: 0.0192\n",
            "Batch 910/2573, Loss: 0.0177\n",
            "Batch 920/2573, Loss: 0.0096\n",
            "Batch 930/2573, Loss: 0.0148\n",
            "Batch 940/2573, Loss: 0.0165\n",
            "Batch 950/2573, Loss: 0.0074\n",
            "Batch 960/2573, Loss: 0.0066\n",
            "Batch 970/2573, Loss: 0.0091\n",
            "Batch 980/2573, Loss: 0.0263\n",
            "Batch 990/2573, Loss: 0.0195\n",
            "Batch 1000/2573, Loss: 0.0174\n",
            "Batch 1010/2573, Loss: 0.0289\n",
            "Batch 1020/2573, Loss: 0.0092\n",
            "Batch 1030/2573, Loss: 0.0168\n",
            "Batch 1040/2573, Loss: 0.0169\n",
            "Batch 1050/2573, Loss: 0.0195\n",
            "Batch 1060/2573, Loss: 0.0113\n",
            "Batch 1070/2573, Loss: 0.0060\n",
            "Batch 1080/2573, Loss: 0.0376\n",
            "Batch 1090/2573, Loss: 0.0178\n",
            "Batch 1100/2573, Loss: 0.0128\n",
            "Batch 1110/2573, Loss: 0.0137\n",
            "Batch 1120/2573, Loss: 0.0044\n",
            "Batch 1130/2573, Loss: 0.0377\n",
            "Batch 1140/2573, Loss: 0.0119\n",
            "Batch 1150/2573, Loss: 0.0061\n",
            "Batch 1160/2573, Loss: 0.0069\n",
            "Batch 1170/2573, Loss: 0.0233\n",
            "Batch 1180/2573, Loss: 0.0185\n",
            "Batch 1190/2573, Loss: 0.0088\n",
            "Batch 1200/2573, Loss: 0.0320\n",
            "Batch 1210/2573, Loss: 0.0141\n",
            "Batch 1220/2573, Loss: 0.0038\n",
            "Batch 1230/2573, Loss: 0.0141\n",
            "Batch 1240/2573, Loss: 0.0274\n",
            "Batch 1250/2573, Loss: 0.0169\n",
            "Batch 1260/2573, Loss: 0.0158\n",
            "Batch 1270/2573, Loss: 0.0092\n",
            "Batch 1280/2573, Loss: 0.0125\n",
            "Batch 1290/2573, Loss: 0.0109\n",
            "Batch 1300/2573, Loss: 0.0137\n",
            "Batch 1310/2573, Loss: 0.0239\n",
            "Batch 1320/2573, Loss: 0.0276\n",
            "Batch 1330/2573, Loss: 0.0213\n",
            "Batch 1340/2573, Loss: 0.0070\n",
            "Batch 1350/2573, Loss: 0.0095\n",
            "Batch 1360/2573, Loss: 0.0338\n",
            "Batch 1370/2573, Loss: 0.0212\n",
            "Batch 1380/2573, Loss: 0.0283\n",
            "Batch 1390/2573, Loss: 0.0211\n",
            "Batch 1400/2573, Loss: 0.0115\n",
            "Batch 1410/2573, Loss: 0.0146\n",
            "Batch 1420/2573, Loss: 0.0256\n",
            "Batch 1430/2573, Loss: 0.0071\n",
            "Batch 1440/2573, Loss: 0.0197\n",
            "Batch 1450/2573, Loss: 0.0151\n",
            "Batch 1460/2573, Loss: 0.0118\n",
            "Batch 1470/2573, Loss: 0.0183\n",
            "Batch 1480/2573, Loss: 0.0195\n",
            "Batch 1490/2573, Loss: 0.0221\n",
            "Batch 1500/2573, Loss: 0.0120\n",
            "Batch 1510/2573, Loss: 0.0073\n",
            "Batch 1520/2573, Loss: 0.0087\n",
            "Batch 1530/2573, Loss: 0.0274\n",
            "Batch 1540/2573, Loss: 0.0189\n",
            "Batch 1550/2573, Loss: 0.0193\n",
            "Batch 1560/2573, Loss: 0.0375\n",
            "Batch 1570/2573, Loss: 0.0114\n",
            "Batch 1580/2573, Loss: 0.0139\n",
            "Batch 1590/2573, Loss: 0.0080\n",
            "Batch 1600/2573, Loss: 0.0103\n",
            "Batch 1610/2573, Loss: 0.0400\n",
            "Batch 1620/2573, Loss: 0.0143\n",
            "Batch 1630/2573, Loss: 0.0128\n",
            "Batch 1640/2573, Loss: 0.0558\n",
            "Batch 1650/2573, Loss: 0.0216\n",
            "Batch 1660/2573, Loss: 0.0298\n",
            "Batch 1670/2573, Loss: 0.0178\n",
            "Batch 1680/2573, Loss: 0.0134\n",
            "Batch 1690/2573, Loss: 0.0076\n",
            "Batch 1700/2573, Loss: 0.0118\n",
            "Batch 1710/2573, Loss: 0.0084\n",
            "Batch 1720/2573, Loss: 0.0177\n",
            "Batch 1730/2573, Loss: 0.0256\n",
            "Batch 1740/2573, Loss: 0.0165\n",
            "Batch 1750/2573, Loss: 0.0054\n",
            "Batch 1760/2573, Loss: 0.0096\n",
            "Batch 1770/2573, Loss: 0.0142\n",
            "Batch 1780/2573, Loss: 0.0073\n",
            "Batch 1790/2573, Loss: 0.0197\n",
            "Batch 1800/2573, Loss: 0.0145\n",
            "Batch 1810/2573, Loss: 0.0111\n",
            "Batch 1820/2573, Loss: 0.0114\n",
            "Batch 1830/2573, Loss: 0.0169\n",
            "Batch 1840/2573, Loss: 0.0129\n",
            "Batch 1850/2573, Loss: 0.0122\n",
            "Batch 1860/2573, Loss: 0.0113\n",
            "Batch 1870/2573, Loss: 0.0359\n",
            "Batch 1880/2573, Loss: 0.0160\n",
            "Batch 1890/2573, Loss: 0.0129\n",
            "Batch 1900/2573, Loss: 0.0102\n",
            "Batch 1910/2573, Loss: 0.0211\n",
            "Batch 1920/2573, Loss: 0.0202\n",
            "Batch 1930/2573, Loss: 0.0111\n",
            "Batch 1940/2573, Loss: 0.0211\n",
            "Batch 1950/2573, Loss: 0.0171\n",
            "Batch 1960/2573, Loss: 0.0074\n",
            "Batch 1970/2573, Loss: 0.0098\n",
            "Batch 1980/2573, Loss: 0.0082\n",
            "Batch 1990/2573, Loss: 0.0183\n",
            "Batch 2000/2573, Loss: 0.0052\n",
            "Batch 2010/2573, Loss: 0.0123\n",
            "Batch 2020/2573, Loss: 0.0362\n",
            "Batch 2030/2573, Loss: 0.0265\n",
            "Batch 2040/2573, Loss: 0.0082\n",
            "Batch 2050/2573, Loss: 0.0124\n",
            "Batch 2060/2573, Loss: 0.0115\n",
            "Batch 2070/2573, Loss: 0.0128\n",
            "Batch 2080/2573, Loss: 0.0159\n",
            "Batch 2090/2573, Loss: 0.0186\n",
            "Batch 2100/2573, Loss: 0.0157\n",
            "Batch 2110/2573, Loss: 0.0296\n",
            "Batch 2120/2573, Loss: 0.0336\n",
            "Batch 2130/2573, Loss: 0.0148\n",
            "Batch 2140/2573, Loss: 0.0043\n",
            "Batch 2150/2573, Loss: 0.0105\n",
            "Batch 2160/2573, Loss: 0.0147\n",
            "Batch 2170/2573, Loss: 0.0199\n",
            "Batch 2180/2573, Loss: 0.0137\n",
            "Batch 2190/2573, Loss: 0.0090\n",
            "Batch 2200/2573, Loss: 0.0224\n",
            "Batch 2210/2573, Loss: 0.0518\n",
            "Batch 2220/2573, Loss: 0.0493\n",
            "Batch 2230/2573, Loss: 0.0186\n",
            "Batch 2240/2573, Loss: 0.0127\n",
            "Batch 2250/2573, Loss: 0.0256\n",
            "Batch 2260/2573, Loss: 0.0168\n",
            "Batch 2270/2573, Loss: 0.0434\n",
            "Batch 2280/2573, Loss: 0.0337\n",
            "Batch 2290/2573, Loss: 0.0100\n",
            "Batch 2300/2573, Loss: 0.0162\n",
            "Batch 2310/2573, Loss: 0.0146\n",
            "Batch 2320/2573, Loss: 0.0137\n",
            "Batch 2330/2573, Loss: 0.0158\n",
            "Batch 2340/2573, Loss: 0.0111\n",
            "Batch 2350/2573, Loss: 0.0117\n",
            "Batch 2360/2573, Loss: 0.0177\n",
            "Batch 2370/2573, Loss: 0.0140\n",
            "Batch 2380/2573, Loss: 0.0176\n",
            "Batch 2390/2573, Loss: 0.0136\n",
            "Batch 2400/2573, Loss: 0.0067\n",
            "Batch 2410/2573, Loss: 0.0098\n",
            "Batch 2420/2573, Loss: 0.0267\n",
            "Batch 2430/2573, Loss: 0.0152\n",
            "Batch 2440/2573, Loss: 0.0047\n",
            "Batch 2450/2573, Loss: 0.0160\n",
            "Batch 2460/2573, Loss: 0.0078\n",
            "Batch 2470/2573, Loss: 0.0172\n",
            "Batch 2480/2573, Loss: 0.0273\n",
            "Batch 2490/2573, Loss: 0.0233\n",
            "Batch 2500/2573, Loss: 0.0380\n",
            "Batch 2510/2573, Loss: 0.0436\n",
            "Batch 2520/2573, Loss: 0.0333\n",
            "Batch 2530/2573, Loss: 0.0147\n",
            "Batch 2540/2573, Loss: 0.0138\n",
            "Batch 2550/2573, Loss: 0.0097\n",
            "Batch 2560/2573, Loss: 0.0148\n",
            "Batch 2570/2573, Loss: 0.0176\n",
            "Epoch 12 Average Loss: 0.0170\n",
            "\n",
            "Epoch 13/20\n",
            "------------------------------\n",
            "Batch 10/2573, Loss: 0.0083\n",
            "Batch 20/2573, Loss: 0.0209\n",
            "Batch 30/2573, Loss: 0.0057\n",
            "Batch 40/2573, Loss: 0.0137\n",
            "Batch 50/2573, Loss: 0.0074\n",
            "Batch 60/2573, Loss: 0.0194\n",
            "Batch 70/2573, Loss: 0.0088\n",
            "Batch 80/2573, Loss: 0.0092\n",
            "Batch 90/2573, Loss: 0.0128\n",
            "Batch 100/2573, Loss: 0.0068\n",
            "Batch 110/2573, Loss: 0.0268\n",
            "Batch 120/2573, Loss: 0.0152\n",
            "Batch 130/2573, Loss: 0.0089\n",
            "Batch 140/2573, Loss: 0.0080\n",
            "Batch 150/2573, Loss: 0.0093\n",
            "Batch 160/2573, Loss: 0.0281\n",
            "Batch 170/2573, Loss: 0.0168\n",
            "Batch 180/2573, Loss: 0.0152\n",
            "Batch 190/2573, Loss: 0.0051\n",
            "Batch 200/2573, Loss: 0.0226\n",
            "Batch 210/2573, Loss: 0.0120\n",
            "Batch 220/2573, Loss: 0.0069\n",
            "Batch 230/2573, Loss: 0.0071\n",
            "Batch 240/2573, Loss: 0.0060\n",
            "Batch 250/2573, Loss: 0.0258\n",
            "Batch 260/2573, Loss: 0.0245\n",
            "Batch 270/2573, Loss: 0.0193\n",
            "Batch 280/2573, Loss: 0.0113\n",
            "Batch 290/2573, Loss: 0.0171\n",
            "Batch 300/2573, Loss: 0.0096\n",
            "Batch 310/2573, Loss: 0.0273\n",
            "Batch 320/2573, Loss: 0.0345\n",
            "Batch 330/2573, Loss: 0.0062\n",
            "Batch 340/2573, Loss: 0.0558\n",
            "Batch 350/2573, Loss: 0.0087\n",
            "Batch 360/2573, Loss: 0.0246\n",
            "Batch 370/2573, Loss: 0.0126\n",
            "Batch 380/2573, Loss: 0.0155\n",
            "Batch 390/2573, Loss: 0.0144\n",
            "Batch 400/2573, Loss: 0.0106\n",
            "Batch 410/2573, Loss: 0.0189\n",
            "Batch 420/2573, Loss: 0.0207\n",
            "Batch 430/2573, Loss: 0.0136\n",
            "Batch 440/2573, Loss: 0.0141\n",
            "Batch 450/2573, Loss: 0.0080\n",
            "Batch 460/2573, Loss: 0.0105\n",
            "Batch 470/2573, Loss: 0.0117\n",
            "Batch 480/2573, Loss: 0.0226\n",
            "Batch 490/2573, Loss: 0.0037\n",
            "Batch 500/2573, Loss: 0.0268\n",
            "Batch 510/2573, Loss: 0.0282\n",
            "Batch 520/2573, Loss: 0.0091\n",
            "Batch 530/2573, Loss: 0.0114\n",
            "Batch 540/2573, Loss: 0.0087\n",
            "Batch 550/2573, Loss: 0.0206\n",
            "Batch 560/2573, Loss: 0.0128\n",
            "Batch 570/2573, Loss: 0.0134\n",
            "Batch 580/2573, Loss: 0.0065\n",
            "Batch 590/2573, Loss: 0.0113\n",
            "Batch 600/2573, Loss: 0.0090\n",
            "Batch 610/2573, Loss: 0.0132\n",
            "Batch 620/2573, Loss: 0.0217\n",
            "Batch 630/2573, Loss: 0.0119\n",
            "Batch 640/2573, Loss: 0.0127\n",
            "Batch 650/2573, Loss: 0.0123\n",
            "Batch 660/2573, Loss: 0.0235\n",
            "Batch 670/2573, Loss: 0.0088\n",
            "Batch 680/2573, Loss: 0.0146\n",
            "Batch 690/2573, Loss: 0.0083\n",
            "Batch 700/2573, Loss: 0.0233\n",
            "Batch 710/2573, Loss: 0.0103\n",
            "Batch 720/2573, Loss: 0.0063\n",
            "Batch 730/2573, Loss: 0.0038\n",
            "Batch 740/2573, Loss: 0.0122\n",
            "Batch 750/2573, Loss: 0.0125\n",
            "Batch 760/2573, Loss: 0.0217\n",
            "Batch 770/2573, Loss: 0.0153\n",
            "Batch 780/2573, Loss: 0.0070\n",
            "Batch 790/2573, Loss: 0.0173\n",
            "Batch 800/2573, Loss: 0.0162\n",
            "Batch 810/2573, Loss: 0.0087\n",
            "Batch 820/2573, Loss: 0.0219\n",
            "Batch 830/2573, Loss: 0.0164\n",
            "Batch 840/2573, Loss: 0.0123\n",
            "Batch 850/2573, Loss: 0.0182\n",
            "Batch 860/2573, Loss: 0.0120\n",
            "Batch 870/2573, Loss: 0.0179\n",
            "Batch 880/2573, Loss: 0.0278\n",
            "Batch 890/2573, Loss: 0.0119\n",
            "Batch 900/2573, Loss: 0.0277\n",
            "Batch 910/2573, Loss: 0.0116\n",
            "Batch 920/2573, Loss: 0.0249\n",
            "Batch 930/2573, Loss: 0.0339\n",
            "Batch 940/2573, Loss: 0.0144\n",
            "Batch 950/2573, Loss: 0.0160\n",
            "Batch 960/2573, Loss: 0.0100\n",
            "Batch 970/2573, Loss: 0.0106\n",
            "Batch 980/2573, Loss: 0.0162\n",
            "Batch 990/2573, Loss: 0.0175\n",
            "Batch 1000/2573, Loss: 0.0069\n",
            "Batch 1010/2573, Loss: 0.0158\n",
            "Batch 1020/2573, Loss: 0.0200\n",
            "Batch 1030/2573, Loss: 0.0133\n",
            "Batch 1040/2573, Loss: 0.0182\n",
            "Batch 1050/2573, Loss: 0.0074\n",
            "Batch 1060/2573, Loss: 0.0069\n",
            "Batch 1070/2573, Loss: 0.0069\n",
            "Batch 1080/2573, Loss: 0.0281\n",
            "Batch 1090/2573, Loss: 0.0112\n",
            "Batch 1100/2573, Loss: 0.0125\n",
            "Batch 1110/2573, Loss: 0.0165\n",
            "Batch 1120/2573, Loss: 0.0106\n",
            "Batch 1130/2573, Loss: 0.0133\n",
            "Batch 1140/2573, Loss: 0.0144\n",
            "Batch 1150/2573, Loss: 0.0537\n",
            "Batch 1160/2573, Loss: 0.0184\n",
            "Batch 1170/2573, Loss: 0.0136\n",
            "Batch 1180/2573, Loss: 0.0208\n",
            "Batch 1190/2573, Loss: 0.0078\n",
            "Batch 1200/2573, Loss: 0.0152\n",
            "Batch 1210/2573, Loss: 0.0173\n",
            "Batch 1220/2573, Loss: 0.0248\n",
            "Batch 1230/2573, Loss: 0.0229\n",
            "Batch 1240/2573, Loss: 0.0189\n",
            "Batch 1250/2573, Loss: 0.0250\n",
            "Batch 1260/2573, Loss: 0.0107\n",
            "Batch 1270/2573, Loss: 0.0061\n",
            "Batch 1280/2573, Loss: 0.0233\n",
            "Batch 1290/2573, Loss: 0.0196\n",
            "Batch 1300/2573, Loss: 0.0196\n",
            "Batch 1310/2573, Loss: 0.0124\n",
            "Batch 1320/2573, Loss: 0.0203\n",
            "Batch 1330/2573, Loss: 0.0114\n",
            "Batch 1340/2573, Loss: 0.0179\n",
            "Batch 1350/2573, Loss: 0.0258\n",
            "Batch 1360/2573, Loss: 0.0271\n",
            "Batch 1370/2573, Loss: 0.0154\n",
            "Batch 1380/2573, Loss: 0.0191\n",
            "Batch 1390/2573, Loss: 0.0127\n",
            "Batch 1400/2573, Loss: 0.0089\n",
            "Batch 1410/2573, Loss: 0.0164\n",
            "Batch 1420/2573, Loss: 0.0166\n",
            "Batch 1430/2573, Loss: 0.0116\n",
            "Batch 1440/2573, Loss: 0.0201\n",
            "Batch 1450/2573, Loss: 0.0255\n",
            "Batch 1460/2573, Loss: 0.0070\n",
            "Batch 1470/2573, Loss: 0.0263\n",
            "Batch 1480/2573, Loss: 0.0112\n",
            "Batch 1490/2573, Loss: 0.0144\n",
            "Batch 1500/2573, Loss: 0.0046\n",
            "Batch 1510/2573, Loss: 0.0144\n",
            "Batch 1520/2573, Loss: 0.0094\n",
            "Batch 1530/2573, Loss: 0.0292\n",
            "Batch 1540/2573, Loss: 0.0174\n",
            "Batch 1550/2573, Loss: 0.0137\n",
            "Batch 1560/2573, Loss: 0.0096\n",
            "Batch 1570/2573, Loss: 0.0135\n",
            "Batch 1580/2573, Loss: 0.0189\n",
            "Batch 1590/2573, Loss: 0.0147\n",
            "Batch 1600/2573, Loss: 0.0084\n",
            "Batch 1610/2573, Loss: 0.0056\n",
            "Batch 1620/2573, Loss: 0.0089\n",
            "Batch 1630/2573, Loss: 0.0380\n",
            "Batch 1640/2573, Loss: 0.0128\n",
            "Batch 1650/2573, Loss: 0.0305\n",
            "Batch 1660/2573, Loss: 0.0106\n",
            "Batch 1670/2573, Loss: 0.0097\n",
            "Batch 1680/2573, Loss: 0.0062\n",
            "Batch 1690/2573, Loss: 0.0286\n",
            "Batch 1700/2573, Loss: 0.0114\n",
            "Batch 1710/2573, Loss: 0.0175\n",
            "Batch 1720/2573, Loss: 0.0130\n",
            "Batch 1730/2573, Loss: 0.0175\n",
            "Batch 1740/2573, Loss: 0.0160\n",
            "Batch 1750/2573, Loss: 0.0130\n",
            "Batch 1760/2573, Loss: 0.0184\n",
            "Batch 1770/2573, Loss: 0.0119\n",
            "Batch 1780/2573, Loss: 0.0165\n",
            "Batch 1790/2573, Loss: 0.0165\n",
            "Batch 1800/2573, Loss: 0.0146\n",
            "Batch 1810/2573, Loss: 0.0106\n",
            "Batch 1820/2573, Loss: 0.0058\n",
            "Batch 1830/2573, Loss: 0.0125\n",
            "Batch 1840/2573, Loss: 0.0106\n",
            "Batch 1850/2573, Loss: 0.0167\n",
            "Batch 1860/2573, Loss: 0.0106\n",
            "Batch 1870/2573, Loss: 0.0084\n",
            "Batch 1880/2573, Loss: 0.0099\n",
            "Batch 1890/2573, Loss: 0.0167\n",
            "Batch 1900/2573, Loss: 0.0364\n",
            "Batch 1910/2573, Loss: 0.0147\n",
            "Batch 1920/2573, Loss: 0.0169\n",
            "Batch 1930/2573, Loss: 0.0123\n",
            "Batch 1940/2573, Loss: 0.0118\n",
            "Batch 1950/2573, Loss: 0.0135\n",
            "Batch 1960/2573, Loss: 0.0126\n",
            "Batch 1970/2573, Loss: 0.0162\n",
            "Batch 1980/2573, Loss: 0.0113\n",
            "Batch 1990/2573, Loss: 0.0071\n",
            "Batch 2000/2573, Loss: 0.0433\n",
            "Batch 2010/2573, Loss: 0.0201\n",
            "Batch 2020/2573, Loss: 0.0154\n",
            "Batch 2030/2573, Loss: 0.0318\n",
            "Batch 2040/2573, Loss: 0.0087\n",
            "Batch 2050/2573, Loss: 0.0067\n",
            "Batch 2060/2573, Loss: 0.0081\n",
            "Batch 2070/2573, Loss: 0.0130\n",
            "Batch 2080/2573, Loss: 0.0189\n",
            "Batch 2090/2573, Loss: 0.0049\n",
            "Batch 2100/2573, Loss: 0.0092\n",
            "Batch 2110/2573, Loss: 0.0208\n",
            "Batch 2120/2573, Loss: 0.0314\n",
            "Batch 2130/2573, Loss: 0.0148\n",
            "Batch 2140/2573, Loss: 0.0126\n",
            "Batch 2150/2573, Loss: 0.0184\n",
            "Batch 2160/2573, Loss: 0.0080\n",
            "Batch 2170/2573, Loss: 0.0084\n",
            "Batch 2180/2573, Loss: 0.0131\n",
            "Batch 2190/2573, Loss: 0.0100\n",
            "Batch 2200/2573, Loss: 0.0243\n",
            "Batch 2210/2573, Loss: 0.0121\n",
            "Batch 2220/2573, Loss: 0.0233\n",
            "Batch 2230/2573, Loss: 0.0120\n",
            "Batch 2240/2573, Loss: 0.0117\n",
            "Batch 2250/2573, Loss: 0.0138\n",
            "Batch 2260/2573, Loss: 0.0188\n",
            "Batch 2270/2573, Loss: 0.0485\n",
            "Batch 2280/2573, Loss: 0.0133\n",
            "Batch 2290/2573, Loss: 0.0114\n",
            "Batch 2300/2573, Loss: 0.0142\n",
            "Batch 2310/2573, Loss: 0.0153\n",
            "Batch 2320/2573, Loss: 0.0217\n",
            "Batch 2330/2573, Loss: 0.0113\n",
            "Batch 2340/2573, Loss: 0.0115\n",
            "Batch 2350/2573, Loss: 0.0109\n",
            "Batch 2360/2573, Loss: 0.0214\n",
            "Batch 2370/2573, Loss: 0.0298\n",
            "Batch 2380/2573, Loss: 0.0139\n",
            "Batch 2390/2573, Loss: 0.0059\n",
            "Batch 2400/2573, Loss: 0.0199\n",
            "Batch 2410/2573, Loss: 0.0156\n",
            "Batch 2420/2573, Loss: 0.0133\n",
            "Batch 2430/2573, Loss: 0.0144\n",
            "Batch 2440/2573, Loss: 0.0303\n",
            "Batch 2450/2573, Loss: 0.0147\n",
            "Batch 2460/2573, Loss: 0.0082\n",
            "Batch 2470/2573, Loss: 0.0177\n",
            "Batch 2480/2573, Loss: 0.0188\n",
            "Batch 2490/2573, Loss: 0.0133\n",
            "Batch 2500/2573, Loss: 0.0377\n",
            "Batch 2510/2573, Loss: 0.0132\n",
            "Batch 2520/2573, Loss: 0.0212\n",
            "Batch 2530/2573, Loss: 0.0124\n",
            "Batch 2540/2573, Loss: 0.0322\n",
            "Batch 2550/2573, Loss: 0.0106\n",
            "Batch 2560/2573, Loss: 0.0176\n",
            "Batch 2570/2573, Loss: 0.0225\n",
            "Epoch 13 Average Loss: 0.0166\n",
            "\n",
            "Epoch 14/20\n",
            "------------------------------\n",
            "Batch 10/2573, Loss: 0.0120\n",
            "Batch 20/2573, Loss: 0.0205\n",
            "Batch 30/2573, Loss: 0.0194\n",
            "Batch 40/2573, Loss: 0.0127\n",
            "Batch 50/2573, Loss: 0.0120\n",
            "Batch 60/2573, Loss: 0.0082\n",
            "Batch 70/2573, Loss: 0.0159\n",
            "Batch 80/2573, Loss: 0.0114\n",
            "Batch 90/2573, Loss: 0.0706\n",
            "Batch 100/2573, Loss: 0.0318\n",
            "Batch 110/2573, Loss: 0.0126\n",
            "Batch 120/2573, Loss: 0.0094\n",
            "Batch 130/2573, Loss: 0.0174\n",
            "Batch 140/2573, Loss: 0.0170\n",
            "Batch 150/2573, Loss: 0.0054\n",
            "Batch 160/2573, Loss: 0.0069\n",
            "Batch 170/2573, Loss: 0.0139\n",
            "Batch 180/2573, Loss: 0.0098\n",
            "Batch 190/2573, Loss: 0.0237\n",
            "Batch 200/2573, Loss: 0.0113\n",
            "Batch 210/2573, Loss: 0.0090\n",
            "Batch 220/2573, Loss: 0.0213\n",
            "Batch 230/2573, Loss: 0.0050\n",
            "Batch 240/2573, Loss: 0.0076\n",
            "Batch 250/2573, Loss: 0.0211\n",
            "Batch 260/2573, Loss: 0.0125\n",
            "Batch 270/2573, Loss: 0.0127\n",
            "Batch 280/2573, Loss: 0.0176\n",
            "Batch 290/2573, Loss: 0.0113\n",
            "Batch 300/2573, Loss: 0.0203\n",
            "Batch 310/2573, Loss: 0.0247\n",
            "Batch 320/2573, Loss: 0.0062\n",
            "Batch 330/2573, Loss: 0.0149\n",
            "Batch 340/2573, Loss: 0.0046\n",
            "Batch 350/2573, Loss: 0.0152\n",
            "Batch 360/2573, Loss: 0.0063\n",
            "Batch 370/2573, Loss: 0.0232\n",
            "Batch 380/2573, Loss: 0.0089\n",
            "Batch 390/2573, Loss: 0.0253\n",
            "Batch 400/2573, Loss: 0.0170\n",
            "Batch 410/2573, Loss: 0.0119\n",
            "Batch 420/2573, Loss: 0.0147\n",
            "Batch 430/2573, Loss: 0.0114\n",
            "Batch 440/2573, Loss: 0.0117\n",
            "Batch 450/2573, Loss: 0.0146\n",
            "Batch 460/2573, Loss: 0.0222\n",
            "Batch 470/2573, Loss: 0.0173\n",
            "Batch 480/2573, Loss: 0.0128\n",
            "Batch 490/2573, Loss: 0.0130\n",
            "Batch 500/2573, Loss: 0.0080\n",
            "Batch 510/2573, Loss: 0.0141\n",
            "Batch 520/2573, Loss: 0.0197\n",
            "Batch 530/2573, Loss: 0.0070\n",
            "Batch 540/2573, Loss: 0.0113\n",
            "Batch 550/2573, Loss: 0.0169\n",
            "Batch 560/2573, Loss: 0.0175\n",
            "Batch 570/2573, Loss: 0.0113\n",
            "Batch 580/2573, Loss: 0.0450\n",
            "Batch 590/2573, Loss: 0.0135\n",
            "Batch 600/2573, Loss: 0.0076\n",
            "Batch 610/2573, Loss: 0.0140\n",
            "Batch 620/2573, Loss: 0.0141\n",
            "Batch 630/2573, Loss: 0.0120\n",
            "Batch 640/2573, Loss: 0.0348\n",
            "Batch 650/2573, Loss: 0.0079\n",
            "Batch 660/2573, Loss: 0.0200\n",
            "Batch 670/2573, Loss: 0.0087\n",
            "Batch 680/2573, Loss: 0.0235\n",
            "Batch 690/2573, Loss: 0.0295\n",
            "Batch 700/2573, Loss: 0.0146\n",
            "Batch 710/2573, Loss: 0.0213\n",
            "Batch 720/2573, Loss: 0.0107\n",
            "Batch 730/2573, Loss: 0.0281\n",
            "Batch 740/2573, Loss: 0.0232\n",
            "Batch 750/2573, Loss: 0.0160\n",
            "Batch 760/2573, Loss: 0.0072\n",
            "Batch 770/2573, Loss: 0.0096\n",
            "Batch 780/2573, Loss: 0.0083\n",
            "Batch 790/2573, Loss: 0.0081\n",
            "Batch 800/2573, Loss: 0.0075\n",
            "Batch 810/2573, Loss: 0.0063\n",
            "Batch 820/2573, Loss: 0.0448\n",
            "Batch 830/2573, Loss: 0.0197\n",
            "Batch 840/2573, Loss: 0.0076\n",
            "Batch 850/2573, Loss: 0.0069\n",
            "Batch 860/2573, Loss: 0.0126\n",
            "Batch 870/2573, Loss: 0.0247\n",
            "Batch 880/2573, Loss: 0.0094\n",
            "Batch 890/2573, Loss: 0.0179\n",
            "Batch 900/2573, Loss: 0.0116\n",
            "Batch 910/2573, Loss: 0.0425\n",
            "Batch 920/2573, Loss: 0.0104\n",
            "Batch 930/2573, Loss: 0.0068\n",
            "Batch 940/2573, Loss: 0.0089\n",
            "Batch 950/2573, Loss: 0.0240\n",
            "Batch 960/2573, Loss: 0.0213\n",
            "Batch 970/2573, Loss: 0.0088\n",
            "Batch 980/2573, Loss: 0.0300\n",
            "Batch 990/2573, Loss: 0.0238\n",
            "Batch 1000/2573, Loss: 0.0168\n",
            "Batch 1010/2573, Loss: 0.0111\n",
            "Batch 1020/2573, Loss: 0.0378\n",
            "Batch 1030/2573, Loss: 0.0053\n",
            "Batch 1040/2573, Loss: 0.0104\n",
            "Batch 1050/2573, Loss: 0.0204\n",
            "Batch 1060/2573, Loss: 0.0076\n",
            "Batch 1070/2573, Loss: 0.0052\n",
            "Batch 1080/2573, Loss: 0.0158\n",
            "Batch 1090/2573, Loss: 0.0209\n",
            "Batch 1100/2573, Loss: 0.0242\n",
            "Batch 1110/2573, Loss: 0.0144\n",
            "Batch 1120/2573, Loss: 0.0128\n",
            "Batch 1130/2573, Loss: 0.0108\n",
            "Batch 1140/2573, Loss: 0.0119\n",
            "Batch 1150/2573, Loss: 0.0168\n",
            "Batch 1160/2573, Loss: 0.0084\n",
            "Batch 1170/2573, Loss: 0.0095\n",
            "Batch 1180/2573, Loss: 0.0118\n",
            "Batch 1190/2573, Loss: 0.0086\n",
            "Batch 1200/2573, Loss: 0.0169\n",
            "Batch 1210/2573, Loss: 0.0123\n",
            "Batch 1220/2573, Loss: 0.0195\n",
            "Batch 1230/2573, Loss: 0.0162\n",
            "Batch 1240/2573, Loss: 0.0076\n",
            "Batch 1250/2573, Loss: 0.0304\n",
            "Batch 1260/2573, Loss: 0.0213\n",
            "Batch 1270/2573, Loss: 0.0320\n",
            "Batch 1280/2573, Loss: 0.0042\n",
            "Batch 1290/2573, Loss: 0.0153\n",
            "Batch 1300/2573, Loss: 0.0358\n",
            "Batch 1310/2573, Loss: 0.0163\n",
            "Batch 1320/2573, Loss: 0.0108\n",
            "Batch 1330/2573, Loss: 0.0118\n",
            "Batch 1340/2573, Loss: 0.0144\n",
            "Batch 1350/2573, Loss: 0.0155\n",
            "Batch 1360/2573, Loss: 0.0154\n",
            "Batch 1370/2573, Loss: 0.0075\n",
            "Batch 1380/2573, Loss: 0.0047\n",
            "Batch 1390/2573, Loss: 0.0209\n",
            "Batch 1400/2573, Loss: 0.0125\n",
            "Batch 1410/2573, Loss: 0.0331\n",
            "Batch 1420/2573, Loss: 0.0115\n",
            "Batch 1430/2573, Loss: 0.0115\n",
            "Batch 1440/2573, Loss: 0.0301\n",
            "Batch 1450/2573, Loss: 0.0125\n",
            "Batch 1460/2573, Loss: 0.0145\n",
            "Batch 1470/2573, Loss: 0.0136\n",
            "Batch 1480/2573, Loss: 0.0211\n",
            "Batch 1490/2573, Loss: 0.0135\n",
            "Batch 1500/2573, Loss: 0.0164\n",
            "Batch 1510/2573, Loss: 0.0078\n",
            "Batch 1520/2573, Loss: 0.0035\n",
            "Batch 1530/2573, Loss: 0.0364\n",
            "Batch 1540/2573, Loss: 0.0064\n",
            "Batch 1550/2573, Loss: 0.0125\n",
            "Batch 1560/2573, Loss: 0.0143\n",
            "Batch 1570/2573, Loss: 0.0106\n",
            "Batch 1580/2573, Loss: 0.0278\n",
            "Batch 1590/2573, Loss: 0.0074\n",
            "Batch 1600/2573, Loss: 0.0108\n",
            "Batch 1610/2573, Loss: 0.0156\n",
            "Batch 1620/2573, Loss: 0.0096\n",
            "Batch 1630/2573, Loss: 0.0258\n",
            "Batch 1640/2573, Loss: 0.0151\n",
            "Batch 1650/2573, Loss: 0.0163\n",
            "Batch 1660/2573, Loss: 0.0081\n",
            "Batch 1670/2573, Loss: 0.0105\n",
            "Batch 1680/2573, Loss: 0.0079\n",
            "Batch 1690/2573, Loss: 0.0149\n",
            "Batch 1700/2573, Loss: 0.0221\n",
            "Batch 1710/2573, Loss: 0.0093\n",
            "Batch 1720/2573, Loss: 0.0168\n",
            "Batch 1730/2573, Loss: 0.0047\n",
            "Batch 1740/2573, Loss: 0.0177\n",
            "Batch 1750/2573, Loss: 0.0076\n",
            "Batch 1760/2573, Loss: 0.0092\n",
            "Batch 1770/2573, Loss: 0.0076\n",
            "Batch 1780/2573, Loss: 0.0170\n",
            "Batch 1790/2573, Loss: 0.0115\n",
            "Batch 1800/2573, Loss: 0.0183\n",
            "Batch 1810/2573, Loss: 0.0334\n",
            "Batch 1820/2573, Loss: 0.0243\n",
            "Batch 1830/2573, Loss: 0.0199\n",
            "Batch 1840/2573, Loss: 0.0108\n",
            "Batch 1850/2573, Loss: 0.0231\n",
            "Batch 1860/2573, Loss: 0.0116\n",
            "Batch 1870/2573, Loss: 0.0125\n",
            "Batch 1880/2573, Loss: 0.0179\n",
            "Batch 1890/2573, Loss: 0.0242\n",
            "Batch 1900/2573, Loss: 0.0112\n",
            "Batch 1910/2573, Loss: 0.0279\n",
            "Batch 1920/2573, Loss: 0.0246\n",
            "Batch 1930/2573, Loss: 0.0094\n",
            "Batch 1940/2573, Loss: 0.0210\n",
            "Batch 1950/2573, Loss: 0.0291\n",
            "Batch 1960/2573, Loss: 0.0123\n",
            "Batch 1970/2573, Loss: 0.0082\n",
            "Batch 1980/2573, Loss: 0.0155\n",
            "Batch 1990/2573, Loss: 0.0092\n",
            "Batch 2000/2573, Loss: 0.0198\n",
            "Batch 2010/2573, Loss: 0.0189\n",
            "Batch 2020/2573, Loss: 0.0297\n",
            "Batch 2030/2573, Loss: 0.0299\n",
            "Batch 2040/2573, Loss: 0.0160\n",
            "Batch 2050/2573, Loss: 0.0112\n",
            "Batch 2060/2573, Loss: 0.0121\n",
            "Batch 2070/2573, Loss: 0.0262\n",
            "Batch 2080/2573, Loss: 0.0113\n",
            "Batch 2090/2573, Loss: 0.0320\n",
            "Batch 2100/2573, Loss: 0.0102\n",
            "Batch 2110/2573, Loss: 0.0116\n",
            "Batch 2120/2573, Loss: 0.0144\n",
            "Batch 2130/2573, Loss: 0.0207\n",
            "Batch 2140/2573, Loss: 0.0270\n",
            "Batch 2150/2573, Loss: 0.0240\n",
            "Batch 2160/2573, Loss: 0.0068\n",
            "Batch 2170/2573, Loss: 0.0193\n",
            "Batch 2180/2573, Loss: 0.0306\n",
            "Batch 2190/2573, Loss: 0.0250\n",
            "Batch 2200/2573, Loss: 0.0130\n",
            "Batch 2210/2573, Loss: 0.0152\n",
            "Batch 2220/2573, Loss: 0.0075\n",
            "Batch 2230/2573, Loss: 0.0280\n",
            "Batch 2240/2573, Loss: 0.0094\n",
            "Batch 2250/2573, Loss: 0.0113\n",
            "Batch 2260/2573, Loss: 0.0112\n",
            "Batch 2270/2573, Loss: 0.0074\n",
            "Batch 2280/2573, Loss: 0.0246\n",
            "Batch 2290/2573, Loss: 0.0106\n",
            "Batch 2300/2573, Loss: 0.0132\n",
            "Batch 2310/2573, Loss: 0.0134\n",
            "Batch 2320/2573, Loss: 0.0096\n",
            "Batch 2330/2573, Loss: 0.0187\n",
            "Batch 2340/2573, Loss: 0.0293\n",
            "Batch 2350/2573, Loss: 0.0237\n",
            "Batch 2360/2573, Loss: 0.0164\n",
            "Batch 2370/2573, Loss: 0.0075\n",
            "Batch 2380/2573, Loss: 0.0110\n",
            "Batch 2390/2573, Loss: 0.0123\n",
            "Batch 2400/2573, Loss: 0.0220\n",
            "Batch 2410/2573, Loss: 0.0104\n",
            "Batch 2420/2573, Loss: 0.0172\n",
            "Batch 2430/2573, Loss: 0.0081\n",
            "Batch 2440/2573, Loss: 0.0099\n",
            "Batch 2450/2573, Loss: 0.0098\n",
            "Batch 2460/2573, Loss: 0.0235\n",
            "Batch 2470/2573, Loss: 0.0192\n",
            "Batch 2480/2573, Loss: 0.0159\n",
            "Batch 2490/2573, Loss: 0.0491\n",
            "Batch 2500/2573, Loss: 0.0104\n",
            "Batch 2510/2573, Loss: 0.0283\n",
            "Batch 2520/2573, Loss: 0.0191\n",
            "Batch 2530/2573, Loss: 0.0097\n",
            "Batch 2540/2573, Loss: 0.0197\n",
            "Batch 2550/2573, Loss: 0.0153\n",
            "Batch 2560/2573, Loss: 0.0125\n",
            "Batch 2570/2573, Loss: 0.0302\n",
            "Epoch 14 Average Loss: 0.0162\n",
            "\n",
            "Epoch 15/20\n",
            "------------------------------\n",
            "Batch 10/2573, Loss: 0.0024\n",
            "Batch 20/2573, Loss: 0.0064\n",
            "Batch 30/2573, Loss: 0.0273\n",
            "Batch 40/2573, Loss: 0.0290\n",
            "Batch 50/2573, Loss: 0.0085\n",
            "Batch 60/2573, Loss: 0.0146\n",
            "Batch 70/2573, Loss: 0.0375\n",
            "Batch 80/2573, Loss: 0.0118\n",
            "Batch 90/2573, Loss: 0.0066\n",
            "Batch 100/2573, Loss: 0.0121\n",
            "Batch 110/2573, Loss: 0.0069\n",
            "Batch 120/2573, Loss: 0.0142\n",
            "Batch 130/2573, Loss: 0.0425\n",
            "Batch 140/2573, Loss: 0.0164\n",
            "Batch 150/2573, Loss: 0.0082\n",
            "Batch 160/2573, Loss: 0.0107\n",
            "Batch 170/2573, Loss: 0.0220\n",
            "Batch 180/2573, Loss: 0.0230\n",
            "Batch 190/2573, Loss: 0.0091\n",
            "Batch 200/2573, Loss: 0.0096\n",
            "Batch 210/2573, Loss: 0.0071\n",
            "Batch 220/2573, Loss: 0.0185\n",
            "Batch 230/2573, Loss: 0.0176\n",
            "Batch 240/2573, Loss: 0.0090\n",
            "Batch 250/2573, Loss: 0.0254\n",
            "Batch 260/2573, Loss: 0.0244\n",
            "Batch 270/2573, Loss: 0.0155\n",
            "Batch 280/2573, Loss: 0.0116\n",
            "Batch 290/2573, Loss: 0.0174\n",
            "Batch 300/2573, Loss: 0.0138\n",
            "Batch 310/2573, Loss: 0.0144\n",
            "Batch 320/2573, Loss: 0.0124\n",
            "Batch 330/2573, Loss: 0.0147\n",
            "Batch 340/2573, Loss: 0.0138\n",
            "Batch 350/2573, Loss: 0.0064\n",
            "Batch 360/2573, Loss: 0.0211\n",
            "Batch 370/2573, Loss: 0.0459\n",
            "Batch 380/2573, Loss: 0.0203\n",
            "Batch 390/2573, Loss: 0.0106\n",
            "Batch 400/2573, Loss: 0.0087\n",
            "Batch 410/2573, Loss: 0.0098\n",
            "Batch 420/2573, Loss: 0.0224\n",
            "Batch 430/2573, Loss: 0.0356\n",
            "Batch 440/2573, Loss: 0.0121\n",
            "Batch 450/2573, Loss: 0.0068\n",
            "Batch 460/2573, Loss: 0.0080\n",
            "Batch 470/2573, Loss: 0.0091\n",
            "Batch 480/2573, Loss: 0.0142\n",
            "Batch 490/2573, Loss: 0.0034\n",
            "Batch 500/2573, Loss: 0.0138\n",
            "Batch 510/2573, Loss: 0.0064\n",
            "Batch 520/2573, Loss: 0.0078\n",
            "Batch 530/2573, Loss: 0.0291\n",
            "Batch 540/2573, Loss: 0.0174\n",
            "Batch 550/2573, Loss: 0.0132\n",
            "Batch 560/2573, Loss: 0.0110\n",
            "Batch 570/2573, Loss: 0.0180\n",
            "Batch 580/2573, Loss: 0.0191\n",
            "Batch 590/2573, Loss: 0.0230\n",
            "Batch 600/2573, Loss: 0.0252\n",
            "Batch 610/2573, Loss: 0.0140\n",
            "Batch 620/2573, Loss: 0.0147\n",
            "Batch 630/2573, Loss: 0.0132\n",
            "Batch 640/2573, Loss: 0.0148\n",
            "Batch 650/2573, Loss: 0.0149\n",
            "Batch 660/2573, Loss: 0.0078\n",
            "Batch 670/2573, Loss: 0.0140\n",
            "Batch 680/2573, Loss: 0.0071\n",
            "Batch 690/2573, Loss: 0.0267\n",
            "Batch 700/2573, Loss: 0.0068\n",
            "Batch 710/2573, Loss: 0.0122\n",
            "Batch 720/2573, Loss: 0.0172\n",
            "Batch 730/2573, Loss: 0.0355\n",
            "Batch 740/2573, Loss: 0.0024\n",
            "Batch 750/2573, Loss: 0.0207\n",
            "Batch 760/2573, Loss: 0.0098\n",
            "Batch 770/2573, Loss: 0.0207\n",
            "Batch 780/2573, Loss: 0.0125\n",
            "Batch 790/2573, Loss: 0.0056\n",
            "Batch 800/2573, Loss: 0.0246\n",
            "Batch 810/2573, Loss: 0.0215\n",
            "Batch 820/2573, Loss: 0.0327\n",
            "Batch 830/2573, Loss: 0.0220\n",
            "Batch 840/2573, Loss: 0.0132\n",
            "Batch 850/2573, Loss: 0.0154\n",
            "Batch 860/2573, Loss: 0.0186\n",
            "Batch 870/2573, Loss: 0.0260\n",
            "Batch 880/2573, Loss: 0.0168\n",
            "Batch 890/2573, Loss: 0.0082\n",
            "Batch 900/2573, Loss: 0.0138\n",
            "Batch 910/2573, Loss: 0.0146\n",
            "Batch 920/2573, Loss: 0.0121\n",
            "Batch 930/2573, Loss: 0.0099\n",
            "Batch 940/2573, Loss: 0.0126\n",
            "Batch 950/2573, Loss: 0.0094\n",
            "Batch 960/2573, Loss: 0.0063\n",
            "Batch 970/2573, Loss: 0.0143\n",
            "Batch 980/2573, Loss: 0.0287\n",
            "Batch 990/2573, Loss: 0.0181\n",
            "Batch 1000/2573, Loss: 0.0062\n",
            "Batch 1010/2573, Loss: 0.0183\n",
            "Batch 1020/2573, Loss: 0.0150\n",
            "Batch 1030/2573, Loss: 0.0179\n",
            "Batch 1040/2573, Loss: 0.0137\n",
            "Batch 1050/2573, Loss: 0.0188\n",
            "Batch 1060/2573, Loss: 0.0042\n",
            "Batch 1070/2573, Loss: 0.0094\n",
            "Batch 1080/2573, Loss: 0.0073\n",
            "Batch 1090/2573, Loss: 0.0095\n",
            "Batch 1100/2573, Loss: 0.0455\n",
            "Batch 1110/2573, Loss: 0.0131\n",
            "Batch 1120/2573, Loss: 0.0256\n",
            "Batch 1130/2573, Loss: 0.0231\n",
            "Batch 1140/2573, Loss: 0.0171\n",
            "Batch 1150/2573, Loss: 0.0045\n",
            "Batch 1160/2573, Loss: 0.0077\n",
            "Batch 1170/2573, Loss: 0.0057\n",
            "Batch 1180/2573, Loss: 0.0234\n",
            "Batch 1190/2573, Loss: 0.0057\n",
            "Batch 1200/2573, Loss: 0.0193\n",
            "Batch 1210/2573, Loss: 0.0151\n",
            "Batch 1220/2573, Loss: 0.0143\n",
            "Batch 1230/2573, Loss: 0.0124\n",
            "Batch 1240/2573, Loss: 0.0183\n",
            "Batch 1250/2573, Loss: 0.0105\n",
            "Batch 1260/2573, Loss: 0.0070\n",
            "Batch 1270/2573, Loss: 0.0252\n",
            "Batch 1280/2573, Loss: 0.0192\n",
            "Batch 1290/2573, Loss: 0.0164\n",
            "Batch 1300/2573, Loss: 0.0097\n",
            "Batch 1310/2573, Loss: 0.0259\n",
            "Batch 1320/2573, Loss: 0.0308\n",
            "Batch 1330/2573, Loss: 0.0147\n",
            "Batch 1340/2573, Loss: 0.0156\n",
            "Batch 1350/2573, Loss: 0.0060\n",
            "Batch 1360/2573, Loss: 0.0087\n",
            "Batch 1370/2573, Loss: 0.0154\n",
            "Batch 1380/2573, Loss: 0.0144\n",
            "Batch 1390/2573, Loss: 0.0629\n",
            "Batch 1400/2573, Loss: 0.0078\n",
            "Batch 1410/2573, Loss: 0.0093\n",
            "Batch 1420/2573, Loss: 0.0192\n",
            "Batch 1430/2573, Loss: 0.0190\n",
            "Batch 1440/2573, Loss: 0.0105\n",
            "Batch 1450/2573, Loss: 0.0438\n",
            "Batch 1460/2573, Loss: 0.0070\n",
            "Batch 1470/2573, Loss: 0.0163\n",
            "Batch 1480/2573, Loss: 0.0334\n",
            "Batch 1490/2573, Loss: 0.0213\n",
            "Batch 1500/2573, Loss: 0.0322\n",
            "Batch 1510/2573, Loss: 0.0117\n",
            "Batch 1520/2573, Loss: 0.0085\n",
            "Batch 1530/2573, Loss: 0.0373\n",
            "Batch 1540/2573, Loss: 0.0106\n",
            "Batch 1550/2573, Loss: 0.0160\n",
            "Batch 1560/2573, Loss: 0.0097\n",
            "Batch 1570/2573, Loss: 0.0115\n",
            "Batch 1580/2573, Loss: 0.0224\n",
            "Batch 1590/2573, Loss: 0.0161\n",
            "Batch 1600/2573, Loss: 0.0279\n",
            "Batch 1610/2573, Loss: 0.0053\n",
            "Batch 1620/2573, Loss: 0.0226\n",
            "Batch 1630/2573, Loss: 0.0259\n",
            "Batch 1640/2573, Loss: 0.0318\n",
            "Batch 1650/2573, Loss: 0.0164\n",
            "Batch 1660/2573, Loss: 0.0139\n",
            "Batch 1670/2573, Loss: 0.0047\n",
            "Batch 1680/2573, Loss: 0.0152\n",
            "Batch 1690/2573, Loss: 0.0084\n",
            "Batch 1700/2573, Loss: 0.0095\n",
            "Batch 1710/2573, Loss: 0.0160\n",
            "Batch 1720/2573, Loss: 0.0203\n",
            "Batch 1730/2573, Loss: 0.0221\n",
            "Batch 1740/2573, Loss: 0.0159\n",
            "Batch 1750/2573, Loss: 0.0130\n",
            "Batch 1760/2573, Loss: 0.0079\n",
            "Batch 1770/2573, Loss: 0.0108\n",
            "Batch 1780/2573, Loss: 0.0175\n",
            "Batch 1790/2573, Loss: 0.0082\n",
            "Batch 1800/2573, Loss: 0.0090\n",
            "Batch 1810/2573, Loss: 0.0107\n",
            "Batch 1820/2573, Loss: 0.0111\n",
            "Batch 1830/2573, Loss: 0.0152\n",
            "Batch 1840/2573, Loss: 0.0219\n",
            "Batch 1850/2573, Loss: 0.0353\n",
            "Batch 1860/2573, Loss: 0.0158\n",
            "Batch 1870/2573, Loss: 0.0171\n",
            "Batch 1880/2573, Loss: 0.0122\n",
            "Batch 1890/2573, Loss: 0.0519\n",
            "Batch 1900/2573, Loss: 0.0068\n",
            "Batch 1910/2573, Loss: 0.0115\n",
            "Batch 1920/2573, Loss: 0.0075\n",
            "Batch 1930/2573, Loss: 0.0077\n",
            "Batch 1940/2573, Loss: 0.0073\n",
            "Batch 1950/2573, Loss: 0.0056\n",
            "Batch 1960/2573, Loss: 0.0580\n",
            "Batch 1970/2573, Loss: 0.0134\n",
            "Batch 1980/2573, Loss: 0.0071\n",
            "Batch 1990/2573, Loss: 0.0221\n",
            "Batch 2000/2573, Loss: 0.0130\n",
            "Batch 2010/2573, Loss: 0.0163\n",
            "Batch 2020/2573, Loss: 0.0104\n",
            "Batch 2030/2573, Loss: 0.0157\n",
            "Batch 2040/2573, Loss: 0.0277\n",
            "Batch 2050/2573, Loss: 0.0129\n",
            "Batch 2060/2573, Loss: 0.0071\n",
            "Batch 2070/2573, Loss: 0.0117\n",
            "Batch 2080/2573, Loss: 0.0195\n",
            "Batch 2090/2573, Loss: 0.0057\n",
            "Batch 2100/2573, Loss: 0.0158\n",
            "Batch 2110/2573, Loss: 0.0191\n",
            "Batch 2120/2573, Loss: 0.0260\n",
            "Batch 2130/2573, Loss: 0.0055\n",
            "Batch 2140/2573, Loss: 0.0310\n",
            "Batch 2150/2573, Loss: 0.0071\n",
            "Batch 2160/2573, Loss: 0.0240\n",
            "Batch 2170/2573, Loss: 0.0042\n",
            "Batch 2180/2573, Loss: 0.0136\n",
            "Batch 2190/2573, Loss: 0.0219\n",
            "Batch 2200/2573, Loss: 0.0122\n",
            "Batch 2210/2573, Loss: 0.0131\n",
            "Batch 2220/2573, Loss: 0.0236\n",
            "Batch 2230/2573, Loss: 0.0047\n",
            "Batch 2240/2573, Loss: 0.0125\n",
            "Batch 2250/2573, Loss: 0.0285\n",
            "Batch 2260/2573, Loss: 0.0148\n",
            "Batch 2270/2573, Loss: 0.0167\n",
            "Batch 2280/2573, Loss: 0.0330\n",
            "Batch 2290/2573, Loss: 0.0057\n",
            "Batch 2300/2573, Loss: 0.0140\n",
            "Batch 2310/2573, Loss: 0.0158\n",
            "Batch 2320/2573, Loss: 0.0254\n",
            "Batch 2330/2573, Loss: 0.0148\n",
            "Batch 2340/2573, Loss: 0.0137\n",
            "Batch 2350/2573, Loss: 0.0152\n",
            "Batch 2360/2573, Loss: 0.0190\n",
            "Batch 2370/2573, Loss: 0.0158\n",
            "Batch 2380/2573, Loss: 0.0191\n",
            "Batch 2390/2573, Loss: 0.0162\n",
            "Batch 2400/2573, Loss: 0.0251\n",
            "Batch 2410/2573, Loss: 0.0129\n",
            "Batch 2420/2573, Loss: 0.0120\n",
            "Batch 2430/2573, Loss: 0.0363\n",
            "Batch 2440/2573, Loss: 0.0168\n",
            "Batch 2450/2573, Loss: 0.0083\n",
            "Batch 2460/2573, Loss: 0.0220\n",
            "Batch 2470/2573, Loss: 0.0121\n",
            "Batch 2480/2573, Loss: 0.0157\n",
            "Batch 2490/2573, Loss: 0.0151\n",
            "Batch 2500/2573, Loss: 0.0058\n",
            "Batch 2510/2573, Loss: 0.0300\n",
            "Batch 2520/2573, Loss: 0.0145\n",
            "Batch 2530/2573, Loss: 0.0143\n",
            "Batch 2540/2573, Loss: 0.0146\n",
            "Batch 2550/2573, Loss: 0.0091\n",
            "Batch 2560/2573, Loss: 0.0240\n",
            "Batch 2570/2573, Loss: 0.0052\n",
            "Epoch 15 Average Loss: 0.0160\n",
            "\n",
            "Epoch 16/20\n",
            "------------------------------\n",
            "Batch 10/2573, Loss: 0.0066\n",
            "Batch 20/2573, Loss: 0.0082\n",
            "Batch 30/2573, Loss: 0.0149\n",
            "Batch 40/2573, Loss: 0.0088\n",
            "Batch 50/2573, Loss: 0.0229\n",
            "Batch 60/2573, Loss: 0.0166\n",
            "Batch 70/2573, Loss: 0.0088\n",
            "Batch 80/2573, Loss: 0.0196\n",
            "Batch 90/2573, Loss: 0.0222\n",
            "Batch 100/2573, Loss: 0.0144\n",
            "Batch 110/2573, Loss: 0.0033\n",
            "Batch 120/2573, Loss: 0.0128\n",
            "Batch 130/2573, Loss: 0.0175\n",
            "Batch 140/2573, Loss: 0.0152\n",
            "Batch 150/2573, Loss: 0.0188\n",
            "Batch 160/2573, Loss: 0.0163\n",
            "Batch 170/2573, Loss: 0.0466\n",
            "Batch 180/2573, Loss: 0.0107\n",
            "Batch 190/2573, Loss: 0.0047\n",
            "Batch 200/2573, Loss: 0.0196\n",
            "Batch 210/2573, Loss: 0.0117\n",
            "Batch 220/2573, Loss: 0.0172\n",
            "Batch 230/2573, Loss: 0.0054\n",
            "Batch 240/2573, Loss: 0.0178\n",
            "Batch 250/2573, Loss: 0.0089\n",
            "Batch 260/2573, Loss: 0.0087\n",
            "Batch 270/2573, Loss: 0.0250\n",
            "Batch 280/2573, Loss: 0.0107\n",
            "Batch 290/2573, Loss: 0.0152\n",
            "Batch 300/2573, Loss: 0.0210\n",
            "Batch 310/2573, Loss: 0.0098\n",
            "Batch 320/2573, Loss: 0.0343\n",
            "Batch 330/2573, Loss: 0.0101\n",
            "Batch 340/2573, Loss: 0.0326\n",
            "Batch 350/2573, Loss: 0.0109\n",
            "Batch 360/2573, Loss: 0.0130\n",
            "Batch 370/2573, Loss: 0.0132\n",
            "Batch 380/2573, Loss: 0.0147\n",
            "Batch 390/2573, Loss: 0.0033\n",
            "Batch 400/2573, Loss: 0.0062\n",
            "Batch 410/2573, Loss: 0.0149\n",
            "Batch 420/2573, Loss: 0.0060\n",
            "Batch 430/2573, Loss: 0.0066\n",
            "Batch 440/2573, Loss: 0.0343\n",
            "Batch 450/2573, Loss: 0.0134\n",
            "Batch 460/2573, Loss: 0.0171\n",
            "Batch 470/2573, Loss: 0.0262\n",
            "Batch 480/2573, Loss: 0.0126\n",
            "Batch 490/2573, Loss: 0.0120\n",
            "Batch 500/2573, Loss: 0.0095\n",
            "Batch 510/2573, Loss: 0.0151\n",
            "Batch 520/2573, Loss: 0.0307\n",
            "Batch 530/2573, Loss: 0.0102\n",
            "Batch 540/2573, Loss: 0.0183\n",
            "Batch 550/2573, Loss: 0.0083\n",
            "Batch 560/2573, Loss: 0.0118\n",
            "Batch 570/2573, Loss: 0.0174\n",
            "Batch 580/2573, Loss: 0.0160\n",
            "Batch 590/2573, Loss: 0.0323\n",
            "Batch 600/2573, Loss: 0.0138\n",
            "Batch 610/2573, Loss: 0.0131\n",
            "Batch 620/2573, Loss: 0.0103\n",
            "Batch 630/2573, Loss: 0.0082\n",
            "Batch 640/2573, Loss: 0.0076\n",
            "Batch 650/2573, Loss: 0.0150\n",
            "Batch 660/2573, Loss: 0.0091\n",
            "Batch 670/2573, Loss: 0.0079\n",
            "Batch 680/2573, Loss: 0.0333\n",
            "Batch 690/2573, Loss: 0.0124\n",
            "Batch 700/2573, Loss: 0.0262\n",
            "Batch 710/2573, Loss: 0.0153\n",
            "Batch 720/2573, Loss: 0.0087\n",
            "Batch 730/2573, Loss: 0.0081\n",
            "Batch 740/2573, Loss: 0.0174\n",
            "Batch 750/2573, Loss: 0.0114\n",
            "Batch 760/2573, Loss: 0.0175\n",
            "Batch 770/2573, Loss: 0.0092\n",
            "Batch 780/2573, Loss: 0.0207\n",
            "Batch 790/2573, Loss: 0.0251\n",
            "Batch 800/2573, Loss: 0.0186\n",
            "Batch 810/2573, Loss: 0.0094\n",
            "Batch 820/2573, Loss: 0.0134\n",
            "Batch 830/2573, Loss: 0.0203\n",
            "Batch 840/2573, Loss: 0.0258\n",
            "Batch 850/2573, Loss: 0.0063\n",
            "Batch 860/2573, Loss: 0.0203\n",
            "Batch 870/2573, Loss: 0.0178\n",
            "Batch 880/2573, Loss: 0.0241\n",
            "Batch 890/2573, Loss: 0.0046\n",
            "Batch 900/2573, Loss: 0.0446\n",
            "Batch 910/2573, Loss: 0.0255\n",
            "Batch 920/2573, Loss: 0.0220\n",
            "Batch 930/2573, Loss: 0.0151\n",
            "Batch 940/2573, Loss: 0.0141\n",
            "Batch 950/2573, Loss: 0.0066\n",
            "Batch 960/2573, Loss: 0.0126\n",
            "Batch 970/2573, Loss: 0.0103\n",
            "Batch 980/2573, Loss: 0.0315\n",
            "Batch 990/2573, Loss: 0.0083\n",
            "Batch 1000/2573, Loss: 0.0215\n",
            "Batch 1010/2573, Loss: 0.0123\n",
            "Batch 1020/2573, Loss: 0.0220\n",
            "Batch 1030/2573, Loss: 0.0046\n",
            "Batch 1040/2573, Loss: 0.0123\n",
            "Batch 1050/2573, Loss: 0.0129\n",
            "Batch 1060/2573, Loss: 0.0134\n",
            "Batch 1070/2573, Loss: 0.0092\n",
            "Batch 1080/2573, Loss: 0.0114\n",
            "Batch 1090/2573, Loss: 0.0095\n",
            "Batch 1100/2573, Loss: 0.0234\n",
            "Batch 1110/2573, Loss: 0.0211\n",
            "Batch 1120/2573, Loss: 0.0270\n",
            "Batch 1130/2573, Loss: 0.0227\n",
            "Batch 1140/2573, Loss: 0.0074\n",
            "Batch 1150/2573, Loss: 0.0114\n",
            "Batch 1160/2573, Loss: 0.0167\n",
            "Batch 1170/2573, Loss: 0.0304\n",
            "Batch 1180/2573, Loss: 0.0324\n",
            "Batch 1190/2573, Loss: 0.0181\n",
            "Batch 1200/2573, Loss: 0.0204\n",
            "Batch 1210/2573, Loss: 0.0113\n",
            "Batch 1220/2573, Loss: 0.0191\n",
            "Batch 1230/2573, Loss: 0.0238\n",
            "Batch 1240/2573, Loss: 0.0109\n",
            "Batch 1250/2573, Loss: 0.0308\n",
            "Batch 1260/2573, Loss: 0.0166\n",
            "Batch 1270/2573, Loss: 0.0181\n",
            "Batch 1280/2573, Loss: 0.0091\n",
            "Batch 1290/2573, Loss: 0.0070\n",
            "Batch 1300/2573, Loss: 0.0142\n",
            "Batch 1310/2573, Loss: 0.0162\n",
            "Batch 1320/2573, Loss: 0.0163\n",
            "Batch 1330/2573, Loss: 0.0215\n",
            "Batch 1340/2573, Loss: 0.0178\n",
            "Batch 1350/2573, Loss: 0.0129\n",
            "Batch 1360/2573, Loss: 0.0205\n",
            "Batch 1370/2573, Loss: 0.0274\n",
            "Batch 1380/2573, Loss: 0.0152\n",
            "Batch 1390/2573, Loss: 0.0057\n",
            "Batch 1400/2573, Loss: 0.0057\n",
            "Batch 1410/2573, Loss: 0.0098\n",
            "Batch 1420/2573, Loss: 0.0227\n",
            "Batch 1430/2573, Loss: 0.0039\n",
            "Batch 1440/2573, Loss: 0.0181\n",
            "Batch 1450/2573, Loss: 0.0022\n",
            "Batch 1460/2573, Loss: 0.0137\n",
            "Batch 1470/2573, Loss: 0.0075\n",
            "Batch 1480/2573, Loss: 0.0087\n",
            "Batch 1490/2573, Loss: 0.0083\n",
            "Batch 1500/2573, Loss: 0.0159\n",
            "Batch 1510/2573, Loss: 0.0335\n",
            "Batch 1520/2573, Loss: 0.0170\n",
            "Batch 1530/2573, Loss: 0.0101\n",
            "Batch 1540/2573, Loss: 0.0138\n",
            "Batch 1550/2573, Loss: 0.0117\n",
            "Batch 1560/2573, Loss: 0.0128\n",
            "Batch 1570/2573, Loss: 0.0079\n",
            "Batch 1580/2573, Loss: 0.0160\n",
            "Batch 1590/2573, Loss: 0.0115\n",
            "Batch 1600/2573, Loss: 0.0129\n",
            "Batch 1610/2573, Loss: 0.0195\n",
            "Batch 1620/2573, Loss: 0.0373\n",
            "Batch 1630/2573, Loss: 0.0117\n",
            "Batch 1640/2573, Loss: 0.0213\n",
            "Batch 1650/2573, Loss: 0.0239\n",
            "Batch 1660/2573, Loss: 0.0354\n",
            "Batch 1670/2573, Loss: 0.0084\n",
            "Batch 1680/2573, Loss: 0.0111\n",
            "Batch 1690/2573, Loss: 0.0151\n",
            "Batch 1700/2573, Loss: 0.0080\n",
            "Batch 1710/2573, Loss: 0.0133\n",
            "Batch 1720/2573, Loss: 0.0388\n",
            "Batch 1730/2573, Loss: 0.0097\n",
            "Batch 1740/2573, Loss: 0.0140\n",
            "Batch 1750/2573, Loss: 0.0150\n",
            "Batch 1760/2573, Loss: 0.0115\n",
            "Batch 1770/2573, Loss: 0.0222\n",
            "Batch 1780/2573, Loss: 0.0133\n",
            "Batch 1790/2573, Loss: 0.0295\n",
            "Batch 1800/2573, Loss: 0.0072\n",
            "Batch 1810/2573, Loss: 0.0093\n",
            "Batch 1820/2573, Loss: 0.0090\n",
            "Batch 1830/2573, Loss: 0.0111\n",
            "Batch 1840/2573, Loss: 0.0117\n",
            "Batch 1850/2573, Loss: 0.0178\n",
            "Batch 1860/2573, Loss: 0.0217\n",
            "Batch 1870/2573, Loss: 0.0105\n",
            "Batch 1880/2573, Loss: 0.0082\n",
            "Batch 1890/2573, Loss: 0.0188\n",
            "Batch 1900/2573, Loss: 0.0122\n",
            "Batch 1910/2573, Loss: 0.0061\n",
            "Batch 1920/2573, Loss: 0.0098\n",
            "Batch 1930/2573, Loss: 0.0102\n",
            "Batch 1940/2573, Loss: 0.0154\n",
            "Batch 1950/2573, Loss: 0.0205\n",
            "Batch 1960/2573, Loss: 0.0066\n",
            "Batch 1970/2573, Loss: 0.0116\n",
            "Batch 1980/2573, Loss: 0.0071\n",
            "Batch 1990/2573, Loss: 0.0211\n",
            "Batch 2000/2573, Loss: 0.0126\n",
            "Batch 2010/2573, Loss: 0.0093\n",
            "Batch 2020/2573, Loss: 0.0136\n",
            "Batch 2030/2573, Loss: 0.0148\n",
            "Batch 2040/2573, Loss: 0.0109\n",
            "Batch 2050/2573, Loss: 0.0061\n",
            "Batch 2060/2573, Loss: 0.0180\n",
            "Batch 2070/2573, Loss: 0.0186\n",
            "Batch 2080/2573, Loss: 0.0075\n",
            "Batch 2090/2573, Loss: 0.0147\n",
            "Batch 2100/2573, Loss: 0.0254\n",
            "Batch 2110/2573, Loss: 0.0107\n",
            "Batch 2120/2573, Loss: 0.0092\n",
            "Batch 2130/2573, Loss: 0.0100\n",
            "Batch 2140/2573, Loss: 0.0195\n",
            "Batch 2150/2573, Loss: 0.0114\n",
            "Batch 2160/2573, Loss: 0.0074\n",
            "Batch 2170/2573, Loss: 0.0144\n",
            "Batch 2180/2573, Loss: 0.0121\n",
            "Batch 2190/2573, Loss: 0.0108\n",
            "Batch 2200/2573, Loss: 0.0105\n",
            "Batch 2210/2573, Loss: 0.0142\n",
            "Batch 2220/2573, Loss: 0.0042\n",
            "Batch 2230/2573, Loss: 0.0106\n",
            "Batch 2240/2573, Loss: 0.0220\n",
            "Batch 2250/2573, Loss: 0.0134\n",
            "Batch 2260/2573, Loss: 0.0177\n",
            "Batch 2270/2573, Loss: 0.0178\n",
            "Batch 2280/2573, Loss: 0.0133\n",
            "Batch 2290/2573, Loss: 0.0092\n",
            "Batch 2300/2573, Loss: 0.0146\n",
            "Batch 2310/2573, Loss: 0.0101\n",
            "Batch 2320/2573, Loss: 0.0107\n",
            "Batch 2330/2573, Loss: 0.0189\n",
            "Batch 2340/2573, Loss: 0.0352\n",
            "Batch 2350/2573, Loss: 0.0234\n",
            "Batch 2360/2573, Loss: 0.0122\n",
            "Batch 2370/2573, Loss: 0.0185\n",
            "Batch 2380/2573, Loss: 0.0131\n",
            "Batch 2390/2573, Loss: 0.0165\n",
            "Batch 2400/2573, Loss: 0.0142\n",
            "Batch 2410/2573, Loss: 0.0106\n",
            "Batch 2420/2573, Loss: 0.0181\n",
            "Batch 2430/2573, Loss: 0.0112\n",
            "Batch 2440/2573, Loss: 0.0079\n",
            "Batch 2450/2573, Loss: 0.0091\n",
            "Batch 2460/2573, Loss: 0.0110\n",
            "Batch 2470/2573, Loss: 0.0131\n",
            "Batch 2480/2573, Loss: 0.0074\n",
            "Batch 2490/2573, Loss: 0.0215\n",
            "Batch 2500/2573, Loss: 0.0202\n",
            "Batch 2510/2573, Loss: 0.0156\n",
            "Batch 2520/2573, Loss: 0.0069\n",
            "Batch 2530/2573, Loss: 0.0271\n",
            "Batch 2540/2573, Loss: 0.0095\n",
            "Batch 2550/2573, Loss: 0.0109\n",
            "Batch 2560/2573, Loss: 0.0189\n",
            "Batch 2570/2573, Loss: 0.0119\n",
            "Epoch 16 Average Loss: 0.0158\n",
            "\n",
            "Epoch 17/20\n",
            "------------------------------\n",
            "Batch 10/2573, Loss: 0.0137\n",
            "Batch 20/2573, Loss: 0.0142\n",
            "Batch 30/2573, Loss: 0.0107\n",
            "Batch 40/2573, Loss: 0.0147\n",
            "Batch 50/2573, Loss: 0.0275\n",
            "Batch 60/2573, Loss: 0.0069\n",
            "Batch 70/2573, Loss: 0.0295\n",
            "Batch 80/2573, Loss: 0.0184\n",
            "Batch 90/2573, Loss: 0.0167\n",
            "Batch 100/2573, Loss: 0.0106\n",
            "Batch 110/2573, Loss: 0.0051\n",
            "Batch 120/2573, Loss: 0.0268\n",
            "Batch 130/2573, Loss: 0.0088\n",
            "Batch 140/2573, Loss: 0.0092\n",
            "Batch 150/2573, Loss: 0.0243\n",
            "Batch 160/2573, Loss: 0.0134\n",
            "Batch 170/2573, Loss: 0.0097\n",
            "Batch 180/2573, Loss: 0.0097\n",
            "Batch 190/2573, Loss: 0.0130\n",
            "Batch 200/2573, Loss: 0.0178\n",
            "Batch 210/2573, Loss: 0.0087\n",
            "Batch 220/2573, Loss: 0.0125\n",
            "Batch 230/2573, Loss: 0.0069\n",
            "Batch 240/2573, Loss: 0.0290\n",
            "Batch 250/2573, Loss: 0.0095\n",
            "Batch 260/2573, Loss: 0.0083\n",
            "Batch 270/2573, Loss: 0.0179\n",
            "Batch 280/2573, Loss: 0.0332\n",
            "Batch 290/2573, Loss: 0.0063\n",
            "Batch 300/2573, Loss: 0.0130\n",
            "Batch 310/2573, Loss: 0.0084\n",
            "Batch 320/2573, Loss: 0.0163\n",
            "Batch 330/2573, Loss: 0.0046\n",
            "Batch 340/2573, Loss: 0.0181\n",
            "Batch 350/2573, Loss: 0.0206\n",
            "Batch 360/2573, Loss: 0.0246\n",
            "Batch 370/2573, Loss: 0.0242\n",
            "Batch 380/2573, Loss: 0.0078\n",
            "Batch 390/2573, Loss: 0.0180\n",
            "Batch 400/2573, Loss: 0.0118\n",
            "Batch 410/2573, Loss: 0.0174\n",
            "Batch 420/2573, Loss: 0.0056\n",
            "Batch 430/2573, Loss: 0.0081\n",
            "Batch 440/2573, Loss: 0.0085\n",
            "Batch 450/2573, Loss: 0.0114\n",
            "Batch 460/2573, Loss: 0.0245\n",
            "Batch 470/2573, Loss: 0.0334\n",
            "Batch 480/2573, Loss: 0.0097\n",
            "Batch 490/2573, Loss: 0.0163\n",
            "Batch 500/2573, Loss: 0.0066\n",
            "Batch 510/2573, Loss: 0.0145\n",
            "Batch 520/2573, Loss: 0.0116\n",
            "Batch 530/2573, Loss: 0.0065\n",
            "Batch 540/2573, Loss: 0.0252\n",
            "Batch 550/2573, Loss: 0.0124\n",
            "Batch 560/2573, Loss: 0.0108\n",
            "Batch 570/2573, Loss: 0.0097\n",
            "Batch 580/2573, Loss: 0.0106\n",
            "Batch 590/2573, Loss: 0.0151\n",
            "Batch 600/2573, Loss: 0.0134\n",
            "Batch 610/2573, Loss: 0.0266\n",
            "Batch 620/2573, Loss: 0.0208\n",
            "Batch 630/2573, Loss: 0.0168\n",
            "Batch 640/2573, Loss: 0.0211\n",
            "Batch 650/2573, Loss: 0.0150\n",
            "Batch 660/2573, Loss: 0.0114\n",
            "Batch 670/2573, Loss: 0.0354\n",
            "Batch 680/2573, Loss: 0.0200\n",
            "Batch 690/2573, Loss: 0.0140\n",
            "Batch 700/2573, Loss: 0.0121\n",
            "Batch 710/2573, Loss: 0.0097\n",
            "Batch 720/2573, Loss: 0.0129\n",
            "Batch 730/2573, Loss: 0.0336\n",
            "Batch 740/2573, Loss: 0.0205\n",
            "Batch 750/2573, Loss: 0.0131\n",
            "Batch 760/2573, Loss: 0.0060\n",
            "Batch 770/2573, Loss: 0.0077\n",
            "Batch 780/2573, Loss: 0.0098\n",
            "Batch 790/2573, Loss: 0.0175\n",
            "Batch 800/2573, Loss: 0.0226\n",
            "Batch 810/2573, Loss: 0.0064\n",
            "Batch 820/2573, Loss: 0.0159\n",
            "Batch 830/2573, Loss: 0.0164\n",
            "Batch 840/2573, Loss: 0.0271\n",
            "Batch 850/2573, Loss: 0.0182\n",
            "Batch 860/2573, Loss: 0.0120\n",
            "Batch 870/2573, Loss: 0.0200\n",
            "Batch 880/2573, Loss: 0.0074\n",
            "Batch 890/2573, Loss: 0.0215\n",
            "Batch 900/2573, Loss: 0.0127\n",
            "Batch 910/2573, Loss: 0.0090\n",
            "Batch 920/2573, Loss: 0.0124\n",
            "Batch 930/2573, Loss: 0.0226\n",
            "Batch 940/2573, Loss: 0.0177\n",
            "Batch 950/2573, Loss: 0.0168\n",
            "Batch 960/2573, Loss: 0.0169\n",
            "Batch 970/2573, Loss: 0.0256\n",
            "Batch 980/2573, Loss: 0.0124\n",
            "Batch 990/2573, Loss: 0.0479\n",
            "Batch 1000/2573, Loss: 0.0050\n",
            "Batch 1010/2573, Loss: 0.0152\n",
            "Batch 1020/2573, Loss: 0.0136\n",
            "Batch 1030/2573, Loss: 0.0135\n",
            "Batch 1040/2573, Loss: 0.0069\n",
            "Batch 1050/2573, Loss: 0.0333\n",
            "Batch 1060/2573, Loss: 0.0075\n",
            "Batch 1070/2573, Loss: 0.0112\n",
            "Batch 1080/2573, Loss: 0.0114\n",
            "Batch 1090/2573, Loss: 0.0072\n",
            "Batch 1100/2573, Loss: 0.0195\n",
            "Batch 1110/2573, Loss: 0.0172\n",
            "Batch 1120/2573, Loss: 0.0145\n",
            "Batch 1130/2573, Loss: 0.0076\n",
            "Batch 1140/2573, Loss: 0.0081\n",
            "Batch 1150/2573, Loss: 0.0053\n",
            "Batch 1160/2573, Loss: 0.0099\n",
            "Batch 1170/2573, Loss: 0.0253\n",
            "Batch 1180/2573, Loss: 0.0084\n",
            "Batch 1190/2573, Loss: 0.0089\n",
            "Batch 1200/2573, Loss: 0.0217\n",
            "Batch 1210/2573, Loss: 0.0118\n",
            "Batch 1220/2573, Loss: 0.0104\n",
            "Batch 1230/2573, Loss: 0.0118\n",
            "Batch 1240/2573, Loss: 0.0085\n",
            "Batch 1250/2573, Loss: 0.0125\n",
            "Batch 1260/2573, Loss: 0.0115\n",
            "Batch 1270/2573, Loss: 0.0121\n",
            "Batch 1280/2573, Loss: 0.0068\n",
            "Batch 1290/2573, Loss: 0.0078\n",
            "Batch 1300/2573, Loss: 0.0261\n",
            "Batch 1310/2573, Loss: 0.0254\n",
            "Batch 1320/2573, Loss: 0.0124\n",
            "Batch 1330/2573, Loss: 0.0069\n",
            "Batch 1340/2573, Loss: 0.0146\n",
            "Batch 1350/2573, Loss: 0.0113\n",
            "Batch 1360/2573, Loss: 0.0312\n",
            "Batch 1370/2573, Loss: 0.0235\n",
            "Batch 1380/2573, Loss: 0.0132\n",
            "Batch 1390/2573, Loss: 0.0060\n",
            "Batch 1400/2573, Loss: 0.0070\n",
            "Batch 1410/2573, Loss: 0.0077\n",
            "Batch 1420/2573, Loss: 0.0444\n",
            "Batch 1430/2573, Loss: 0.0174\n",
            "Batch 1440/2573, Loss: 0.0077\n",
            "Batch 1450/2573, Loss: 0.0143\n",
            "Batch 1460/2573, Loss: 0.0195\n",
            "Batch 1470/2573, Loss: 0.0207\n",
            "Batch 1480/2573, Loss: 0.0124\n",
            "Batch 1490/2573, Loss: 0.0234\n",
            "Batch 1500/2573, Loss: 0.0056\n",
            "Batch 1510/2573, Loss: 0.0123\n",
            "Batch 1520/2573, Loss: 0.0283\n",
            "Batch 1530/2573, Loss: 0.0235\n",
            "Batch 1540/2573, Loss: 0.0140\n",
            "Batch 1550/2573, Loss: 0.0366\n",
            "Batch 1560/2573, Loss: 0.0121\n",
            "Batch 1570/2573, Loss: 0.0151\n",
            "Batch 1580/2573, Loss: 0.0082\n",
            "Batch 1590/2573, Loss: 0.0122\n",
            "Batch 1600/2573, Loss: 0.0233\n",
            "Batch 1610/2573, Loss: 0.0179\n",
            "Batch 1620/2573, Loss: 0.0149\n",
            "Batch 1630/2573, Loss: 0.0163\n",
            "Batch 1640/2573, Loss: 0.0274\n",
            "Batch 1650/2573, Loss: 0.0095\n",
            "Batch 1660/2573, Loss: 0.0081\n",
            "Batch 1670/2573, Loss: 0.0150\n",
            "Batch 1680/2573, Loss: 0.0065\n",
            "Batch 1690/2573, Loss: 0.0183\n",
            "Batch 1700/2573, Loss: 0.0114\n",
            "Batch 1710/2573, Loss: 0.0148\n",
            "Batch 1720/2573, Loss: 0.0283\n",
            "Batch 1730/2573, Loss: 0.0259\n",
            "Batch 1740/2573, Loss: 0.0206\n",
            "Batch 1750/2573, Loss: 0.0269\n",
            "Batch 1760/2573, Loss: 0.0187\n",
            "Batch 1770/2573, Loss: 0.0174\n",
            "Batch 1780/2573, Loss: 0.0101\n",
            "Batch 1790/2573, Loss: 0.0095\n",
            "Batch 1800/2573, Loss: 0.0072\n",
            "Batch 1810/2573, Loss: 0.0148\n",
            "Batch 1820/2573, Loss: 0.0235\n",
            "Batch 1830/2573, Loss: 0.0173\n",
            "Batch 1840/2573, Loss: 0.0333\n",
            "Batch 1850/2573, Loss: 0.0101\n",
            "Batch 1860/2573, Loss: 0.0147\n",
            "Batch 1870/2573, Loss: 0.0216\n",
            "Batch 1880/2573, Loss: 0.0208\n",
            "Batch 1890/2573, Loss: 0.0153\n",
            "Batch 1900/2573, Loss: 0.0123\n",
            "Batch 1910/2573, Loss: 0.0079\n",
            "Batch 1920/2573, Loss: 0.0134\n",
            "Batch 1930/2573, Loss: 0.0097\n",
            "Batch 1940/2573, Loss: 0.0271\n",
            "Batch 1950/2573, Loss: 0.0283\n",
            "Batch 1960/2573, Loss: 0.0140\n",
            "Batch 1970/2573, Loss: 0.0256\n",
            "Batch 1980/2573, Loss: 0.0126\n",
            "Batch 1990/2573, Loss: 0.0113\n",
            "Batch 2000/2573, Loss: 0.0158\n",
            "Batch 2010/2573, Loss: 0.0179\n",
            "Batch 2020/2573, Loss: 0.0380\n",
            "Batch 2030/2573, Loss: 0.0213\n",
            "Batch 2040/2573, Loss: 0.0193\n",
            "Batch 2050/2573, Loss: 0.0127\n",
            "Batch 2060/2573, Loss: 0.0193\n",
            "Batch 2070/2573, Loss: 0.0126\n",
            "Batch 2080/2573, Loss: 0.0273\n",
            "Batch 2090/2573, Loss: 0.0222\n",
            "Batch 2100/2573, Loss: 0.0179\n",
            "Batch 2110/2573, Loss: 0.0185\n",
            "Batch 2120/2573, Loss: 0.0098\n",
            "Batch 2130/2573, Loss: 0.0093\n",
            "Batch 2140/2573, Loss: 0.0170\n",
            "Batch 2150/2573, Loss: 0.0092\n",
            "Batch 2160/2573, Loss: 0.0084\n",
            "Batch 2170/2573, Loss: 0.0332\n",
            "Batch 2180/2573, Loss: 0.0239\n",
            "Batch 2190/2573, Loss: 0.0116\n",
            "Batch 2200/2573, Loss: 0.0402\n",
            "Batch 2210/2573, Loss: 0.0049\n",
            "Batch 2220/2573, Loss: 0.0121\n",
            "Batch 2230/2573, Loss: 0.0239\n",
            "Batch 2240/2573, Loss: 0.0272\n",
            "Batch 2250/2573, Loss: 0.0089\n",
            "Batch 2260/2573, Loss: 0.0110\n",
            "Batch 2270/2573, Loss: 0.0248\n",
            "Batch 2280/2573, Loss: 0.0145\n",
            "Batch 2290/2573, Loss: 0.0097\n",
            "Batch 2300/2573, Loss: 0.0229\n",
            "Batch 2310/2573, Loss: 0.0076\n",
            "Batch 2320/2573, Loss: 0.0159\n",
            "Batch 2330/2573, Loss: 0.0113\n",
            "Batch 2340/2573, Loss: 0.0052\n",
            "Batch 2350/2573, Loss: 0.0201\n",
            "Batch 2360/2573, Loss: 0.0078\n",
            "Batch 2370/2573, Loss: 0.0111\n",
            "Batch 2380/2573, Loss: 0.0135\n",
            "Batch 2390/2573, Loss: 0.0099\n",
            "Batch 2400/2573, Loss: 0.0062\n",
            "Batch 2410/2573, Loss: 0.0182\n",
            "Batch 2420/2573, Loss: 0.0129\n",
            "Batch 2430/2573, Loss: 0.0078\n",
            "Batch 2440/2573, Loss: 0.0053\n",
            "Batch 2450/2573, Loss: 0.0197\n",
            "Batch 2460/2573, Loss: 0.0087\n",
            "Batch 2470/2573, Loss: 0.0127\n",
            "Batch 2480/2573, Loss: 0.0157\n",
            "Batch 2490/2573, Loss: 0.0102\n",
            "Batch 2500/2573, Loss: 0.0143\n",
            "Batch 2510/2573, Loss: 0.0086\n",
            "Batch 2520/2573, Loss: 0.0189\n",
            "Batch 2530/2573, Loss: 0.0230\n",
            "Batch 2540/2573, Loss: 0.0292\n",
            "Batch 2550/2573, Loss: 0.0065\n",
            "Batch 2560/2573, Loss: 0.0088\n",
            "Batch 2570/2573, Loss: 0.0209\n",
            "Epoch 17 Average Loss: 0.0156\n",
            "\n",
            "Epoch 18/20\n",
            "------------------------------\n",
            "Batch 10/2573, Loss: 0.0239\n",
            "Batch 20/2573, Loss: 0.0108\n",
            "Batch 30/2573, Loss: 0.0302\n",
            "Batch 40/2573, Loss: 0.0131\n",
            "Batch 50/2573, Loss: 0.0156\n",
            "Batch 60/2573, Loss: 0.0063\n",
            "Batch 70/2573, Loss: 0.0081\n",
            "Batch 80/2573, Loss: 0.0233\n",
            "Batch 90/2573, Loss: 0.0114\n",
            "Batch 100/2573, Loss: 0.0074\n",
            "Batch 110/2573, Loss: 0.0107\n",
            "Batch 120/2573, Loss: 0.0187\n",
            "Batch 130/2573, Loss: 0.0179\n",
            "Batch 140/2573, Loss: 0.0174\n",
            "Batch 150/2573, Loss: 0.0098\n",
            "Batch 160/2573, Loss: 0.0331\n",
            "Batch 170/2573, Loss: 0.0165\n",
            "Batch 180/2573, Loss: 0.0086\n",
            "Batch 190/2573, Loss: 0.0104\n",
            "Batch 200/2573, Loss: 0.0097\n",
            "Batch 210/2573, Loss: 0.0086\n",
            "Batch 220/2573, Loss: 0.0086\n",
            "Batch 230/2573, Loss: 0.0149\n",
            "Batch 240/2573, Loss: 0.0114\n",
            "Batch 250/2573, Loss: 0.0071\n",
            "Batch 260/2573, Loss: 0.0107\n",
            "Batch 270/2573, Loss: 0.0130\n",
            "Batch 280/2573, Loss: 0.0283\n",
            "Batch 290/2573, Loss: 0.0063\n",
            "Batch 300/2573, Loss: 0.0131\n",
            "Batch 310/2573, Loss: 0.0126\n",
            "Batch 320/2573, Loss: 0.0073\n",
            "Batch 330/2573, Loss: 0.0076\n",
            "Batch 340/2573, Loss: 0.0147\n",
            "Batch 350/2573, Loss: 0.0049\n",
            "Batch 360/2573, Loss: 0.0073\n",
            "Batch 370/2573, Loss: 0.0106\n",
            "Batch 380/2573, Loss: 0.0115\n",
            "Batch 390/2573, Loss: 0.0099\n",
            "Batch 400/2573, Loss: 0.0149\n",
            "Batch 410/2573, Loss: 0.0197\n",
            "Batch 420/2573, Loss: 0.0188\n",
            "Batch 430/2573, Loss: 0.0125\n",
            "Batch 440/2573, Loss: 0.0102\n",
            "Batch 450/2573, Loss: 0.0127\n",
            "Batch 460/2573, Loss: 0.0190\n",
            "Batch 470/2573, Loss: 0.0120\n",
            "Batch 480/2573, Loss: 0.0205\n",
            "Batch 490/2573, Loss: 0.0114\n",
            "Batch 500/2573, Loss: 0.0341\n",
            "Batch 510/2573, Loss: 0.0154\n",
            "Batch 520/2573, Loss: 0.0136\n",
            "Batch 530/2573, Loss: 0.0110\n",
            "Batch 540/2573, Loss: 0.0422\n",
            "Batch 550/2573, Loss: 0.0084\n",
            "Batch 560/2573, Loss: 0.0064\n",
            "Batch 570/2573, Loss: 0.0221\n",
            "Batch 580/2573, Loss: 0.0059\n",
            "Batch 590/2573, Loss: 0.0087\n",
            "Batch 600/2573, Loss: 0.0073\n",
            "Batch 610/2573, Loss: 0.0126\n",
            "Batch 620/2573, Loss: 0.0150\n",
            "Batch 630/2573, Loss: 0.0138\n",
            "Batch 640/2573, Loss: 0.0173\n",
            "Batch 650/2573, Loss: 0.0243\n",
            "Batch 660/2573, Loss: 0.0350\n",
            "Batch 670/2573, Loss: 0.0107\n",
            "Batch 680/2573, Loss: 0.0106\n",
            "Batch 690/2573, Loss: 0.0140\n",
            "Batch 700/2573, Loss: 0.0194\n",
            "Batch 710/2573, Loss: 0.0169\n",
            "Batch 720/2573, Loss: 0.0147\n",
            "Batch 730/2573, Loss: 0.0098\n",
            "Batch 740/2573, Loss: 0.0043\n",
            "Batch 750/2573, Loss: 0.0113\n",
            "Batch 760/2573, Loss: 0.0347\n",
            "Batch 770/2573, Loss: 0.0077\n",
            "Batch 780/2573, Loss: 0.0072\n",
            "Batch 790/2573, Loss: 0.0227\n",
            "Batch 800/2573, Loss: 0.0138\n",
            "Batch 810/2573, Loss: 0.0059\n",
            "Batch 820/2573, Loss: 0.0257\n",
            "Batch 830/2573, Loss: 0.0261\n",
            "Batch 840/2573, Loss: 0.0257\n",
            "Batch 850/2573, Loss: 0.0123\n",
            "Batch 860/2573, Loss: 0.0105\n",
            "Batch 870/2573, Loss: 0.0071\n",
            "Batch 880/2573, Loss: 0.0077\n",
            "Batch 890/2573, Loss: 0.0189\n",
            "Batch 900/2573, Loss: 0.0160\n",
            "Batch 910/2573, Loss: 0.0084\n",
            "Batch 920/2573, Loss: 0.0093\n",
            "Batch 930/2573, Loss: 0.0075\n",
            "Batch 940/2573, Loss: 0.0127\n",
            "Batch 950/2573, Loss: 0.0082\n",
            "Batch 960/2573, Loss: 0.0178\n",
            "Batch 970/2573, Loss: 0.0416\n",
            "Batch 980/2573, Loss: 0.0112\n",
            "Batch 990/2573, Loss: 0.0100\n",
            "Batch 1000/2573, Loss: 0.0100\n",
            "Batch 1010/2573, Loss: 0.0135\n",
            "Batch 1020/2573, Loss: 0.0126\n",
            "Batch 1030/2573, Loss: 0.0224\n",
            "Batch 1040/2573, Loss: 0.0304\n",
            "Batch 1050/2573, Loss: 0.0193\n",
            "Batch 1060/2573, Loss: 0.0291\n",
            "Batch 1070/2573, Loss: 0.0100\n",
            "Batch 1080/2573, Loss: 0.0157\n",
            "Batch 1090/2573, Loss: 0.0147\n",
            "Batch 1100/2573, Loss: 0.0129\n",
            "Batch 1110/2573, Loss: 0.0588\n",
            "Batch 1120/2573, Loss: 0.0213\n",
            "Batch 1130/2573, Loss: 0.0071\n",
            "Batch 1140/2573, Loss: 0.0183\n",
            "Batch 1150/2573, Loss: 0.0318\n",
            "Batch 1160/2573, Loss: 0.0175\n",
            "Batch 1170/2573, Loss: 0.0238\n",
            "Batch 1180/2573, Loss: 0.0100\n",
            "Batch 1190/2573, Loss: 0.0247\n",
            "Batch 1200/2573, Loss: 0.0233\n",
            "Batch 1210/2573, Loss: 0.0159\n",
            "Batch 1220/2573, Loss: 0.0215\n",
            "Batch 1230/2573, Loss: 0.0262\n",
            "Batch 1240/2573, Loss: 0.0165\n",
            "Batch 1250/2573, Loss: 0.0259\n",
            "Batch 1260/2573, Loss: 0.0091\n",
            "Batch 1270/2573, Loss: 0.0082\n",
            "Batch 1280/2573, Loss: 0.0093\n",
            "Batch 1290/2573, Loss: 0.0180\n",
            "Batch 1300/2573, Loss: 0.0062\n",
            "Batch 1310/2573, Loss: 0.0097\n",
            "Batch 1320/2573, Loss: 0.0118\n",
            "Batch 1330/2573, Loss: 0.0218\n",
            "Batch 1340/2573, Loss: 0.0136\n",
            "Batch 1350/2573, Loss: 0.0146\n",
            "Batch 1360/2573, Loss: 0.0081\n",
            "Batch 1370/2573, Loss: 0.0322\n",
            "Batch 1380/2573, Loss: 0.0233\n",
            "Batch 1390/2573, Loss: 0.0121\n",
            "Batch 1400/2573, Loss: 0.0302\n",
            "Batch 1410/2573, Loss: 0.0096\n",
            "Batch 1420/2573, Loss: 0.0117\n",
            "Batch 1430/2573, Loss: 0.0101\n",
            "Batch 1440/2573, Loss: 0.0139\n",
            "Batch 1450/2573, Loss: 0.0293\n",
            "Batch 1460/2573, Loss: 0.0125\n",
            "Batch 1470/2573, Loss: 0.0246\n",
            "Batch 1480/2573, Loss: 0.0084\n",
            "Batch 1490/2573, Loss: 0.0094\n",
            "Batch 1500/2573, Loss: 0.0111\n",
            "Batch 1510/2573, Loss: 0.0094\n",
            "Batch 1520/2573, Loss: 0.0178\n",
            "Batch 1530/2573, Loss: 0.0112\n",
            "Batch 1540/2573, Loss: 0.0153\n",
            "Batch 1550/2573, Loss: 0.0112\n",
            "Batch 1560/2573, Loss: 0.0294\n",
            "Batch 1570/2573, Loss: 0.0136\n",
            "Batch 1580/2573, Loss: 0.0138\n",
            "Batch 1590/2573, Loss: 0.0140\n",
            "Batch 1600/2573, Loss: 0.0054\n",
            "Batch 1610/2573, Loss: 0.0295\n",
            "Batch 1620/2573, Loss: 0.0202\n",
            "Batch 1630/2573, Loss: 0.0177\n",
            "Batch 1640/2573, Loss: 0.0148\n",
            "Batch 1650/2573, Loss: 0.0085\n",
            "Batch 1660/2573, Loss: 0.0096\n",
            "Batch 1670/2573, Loss: 0.0080\n",
            "Batch 1680/2573, Loss: 0.0242\n",
            "Batch 1690/2573, Loss: 0.0127\n",
            "Batch 1700/2573, Loss: 0.0148\n",
            "Batch 1710/2573, Loss: 0.0103\n",
            "Batch 1720/2573, Loss: 0.0481\n",
            "Batch 1730/2573, Loss: 0.0082\n",
            "Batch 1740/2573, Loss: 0.0175\n",
            "Batch 1750/2573, Loss: 0.0152\n",
            "Batch 1760/2573, Loss: 0.0100\n",
            "Batch 1770/2573, Loss: 0.0151\n",
            "Batch 1780/2573, Loss: 0.0074\n",
            "Batch 1790/2573, Loss: 0.0122\n",
            "Batch 1800/2573, Loss: 0.0098\n",
            "Batch 1810/2573, Loss: 0.0150\n",
            "Batch 1820/2573, Loss: 0.0057\n",
            "Batch 1830/2573, Loss: 0.0105\n",
            "Batch 1840/2573, Loss: 0.0103\n",
            "Batch 1850/2573, Loss: 0.0148\n",
            "Batch 1860/2573, Loss: 0.0093\n",
            "Batch 1870/2573, Loss: 0.0038\n",
            "Batch 1880/2573, Loss: 0.0115\n",
            "Batch 1890/2573, Loss: 0.0188\n",
            "Batch 1900/2573, Loss: 0.0387\n",
            "Batch 1910/2573, Loss: 0.0130\n",
            "Batch 1920/2573, Loss: 0.0325\n",
            "Batch 1930/2573, Loss: 0.0229\n",
            "Batch 1940/2573, Loss: 0.0063\n",
            "Batch 1950/2573, Loss: 0.0135\n",
            "Batch 1960/2573, Loss: 0.0091\n",
            "Batch 1970/2573, Loss: 0.0145\n",
            "Batch 1980/2573, Loss: 0.0237\n",
            "Batch 1990/2573, Loss: 0.0187\n",
            "Batch 2000/2573, Loss: 0.0113\n",
            "Batch 2010/2573, Loss: 0.0086\n",
            "Batch 2020/2573, Loss: 0.0172\n",
            "Batch 2030/2573, Loss: 0.0184\n",
            "Batch 2040/2573, Loss: 0.0370\n",
            "Batch 2050/2573, Loss: 0.0080\n",
            "Batch 2060/2573, Loss: 0.0446\n",
            "Batch 2070/2573, Loss: 0.0169\n",
            "Batch 2080/2573, Loss: 0.0106\n",
            "Batch 2090/2573, Loss: 0.0366\n",
            "Batch 2100/2573, Loss: 0.0306\n",
            "Batch 2110/2573, Loss: 0.0219\n",
            "Batch 2120/2573, Loss: 0.0264\n",
            "Batch 2130/2573, Loss: 0.0144\n",
            "Batch 2140/2573, Loss: 0.0188\n",
            "Batch 2150/2573, Loss: 0.0094\n",
            "Batch 2160/2573, Loss: 0.0103\n",
            "Batch 2170/2573, Loss: 0.0111\n",
            "Batch 2180/2573, Loss: 0.0195\n",
            "Batch 2190/2573, Loss: 0.0289\n",
            "Batch 2200/2573, Loss: 0.0160\n",
            "Batch 2210/2573, Loss: 0.0365\n",
            "Batch 2220/2573, Loss: 0.0070\n",
            "Batch 2230/2573, Loss: 0.0250\n",
            "Batch 2240/2573, Loss: 0.0072\n",
            "Batch 2250/2573, Loss: 0.0171\n",
            "Batch 2260/2573, Loss: 0.0139\n",
            "Batch 2270/2573, Loss: 0.0171\n",
            "Batch 2280/2573, Loss: 0.0119\n",
            "Batch 2290/2573, Loss: 0.0112\n",
            "Batch 2300/2573, Loss: 0.0207\n",
            "Batch 2310/2573, Loss: 0.0155\n",
            "Batch 2320/2573, Loss: 0.0155\n",
            "Batch 2330/2573, Loss: 0.0165\n",
            "Batch 2340/2573, Loss: 0.0146\n",
            "Batch 2350/2573, Loss: 0.0231\n",
            "Batch 2360/2573, Loss: 0.0178\n",
            "Batch 2370/2573, Loss: 0.0240\n",
            "Batch 2380/2573, Loss: 0.0236\n",
            "Batch 2390/2573, Loss: 0.0089\n",
            "Batch 2400/2573, Loss: 0.0217\n",
            "Batch 2410/2573, Loss: 0.0424\n",
            "Batch 2420/2573, Loss: 0.0076\n",
            "Batch 2430/2573, Loss: 0.0155\n",
            "Batch 2440/2573, Loss: 0.0173\n",
            "Batch 2450/2573, Loss: 0.0063\n",
            "Batch 2460/2573, Loss: 0.0211\n",
            "Batch 2470/2573, Loss: 0.0284\n",
            "Batch 2480/2573, Loss: 0.0136\n",
            "Batch 2490/2573, Loss: 0.0070\n",
            "Batch 2500/2573, Loss: 0.0100\n",
            "Batch 2510/2573, Loss: 0.0118\n",
            "Batch 2520/2573, Loss: 0.0069\n",
            "Batch 2530/2573, Loss: 0.0173\n",
            "Batch 2540/2573, Loss: 0.0107\n",
            "Batch 2550/2573, Loss: 0.0125\n",
            "Batch 2560/2573, Loss: 0.0327\n",
            "Batch 2570/2573, Loss: 0.0134\n",
            "Epoch 18 Average Loss: 0.0155\n",
            "\n",
            "Epoch 19/20\n",
            "------------------------------\n",
            "Batch 10/2573, Loss: 0.0190\n",
            "Batch 20/2573, Loss: 0.0039\n",
            "Batch 30/2573, Loss: 0.0084\n",
            "Batch 40/2573, Loss: 0.0173\n",
            "Batch 50/2573, Loss: 0.0134\n",
            "Batch 60/2573, Loss: 0.0113\n",
            "Batch 70/2573, Loss: 0.0095\n",
            "Batch 80/2573, Loss: 0.0083\n",
            "Batch 90/2573, Loss: 0.0212\n",
            "Batch 100/2573, Loss: 0.0106\n",
            "Batch 110/2573, Loss: 0.0233\n",
            "Batch 120/2573, Loss: 0.0195\n",
            "Batch 130/2573, Loss: 0.0148\n",
            "Batch 140/2573, Loss: 0.0276\n",
            "Batch 150/2573, Loss: 0.0126\n",
            "Batch 160/2573, Loss: 0.0070\n",
            "Batch 170/2573, Loss: 0.0134\n",
            "Batch 180/2573, Loss: 0.0204\n",
            "Batch 190/2573, Loss: 0.0094\n",
            "Batch 200/2573, Loss: 0.0104\n",
            "Batch 210/2573, Loss: 0.0102\n",
            "Batch 220/2573, Loss: 0.0095\n",
            "Batch 230/2573, Loss: 0.0092\n",
            "Batch 240/2573, Loss: 0.0048\n",
            "Batch 250/2573, Loss: 0.0300\n",
            "Batch 260/2573, Loss: 0.0137\n",
            "Batch 270/2573, Loss: 0.0345\n",
            "Batch 280/2573, Loss: 0.0102\n",
            "Batch 290/2573, Loss: 0.0167\n",
            "Batch 300/2573, Loss: 0.0293\n",
            "Batch 310/2573, Loss: 0.0135\n",
            "Batch 320/2573, Loss: 0.0157\n",
            "Batch 330/2573, Loss: 0.0159\n",
            "Batch 340/2573, Loss: 0.0263\n",
            "Batch 350/2573, Loss: 0.0170\n",
            "Batch 360/2573, Loss: 0.0162\n",
            "Batch 370/2573, Loss: 0.0081\n",
            "Batch 380/2573, Loss: 0.0136\n",
            "Batch 390/2573, Loss: 0.0144\n",
            "Batch 400/2573, Loss: 0.0247\n",
            "Batch 410/2573, Loss: 0.0091\n",
            "Batch 420/2573, Loss: 0.0048\n",
            "Batch 430/2573, Loss: 0.0422\n",
            "Batch 440/2573, Loss: 0.0210\n",
            "Batch 450/2573, Loss: 0.0146\n",
            "Batch 460/2573, Loss: 0.0085\n",
            "Batch 470/2573, Loss: 0.0120\n",
            "Batch 480/2573, Loss: 0.0286\n",
            "Batch 490/2573, Loss: 0.0208\n",
            "Batch 500/2573, Loss: 0.0133\n",
            "Batch 510/2573, Loss: 0.0131\n",
            "Batch 520/2573, Loss: 0.0196\n",
            "Batch 530/2573, Loss: 0.0121\n",
            "Batch 540/2573, Loss: 0.0231\n",
            "Batch 550/2573, Loss: 0.0180\n",
            "Batch 560/2573, Loss: 0.0101\n",
            "Batch 570/2573, Loss: 0.0172\n",
            "Batch 580/2573, Loss: 0.0058\n",
            "Batch 590/2573, Loss: 0.0087\n",
            "Batch 600/2573, Loss: 0.0050\n",
            "Batch 610/2573, Loss: 0.0199\n",
            "Batch 620/2573, Loss: 0.0120\n",
            "Batch 630/2573, Loss: 0.0075\n",
            "Batch 640/2573, Loss: 0.0108\n",
            "Batch 650/2573, Loss: 0.0112\n",
            "Batch 660/2573, Loss: 0.0085\n",
            "Batch 670/2573, Loss: 0.0103\n",
            "Batch 680/2573, Loss: 0.0128\n",
            "Batch 690/2573, Loss: 0.0134\n",
            "Batch 700/2573, Loss: 0.0202\n",
            "Batch 710/2573, Loss: 0.0076\n",
            "Batch 720/2573, Loss: 0.0071\n",
            "Batch 730/2573, Loss: 0.0297\n",
            "Batch 740/2573, Loss: 0.0061\n",
            "Batch 750/2573, Loss: 0.0076\n",
            "Batch 760/2573, Loss: 0.0117\n",
            "Batch 770/2573, Loss: 0.0095\n",
            "Batch 780/2573, Loss: 0.0298\n",
            "Batch 790/2573, Loss: 0.0183\n",
            "Batch 800/2573, Loss: 0.0074\n",
            "Batch 810/2573, Loss: 0.0058\n",
            "Batch 820/2573, Loss: 0.0085\n",
            "Batch 830/2573, Loss: 0.0054\n",
            "Batch 840/2573, Loss: 0.0125\n",
            "Batch 850/2573, Loss: 0.0081\n",
            "Batch 860/2573, Loss: 0.0152\n",
            "Batch 870/2573, Loss: 0.0139\n",
            "Batch 880/2573, Loss: 0.0186\n",
            "Batch 890/2573, Loss: 0.0124\n",
            "Batch 900/2573, Loss: 0.0238\n",
            "Batch 910/2573, Loss: 0.0093\n",
            "Batch 920/2573, Loss: 0.0093\n",
            "Batch 930/2573, Loss: 0.0068\n",
            "Batch 940/2573, Loss: 0.0230\n",
            "Batch 950/2573, Loss: 0.0279\n",
            "Batch 960/2573, Loss: 0.0278\n",
            "Batch 970/2573, Loss: 0.0102\n",
            "Batch 980/2573, Loss: 0.0157\n",
            "Batch 990/2573, Loss: 0.0063\n",
            "Batch 1000/2573, Loss: 0.0149\n",
            "Batch 1010/2573, Loss: 0.0090\n",
            "Batch 1020/2573, Loss: 0.0169\n",
            "Batch 1030/2573, Loss: 0.0190\n",
            "Batch 1040/2573, Loss: 0.0088\n",
            "Batch 1050/2573, Loss: 0.0154\n",
            "Batch 1060/2573, Loss: 0.0121\n",
            "Batch 1070/2573, Loss: 0.0139\n",
            "Batch 1080/2573, Loss: 0.0209\n",
            "Batch 1090/2573, Loss: 0.0166\n",
            "Batch 1100/2573, Loss: 0.0169\n",
            "Batch 1110/2573, Loss: 0.0119\n",
            "Batch 1120/2573, Loss: 0.0119\n",
            "Batch 1130/2573, Loss: 0.0085\n",
            "Batch 1140/2573, Loss: 0.0124\n",
            "Batch 1150/2573, Loss: 0.0097\n",
            "Batch 1160/2573, Loss: 0.0078\n",
            "Batch 1170/2573, Loss: 0.0081\n",
            "Batch 1180/2573, Loss: 0.0084\n",
            "Batch 1190/2573, Loss: 0.0094\n",
            "Batch 1200/2573, Loss: 0.0102\n",
            "Batch 1210/2573, Loss: 0.0135\n",
            "Batch 1220/2573, Loss: 0.0080\n",
            "Batch 1230/2573, Loss: 0.0097\n",
            "Batch 1240/2573, Loss: 0.0257\n",
            "Batch 1250/2573, Loss: 0.0289\n",
            "Batch 1260/2573, Loss: 0.0193\n",
            "Batch 1270/2573, Loss: 0.0186\n",
            "Batch 1280/2573, Loss: 0.0135\n",
            "Batch 1290/2573, Loss: 0.0215\n",
            "Batch 1300/2573, Loss: 0.0086\n",
            "Batch 1310/2573, Loss: 0.0261\n",
            "Batch 1320/2573, Loss: 0.0170\n",
            "Batch 1330/2573, Loss: 0.0137\n",
            "Batch 1340/2573, Loss: 0.0070\n",
            "Batch 1350/2573, Loss: 0.0234\n",
            "Batch 1360/2573, Loss: 0.0265\n",
            "Batch 1370/2573, Loss: 0.0258\n",
            "Batch 1380/2573, Loss: 0.0134\n",
            "Batch 1390/2573, Loss: 0.0154\n",
            "Batch 1400/2573, Loss: 0.0062\n",
            "Batch 1410/2573, Loss: 0.0066\n",
            "Batch 1420/2573, Loss: 0.0046\n",
            "Batch 1430/2573, Loss: 0.0107\n",
            "Batch 1440/2573, Loss: 0.0244\n",
            "Batch 1450/2573, Loss: 0.0132\n",
            "Batch 1460/2573, Loss: 0.0134\n",
            "Batch 1470/2573, Loss: 0.0137\n",
            "Batch 1480/2573, Loss: 0.0091\n",
            "Batch 1490/2573, Loss: 0.0176\n",
            "Batch 1500/2573, Loss: 0.0139\n",
            "Batch 1510/2573, Loss: 0.0188\n",
            "Batch 1520/2573, Loss: 0.0265\n",
            "Batch 1530/2573, Loss: 0.0201\n",
            "Batch 1540/2573, Loss: 0.0190\n",
            "Batch 1550/2573, Loss: 0.0313\n",
            "Batch 1560/2573, Loss: 0.0091\n",
            "Batch 1570/2573, Loss: 0.0121\n",
            "Batch 1580/2573, Loss: 0.0340\n",
            "Batch 1590/2573, Loss: 0.0153\n",
            "Batch 1600/2573, Loss: 0.0060\n",
            "Batch 1610/2573, Loss: 0.0261\n",
            "Batch 1620/2573, Loss: 0.0083\n",
            "Batch 1630/2573, Loss: 0.0295\n",
            "Batch 1640/2573, Loss: 0.0099\n",
            "Batch 1650/2573, Loss: 0.0135\n",
            "Batch 1660/2573, Loss: 0.0258\n",
            "Batch 1670/2573, Loss: 0.0093\n",
            "Batch 1680/2573, Loss: 0.0065\n",
            "Batch 1690/2573, Loss: 0.0157\n",
            "Batch 1700/2573, Loss: 0.0110\n",
            "Batch 1710/2573, Loss: 0.0056\n",
            "Batch 1720/2573, Loss: 0.0254\n",
            "Batch 1730/2573, Loss: 0.0255\n",
            "Batch 1740/2573, Loss: 0.0199\n",
            "Batch 1750/2573, Loss: 0.0112\n",
            "Batch 1760/2573, Loss: 0.0362\n",
            "Batch 1770/2573, Loss: 0.0092\n",
            "Batch 1780/2573, Loss: 0.0136\n",
            "Batch 1790/2573, Loss: 0.0106\n",
            "Batch 1800/2573, Loss: 0.0324\n",
            "Batch 1810/2573, Loss: 0.0237\n",
            "Batch 1820/2573, Loss: 0.0097\n",
            "Batch 1830/2573, Loss: 0.0121\n",
            "Batch 1840/2573, Loss: 0.0125\n",
            "Batch 1850/2573, Loss: 0.0291\n",
            "Batch 1860/2573, Loss: 0.0154\n",
            "Batch 1870/2573, Loss: 0.0135\n",
            "Batch 1880/2573, Loss: 0.0068\n",
            "Batch 1890/2573, Loss: 0.0174\n",
            "Batch 1900/2573, Loss: 0.0243\n",
            "Batch 1910/2573, Loss: 0.0086\n",
            "Batch 1920/2573, Loss: 0.0141\n",
            "Batch 1930/2573, Loss: 0.0152\n",
            "Batch 1940/2573, Loss: 0.0124\n",
            "Batch 1950/2573, Loss: 0.0098\n",
            "Batch 1960/2573, Loss: 0.0052\n",
            "Batch 1970/2573, Loss: 0.0143\n",
            "Batch 1980/2573, Loss: 0.0089\n",
            "Batch 1990/2573, Loss: 0.0230\n",
            "Batch 2000/2573, Loss: 0.0094\n",
            "Batch 2010/2573, Loss: 0.0214\n",
            "Batch 2020/2573, Loss: 0.0292\n",
            "Batch 2030/2573, Loss: 0.0279\n",
            "Batch 2040/2573, Loss: 0.0118\n",
            "Batch 2050/2573, Loss: 0.0131\n",
            "Batch 2060/2573, Loss: 0.0122\n",
            "Batch 2070/2573, Loss: 0.0148\n",
            "Batch 2080/2573, Loss: 0.0198\n",
            "Batch 2090/2573, Loss: 0.0105\n",
            "Batch 2100/2573, Loss: 0.0088\n",
            "Batch 2110/2573, Loss: 0.0080\n",
            "Batch 2120/2573, Loss: 0.0065\n",
            "Batch 2130/2573, Loss: 0.0061\n",
            "Batch 2140/2573, Loss: 0.0115\n",
            "Batch 2150/2573, Loss: 0.0115\n",
            "Batch 2160/2573, Loss: 0.0068\n",
            "Batch 2170/2573, Loss: 0.0262\n",
            "Batch 2180/2573, Loss: 0.0162\n",
            "Batch 2190/2573, Loss: 0.0070\n",
            "Batch 2200/2573, Loss: 0.0112\n",
            "Batch 2210/2573, Loss: 0.0079\n",
            "Batch 2220/2573, Loss: 0.0138\n",
            "Batch 2230/2573, Loss: 0.0110\n",
            "Batch 2240/2573, Loss: 0.0224\n",
            "Batch 2250/2573, Loss: 0.0108\n",
            "Batch 2260/2573, Loss: 0.0188\n",
            "Batch 2270/2573, Loss: 0.0076\n",
            "Batch 2280/2573, Loss: 0.0084\n",
            "Batch 2290/2573, Loss: 0.0082\n",
            "Batch 2300/2573, Loss: 0.0199\n",
            "Batch 2310/2573, Loss: 0.0074\n",
            "Batch 2320/2573, Loss: 0.0102\n",
            "Batch 2330/2573, Loss: 0.0130\n",
            "Batch 2340/2573, Loss: 0.0102\n",
            "Batch 2350/2573, Loss: 0.0074\n",
            "Batch 2360/2573, Loss: 0.0202\n",
            "Batch 2370/2573, Loss: 0.0104\n",
            "Batch 2380/2573, Loss: 0.0095\n",
            "Batch 2390/2573, Loss: 0.0207\n",
            "Batch 2400/2573, Loss: 0.0133\n",
            "Batch 2410/2573, Loss: 0.0057\n",
            "Batch 2420/2573, Loss: 0.0422\n",
            "Batch 2430/2573, Loss: 0.0087\n",
            "Batch 2440/2573, Loss: 0.0075\n",
            "Batch 2450/2573, Loss: 0.0220\n",
            "Batch 2460/2573, Loss: 0.0117\n",
            "Batch 2470/2573, Loss: 0.0130\n",
            "Batch 2480/2573, Loss: 0.0210\n",
            "Batch 2490/2573, Loss: 0.0333\n",
            "Batch 2500/2573, Loss: 0.0249\n",
            "Batch 2510/2573, Loss: 0.0126\n",
            "Batch 2520/2573, Loss: 0.0105\n",
            "Batch 2530/2573, Loss: 0.0080\n",
            "Batch 2540/2573, Loss: 0.0274\n",
            "Batch 2550/2573, Loss: 0.0070\n",
            "Batch 2560/2573, Loss: 0.0236\n",
            "Batch 2570/2573, Loss: 0.0083\n",
            "Epoch 19 Average Loss: 0.0153\n",
            "\n",
            "Epoch 20/20\n",
            "------------------------------\n",
            "Batch 10/2573, Loss: 0.0102\n",
            "Batch 20/2573, Loss: 0.0107\n",
            "Batch 30/2573, Loss: 0.0129\n",
            "Batch 40/2573, Loss: 0.0117\n",
            "Batch 50/2573, Loss: 0.0104\n",
            "Batch 60/2573, Loss: 0.0099\n",
            "Batch 70/2573, Loss: 0.0168\n",
            "Batch 80/2573, Loss: 0.0102\n",
            "Batch 90/2573, Loss: 0.0089\n",
            "Batch 100/2573, Loss: 0.0153\n",
            "Batch 110/2573, Loss: 0.0166\n",
            "Batch 120/2573, Loss: 0.0054\n",
            "Batch 130/2573, Loss: 0.0072\n",
            "Batch 140/2573, Loss: 0.0147\n",
            "Batch 150/2573, Loss: 0.0048\n",
            "Batch 160/2573, Loss: 0.0088\n",
            "Batch 170/2573, Loss: 0.0172\n",
            "Batch 180/2573, Loss: 0.0059\n",
            "Batch 190/2573, Loss: 0.0057\n",
            "Batch 200/2573, Loss: 0.0055\n",
            "Batch 210/2573, Loss: 0.0202\n",
            "Batch 220/2573, Loss: 0.0186\n",
            "Batch 230/2573, Loss: 0.0082\n",
            "Batch 240/2573, Loss: 0.0146\n",
            "Batch 250/2573, Loss: 0.0144\n",
            "Batch 260/2573, Loss: 0.0072\n",
            "Batch 270/2573, Loss: 0.0070\n",
            "Batch 280/2573, Loss: 0.0282\n",
            "Batch 290/2573, Loss: 0.0239\n",
            "Batch 300/2573, Loss: 0.0144\n",
            "Batch 310/2573, Loss: 0.0048\n",
            "Batch 320/2573, Loss: 0.0156\n",
            "Batch 330/2573, Loss: 0.0093\n",
            "Batch 340/2573, Loss: 0.0083\n",
            "Batch 350/2573, Loss: 0.0167\n",
            "Batch 360/2573, Loss: 0.0086\n",
            "Batch 370/2573, Loss: 0.0128\n",
            "Batch 380/2573, Loss: 0.0083\n",
            "Batch 390/2573, Loss: 0.0048\n",
            "Batch 400/2573, Loss: 0.0133\n",
            "Batch 410/2573, Loss: 0.0120\n",
            "Batch 420/2573, Loss: 0.0108\n",
            "Batch 430/2573, Loss: 0.0358\n",
            "Batch 440/2573, Loss: 0.0085\n",
            "Batch 450/2573, Loss: 0.0082\n",
            "Batch 460/2573, Loss: 0.0118\n",
            "Batch 470/2573, Loss: 0.0089\n",
            "Batch 480/2573, Loss: 0.0097\n",
            "Batch 490/2573, Loss: 0.0071\n",
            "Batch 500/2573, Loss: 0.0079\n",
            "Batch 510/2573, Loss: 0.0167\n",
            "Batch 520/2573, Loss: 0.0260\n",
            "Batch 530/2573, Loss: 0.0302\n",
            "Batch 540/2573, Loss: 0.0059\n",
            "Batch 550/2573, Loss: 0.0390\n",
            "Batch 560/2573, Loss: 0.0133\n",
            "Batch 570/2573, Loss: 0.0165\n",
            "Batch 580/2573, Loss: 0.0130\n",
            "Batch 590/2573, Loss: 0.0120\n",
            "Batch 600/2573, Loss: 0.0202\n",
            "Batch 610/2573, Loss: 0.0105\n",
            "Batch 620/2573, Loss: 0.0155\n",
            "Batch 630/2573, Loss: 0.0174\n",
            "Batch 640/2573, Loss: 0.0092\n",
            "Batch 650/2573, Loss: 0.0080\n",
            "Batch 660/2573, Loss: 0.0137\n",
            "Batch 670/2573, Loss: 0.0101\n",
            "Batch 680/2573, Loss: 0.0142\n",
            "Batch 690/2573, Loss: 0.0066\n",
            "Batch 700/2573, Loss: 0.0232\n",
            "Batch 710/2573, Loss: 0.0074\n",
            "Batch 720/2573, Loss: 0.0170\n",
            "Batch 730/2573, Loss: 0.0283\n",
            "Batch 740/2573, Loss: 0.0118\n",
            "Batch 750/2573, Loss: 0.0097\n",
            "Batch 760/2573, Loss: 0.0121\n",
            "Batch 770/2573, Loss: 0.0131\n",
            "Batch 780/2573, Loss: 0.0104\n",
            "Batch 790/2573, Loss: 0.0082\n",
            "Batch 800/2573, Loss: 0.0327\n",
            "Batch 810/2573, Loss: 0.0132\n",
            "Batch 820/2573, Loss: 0.0180\n",
            "Batch 830/2573, Loss: 0.0085\n",
            "Batch 840/2573, Loss: 0.0205\n",
            "Batch 850/2573, Loss: 0.0096\n",
            "Batch 860/2573, Loss: 0.0067\n",
            "Batch 870/2573, Loss: 0.0103\n",
            "Batch 880/2573, Loss: 0.0111\n",
            "Batch 890/2573, Loss: 0.0103\n",
            "Batch 900/2573, Loss: 0.0096\n",
            "Batch 910/2573, Loss: 0.0216\n",
            "Batch 920/2573, Loss: 0.0458\n",
            "Batch 930/2573, Loss: 0.0142\n",
            "Batch 940/2573, Loss: 0.0076\n",
            "Batch 950/2573, Loss: 0.0119\n",
            "Batch 960/2573, Loss: 0.0126\n",
            "Batch 970/2573, Loss: 0.0310\n",
            "Batch 980/2573, Loss: 0.0117\n",
            "Batch 990/2573, Loss: 0.0139\n",
            "Batch 1000/2573, Loss: 0.0092\n",
            "Batch 1010/2573, Loss: 0.0182\n",
            "Batch 1020/2573, Loss: 0.0081\n",
            "Batch 1030/2573, Loss: 0.0156\n",
            "Batch 1040/2573, Loss: 0.0191\n",
            "Batch 1050/2573, Loss: 0.0118\n",
            "Batch 1060/2573, Loss: 0.0116\n",
            "Batch 1070/2573, Loss: 0.0289\n",
            "Batch 1080/2573, Loss: 0.0076\n",
            "Batch 1090/2573, Loss: 0.0136\n",
            "Batch 1100/2573, Loss: 0.0105\n",
            "Batch 1110/2573, Loss: 0.0116\n",
            "Batch 1120/2573, Loss: 0.0102\n",
            "Batch 1130/2573, Loss: 0.0063\n",
            "Batch 1140/2573, Loss: 0.0335\n",
            "Batch 1150/2573, Loss: 0.0119\n",
            "Batch 1160/2573, Loss: 0.0142\n",
            "Batch 1170/2573, Loss: 0.0118\n",
            "Batch 1180/2573, Loss: 0.0141\n",
            "Batch 1190/2573, Loss: 0.0115\n",
            "Batch 1200/2573, Loss: 0.0048\n",
            "Batch 1210/2573, Loss: 0.0265\n",
            "Batch 1220/2573, Loss: 0.0190\n",
            "Batch 1230/2573, Loss: 0.0151\n",
            "Batch 1240/2573, Loss: 0.0097\n",
            "Batch 1250/2573, Loss: 0.0290\n",
            "Batch 1260/2573, Loss: 0.0116\n",
            "Batch 1270/2573, Loss: 0.0133\n",
            "Batch 1280/2573, Loss: 0.0111\n",
            "Batch 1290/2573, Loss: 0.0138\n",
            "Batch 1300/2573, Loss: 0.0062\n",
            "Batch 1310/2573, Loss: 0.0103\n",
            "Batch 1320/2573, Loss: 0.0321\n",
            "Batch 1330/2573, Loss: 0.0237\n",
            "Batch 1340/2573, Loss: 0.0150\n",
            "Batch 1350/2573, Loss: 0.0176\n",
            "Batch 1360/2573, Loss: 0.0222\n",
            "Batch 1370/2573, Loss: 0.0210\n",
            "Batch 1380/2573, Loss: 0.0139\n",
            "Batch 1390/2573, Loss: 0.0135\n",
            "Batch 1400/2573, Loss: 0.0061\n",
            "Batch 1410/2573, Loss: 0.0129\n",
            "Batch 1420/2573, Loss: 0.0293\n",
            "Batch 1430/2573, Loss: 0.0067\n",
            "Batch 1440/2573, Loss: 0.0165\n",
            "Batch 1450/2573, Loss: 0.0053\n",
            "Batch 1460/2573, Loss: 0.0220\n",
            "Batch 1470/2573, Loss: 0.0054\n",
            "Batch 1480/2573, Loss: 0.0147\n",
            "Batch 1490/2573, Loss: 0.0059\n",
            "Batch 1500/2573, Loss: 0.0085\n",
            "Batch 1510/2573, Loss: 0.0059\n",
            "Batch 1520/2573, Loss: 0.0319\n",
            "Batch 1530/2573, Loss: 0.0100\n",
            "Batch 1540/2573, Loss: 0.0132\n",
            "Batch 1550/2573, Loss: 0.0129\n",
            "Batch 1560/2573, Loss: 0.0228\n",
            "Batch 1570/2573, Loss: 0.0050\n",
            "Batch 1580/2573, Loss: 0.0110\n",
            "Batch 1590/2573, Loss: 0.0094\n",
            "Batch 1600/2573, Loss: 0.0203\n",
            "Batch 1610/2573, Loss: 0.0291\n",
            "Batch 1620/2573, Loss: 0.0153\n",
            "Batch 1630/2573, Loss: 0.0284\n",
            "Batch 1640/2573, Loss: 0.0240\n",
            "Batch 1650/2573, Loss: 0.0068\n",
            "Batch 1660/2573, Loss: 0.0150\n",
            "Batch 1670/2573, Loss: 0.0059\n",
            "Batch 1680/2573, Loss: 0.0357\n",
            "Batch 1690/2573, Loss: 0.0118\n",
            "Batch 1700/2573, Loss: 0.0161\n",
            "Batch 1710/2573, Loss: 0.0205\n",
            "Batch 1720/2573, Loss: 0.0149\n",
            "Batch 1730/2573, Loss: 0.0161\n",
            "Batch 1740/2573, Loss: 0.0242\n",
            "Batch 1750/2573, Loss: 0.0096\n",
            "Batch 1760/2573, Loss: 0.0461\n",
            "Batch 1770/2573, Loss: 0.0068\n",
            "Batch 1780/2573, Loss: 0.0133\n",
            "Batch 1790/2573, Loss: 0.0090\n",
            "Batch 1800/2573, Loss: 0.0127\n",
            "Batch 1810/2573, Loss: 0.0127\n",
            "Batch 1820/2573, Loss: 0.0085\n",
            "Batch 1830/2573, Loss: 0.0183\n",
            "Batch 1840/2573, Loss: 0.0134\n",
            "Batch 1850/2573, Loss: 0.0156\n",
            "Batch 1860/2573, Loss: 0.0154\n",
            "Batch 1870/2573, Loss: 0.0200\n",
            "Batch 1880/2573, Loss: 0.0133\n",
            "Batch 1890/2573, Loss: 0.0222\n",
            "Batch 1900/2573, Loss: 0.0134\n",
            "Batch 1910/2573, Loss: 0.0134\n",
            "Batch 1920/2573, Loss: 0.0192\n",
            "Batch 1930/2573, Loss: 0.0151\n",
            "Batch 1940/2573, Loss: 0.0103\n",
            "Batch 1950/2573, Loss: 0.0082\n",
            "Batch 1960/2573, Loss: 0.0081\n",
            "Batch 1970/2573, Loss: 0.0129\n",
            "Batch 1980/2573, Loss: 0.0068\n",
            "Batch 1990/2573, Loss: 0.0377\n",
            "Batch 2000/2573, Loss: 0.0254\n",
            "Batch 2010/2573, Loss: 0.0177\n",
            "Batch 2020/2573, Loss: 0.0162\n",
            "Batch 2030/2573, Loss: 0.0110\n",
            "Batch 2040/2573, Loss: 0.0172\n",
            "Batch 2050/2573, Loss: 0.0166\n",
            "Batch 2060/2573, Loss: 0.0107\n",
            "Batch 2070/2573, Loss: 0.0334\n",
            "Batch 2080/2573, Loss: 0.0125\n",
            "Batch 2090/2573, Loss: 0.0290\n",
            "Batch 2100/2573, Loss: 0.0099\n",
            "Batch 2110/2573, Loss: 0.0083\n",
            "Batch 2120/2573, Loss: 0.0165\n",
            "Batch 2130/2573, Loss: 0.0154\n",
            "Batch 2140/2573, Loss: 0.0184\n",
            "Batch 2150/2573, Loss: 0.0104\n",
            "Batch 2160/2573, Loss: 0.0054\n",
            "Batch 2170/2573, Loss: 0.0122\n",
            "Batch 2180/2573, Loss: 0.0126\n",
            "Batch 2190/2573, Loss: 0.0132\n",
            "Batch 2200/2573, Loss: 0.0278\n",
            "Batch 2210/2573, Loss: 0.0255\n",
            "Batch 2220/2573, Loss: 0.0283\n",
            "Batch 2230/2573, Loss: 0.0355\n",
            "Batch 2240/2573, Loss: 0.0179\n",
            "Batch 2250/2573, Loss: 0.0409\n",
            "Batch 2260/2573, Loss: 0.0200\n",
            "Batch 2270/2573, Loss: 0.0037\n",
            "Batch 2280/2573, Loss: 0.0108\n",
            "Batch 2290/2573, Loss: 0.0113\n",
            "Batch 2300/2573, Loss: 0.0054\n",
            "Batch 2310/2573, Loss: 0.0168\n",
            "Batch 2320/2573, Loss: 0.0097\n",
            "Batch 2330/2573, Loss: 0.0143\n",
            "Batch 2340/2573, Loss: 0.0099\n",
            "Batch 2350/2573, Loss: 0.0152\n",
            "Batch 2360/2573, Loss: 0.0255\n",
            "Batch 2370/2573, Loss: 0.0178\n",
            "Batch 2380/2573, Loss: 0.0081\n",
            "Batch 2390/2573, Loss: 0.0278\n",
            "Batch 2400/2573, Loss: 0.0182\n",
            "Batch 2410/2573, Loss: 0.0124\n",
            "Batch 2420/2573, Loss: 0.0179\n",
            "Batch 2430/2573, Loss: 0.0159\n",
            "Batch 2440/2573, Loss: 0.0057\n",
            "Batch 2450/2573, Loss: 0.0114\n",
            "Batch 2460/2573, Loss: 0.0090\n",
            "Batch 2470/2573, Loss: 0.0210\n",
            "Batch 2480/2573, Loss: 0.0396\n",
            "Batch 2490/2573, Loss: 0.0112\n",
            "Batch 2500/2573, Loss: 0.0105\n",
            "Batch 2510/2573, Loss: 0.0103\n",
            "Batch 2520/2573, Loss: 0.0145\n",
            "Batch 2530/2573, Loss: 0.0069\n",
            "Batch 2540/2573, Loss: 0.0238\n",
            "Batch 2550/2573, Loss: 0.0097\n",
            "Batch 2560/2573, Loss: 0.0136\n",
            "Batch 2570/2573, Loss: 0.0123\n",
            "Epoch 20 Average Loss: 0.0151\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **7: Evaluation Function**\n",
        "\n",
        "- Sets model to evaluation mode\n",
        "- Iterates through test data without gradient computation\n",
        "- Calculates Euclidean distances between embeddings\n",
        "- Makes binary predictions using 0.6 threshold\n",
        "- Computes precision, recall, and F1-score using sklearn\n",
        "- Prints detailed evaluation results and distance statistics"
      ],
      "metadata": {
        "id": "ctR1hUHzQRq4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def evaluate_model(model, test_loader, threshold=0.7):\n",
        "    \"\"\"\n",
        "    Evaluate the trained model on test set with pre-computed embeddings\n",
        "    \"\"\"\n",
        "    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "    model = model.to(device)\n",
        "    model.eval()\n",
        "\n",
        "    all_predictions = []\n",
        "    all_labels = []\n",
        "    all_distances = []\n",
        "\n",
        "    print(\"Evaluating model on test set...\")\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for embedding1_batch, embedding2_batch, labels_batch in test_loader:\n",
        "            # Move tensors to device\n",
        "            embedding1_batch = embedding1_batch.to(device)\n",
        "            embedding2_batch = embedding2_batch.to(device)\n",
        "            labels_batch = labels_batch.to(device)\n",
        "\n",
        "            # Forward pass\n",
        "            output1, output2 = model(embedding1_batch, embedding2_batch)\n",
        "\n",
        "            # Calculate distances\n",
        "            distances = torch.nn.functional.pairwise_distance(output1, output2)\n",
        "\n",
        "            # Make predictions based on threshold\n",
        "            predictions = (distances < threshold).float()\n",
        "\n",
        "            # Store results\n",
        "            all_predictions.extend(predictions.cpu().numpy())\n",
        "            all_labels.extend(labels_batch.cpu().numpy())\n",
        "            all_distances.extend(distances.cpu().numpy())\n",
        "\n",
        "    # Convert to numpy arrays\n",
        "    all_predictions = np.array(all_predictions)\n",
        "    all_labels = np.array(all_labels)\n",
        "    all_distances = np.array(all_distances)\n",
        "\n",
        "    # Calculate metrics\n",
        "    precision, recall, f1, _ = precision_recall_fscore_support(\n",
        "        all_labels, all_predictions, average='binary', zero_division=0\n",
        "    )\n",
        "\n",
        "    # Print results\n",
        "    print(f\"\\nEvaluation Results (threshold = {threshold}):\")\n",
        "    print(\"-\" * 40)\n",
        "    print(f\"Precision: {precision:.4f}\")\n",
        "    print(f\"Recall: {recall:.4f}\")\n",
        "    print(f\"F1-Score: {f1:.4f}\")\n",
        "    print(f\"Average Distance (Matches): {all_distances[all_labels == 1].mean():.4f}\")\n",
        "    print(f\"Average Distance (Non-matches): {all_distances[all_labels == 0].mean():.4f}\")\n",
        "\n",
        "    return precision, recall, f1, all_predictions, all_labels, all_distances"
      ],
      "metadata": {
        "id": "CApfAzdRQQ-M"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "THRESHOLD = 0.6\n",
        "\n",
        "precision, recall, f1, predictions, labels, distances = evaluate_model(\n",
        "        trained_model,\n",
        "        test_loader,\n",
        "        threshold=THRESHOLD\n",
        "    )"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ryWzf4HEQNM6",
        "outputId": "618018aa-e069-4670-f212-e5aafafae43d"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Evaluating model on test set...\n",
            "\n",
            "Evaluation Results (threshold = 0.6):\n",
            "----------------------------------------\n",
            "Precision: 0.9661\n",
            "Recall: 0.9970\n",
            "F1-Score: 0.9813\n",
            "Average Distance (Matches): 0.1225\n",
            "Average Distance (Non-matches): 1.3318\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **8: Model Saving Function**\n",
        "\n",
        "- Saves only the trainable projection head (since SBERT is frozen)\n",
        "- Stores model metadata for proper reconstruction\n",
        "- Implements loading function to recreate the model\n",
        "- Uses CPU mapping to ensure compatibility across devices"
      ],
      "metadata": {
        "id": "wCp2fbcyQmZX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def save_model(model, filepath='siamese_matcher.pth'):\n",
        "    \"\"\"\n",
        "    Save the trained model\n",
        "    \"\"\"\n",
        "    # Save only the trainable projection head since SentenceTransformer is frozen\n",
        "    model_state = {\n",
        "        'projection_head_state_dict': model.projection_head.state_dict(),\n",
        "        'model_architecture': 'SiameseNetwork',\n",
        "        'sbert_model': 'all-MiniLM-L6-v2',\n",
        "        'embedding_dim': 128\n",
        "    }\n",
        "\n",
        "    torch.save(model_state, filepath)\n",
        "    print(f\"Model saved to {filepath}\")\n",
        "\n",
        "def load_model(filepath='siamese_matcher.pth'):\n",
        "    \"\"\"\n",
        "    Load the trained model\n",
        "    \"\"\"\n",
        "    model_state = torch.load(filepath, map_location='cpu')\n",
        "\n",
        "    # Create new model instance\n",
        "    model = SiameseNetwork(embedding_dim=model_state['embedding_dim'])\n",
        "\n",
        "    # Load only the projection head weights\n",
        "    model.projection_head.load_state_dict(model_state['projection_head_state_dict'])\n",
        "\n",
        "    print(f\"Model loaded from {filepath}\")\n",
        "    return model\n"
      ],
      "metadata": {
        "id": "yRDLVXTqQevf"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "save_model(trained_model, 'siamese_matcher.pth')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_Pm6HlLZQtuQ",
        "outputId": "57a1fc46-4fe3-41b3-cbc1-5f3dac2abcad"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model saved to siamese_matcher.pth\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def test_inference(model_path='siamese_matcher.pth'):\n",
        "    \"\"\"\n",
        "    Example of how to use the trained model for inference\n",
        "    \"\"\"\n",
        "    import torch\n",
        "    from sentence_transformers import SentenceTransformer\n",
        "\n",
        "    # Load the trained Siamese model\n",
        "    model = load_model(model_path)\n",
        "\n",
        "    # Move model to device (GPU if available)\n",
        "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "    model = model.to(device)\n",
        "    model.eval()\n",
        "\n",
        "    # Load the SentenceTransformer model\n",
        "    text_encoder = SentenceTransformer('all-MiniLM-L6-v2')\n",
        "\n",
        "    # Example product pairs for testing\n",
        "    test_pairs = [\n",
        "    (\"iPhone 13 Pro Max 256GB Blue\", \"Apple iPhone 13 Pro Max 256GB Blue\"),\n",
        "    (\"Samsung Galaxy S21\", \"iPhone 12 Pro\"),\n",
        "    (\"Nike Air Force 1 White\", \"Nike Air Force One White Sneakers\"),\n",
        "    (\"Dell Laptop 15 inch\", \"MacBook Pro 13 inch\"),\n",
        "\n",
        "    # Additional 30 pairs\n",
        "    (\"Sony WH-1000XM4 Headphones\", \"Sony WH1000XM4 Wireless Noise Cancelling Headphones\"),\n",
        "    (\"Canon EOS 5D Mark IV DSLR\", \"Canon EOS 6D Mark II DSLR Camera\"),\n",
        "    (\"Apple Watch Series 7 GPS\", \"Apple Watch Series 7 Cellular\"),\n",
        "    (\"Adidas Ultraboost 21\", \"Adidas Ultraboost 20 Shoes\"),\n",
        "    (\"Lenovo ThinkPad X1 Carbon\", \"Lenovo ThinkPad X1 Yoga\"),\n",
        "    (\"Samsung Galaxy Tab S7\", \"Samsung Galaxy Tab S8\"),\n",
        "    (\"Google Pixel 6 Pro\", \"Google Pixel 6\"),\n",
        "    (\"Bose QuietComfort 35 II\", \"Bose Noise Cancelling Headphones 700\"),\n",
        "    (\"HP Spectre x360 Laptop\", \"HP Envy x360 Laptop\"),\n",
        "    (\"Microsoft Surface Pro 7\", \"Microsoft Surface Go 3\"),\n",
        "    (\"Fitbit Charge 5\", \"Fitbit Inspire 2\"),\n",
        "    (\"Logitech MX Master 3 Mouse\", \"Logitech MX Anywhere 3 Mouse\"),\n",
        "    (\"Razer BlackWidow V3 Keyboard\", \"Razer Huntsman Mini Keyboard\"),\n",
        "    (\"GoPro Hero 9 Black\", \"GoPro Hero 8 Black\"),\n",
        "    (\"Nintendo Switch Console\", \"Nintendo Switch OLED Console\"),\n",
        "    (\"Amazon Echo Dot 4th Gen\", \"Amazon Echo Dot 3rd Gen\"),\n",
        "    (\"JBL Flip 5 Bluetooth Speaker\", \"JBL Charge 4 Speaker\"),\n",
        "    (\"Canon PIXMA MG3620 Printer\", \"Canon PIXMA TS6320 Printer\"),\n",
        "    (\"Samsung Galaxy Buds Pro\", \"Samsung Galaxy Buds Live\"),\n",
        "    (\"Apple AirPods Pro\", \"Apple AirPods 2nd Gen\"),\n",
        "    (\"Sony PlayStation 5 Console\", \"Sony PlayStation 4 Pro\"),\n",
        "    (\"LG 55 inch OLED TV\", \"LG 65 inch OLED TV\"),\n",
        "    (\"Dyson V11 Vacuum Cleaner\", \"Dyson V10 Vacuum Cleaner\"),\n",
        "    (\"Instant Pot Duo 7-in-1\", \"Instant Pot Duo 6-in-1\"),\n",
        "    (\"Nikon D750 DSLR Camera\", \"Nikon D5600 DSLR Camera\"),\n",
        "    (\"Corsair Vengeance LPX 16GB RAM\", \"Corsair Dominator Platinum 16GB RAM\"),\n",
        "    (\"Seagate 2TB External Hard Drive\", \"Seagate 1TB External Hard Drive\"),\n",
        "    (\"Samsung 970 EVO Plus SSD 1TB\", \"Samsung 980 PRO SSD 1TB\"),\n",
        "    (\"Kingston A2000 500GB NVMe SSD\", \"Crucial P2 500GB NVMe SSD\"),\n",
        "    (\"Anker PowerCore 10000mAh\", \"Crucial P2 500GB NVMe SSD\")\n",
        "]\n",
        "    print(\"Testing inference on sample pairs:\")\n",
        "    print(\"-\" * 60)\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for title1, title2 in test_pairs:\n",
        "            # Get embeddings using the SentenceTransformer\n",
        "            embedding1 = text_encoder.encode(title1, convert_to_tensor=True).unsqueeze(0).to(device)\n",
        "            embedding2 = text_encoder.encode(title2, convert_to_tensor=True).unsqueeze(0).to(device)\n",
        "\n",
        "            # Get projected embeddings from the Siamese network\n",
        "            output1, output2 = model(embedding1, embedding2)\n",
        "\n",
        "            # Calculate distance\n",
        "            distance = torch.nn.functional.pairwise_distance(output1, output2).item()\n",
        "\n",
        "            # Make prediction\n",
        "            threshold = 0.6\n",
        "            is_match = distance < threshold\n",
        "\n",
        "            print(f\"Title 1: {title1}\")\n",
        "            print(f\"Title 2: {title2}\")\n",
        "            print(f\"Distance: {distance:.4f}\")\n",
        "            print(f\"Prediction: {'MATCH' if is_match else 'NO MATCH'}\")\n",
        "            print(\"-\" * 60)\n",
        "\n",
        "# Uncomment to test inference after training\n",
        "# test_inference()\n"
      ],
      "metadata": {
        "id": "AdIM2qLeQz7F"
      },
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test_inference('siamese_matcher.pth')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xvjdpPKQRoPM",
        "outputId": "31fdcf8f-7780-4e0a-ef4d-4d95e5005739"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model loaded from siamese_matcher.pth\n",
            "Testing inference on sample pairs:\n",
            "------------------------------------------------------------\n",
            "Title 1: iPhone 13 Pro Max 256GB Blue\n",
            "Title 2: Apple iPhone 13 Pro Max 256GB Blue\n",
            "Distance: 0.0373\n",
            "Prediction: MATCH\n",
            "------------------------------------------------------------\n",
            "Title 1: Samsung Galaxy S21\n",
            "Title 2: iPhone 12 Pro\n",
            "Distance: 0.9483\n",
            "Prediction: NO MATCH\n",
            "------------------------------------------------------------\n",
            "Title 1: Nike Air Force 1 White\n",
            "Title 2: Nike Air Force One White Sneakers\n",
            "Distance: 0.2780\n",
            "Prediction: MATCH\n",
            "------------------------------------------------------------\n",
            "Title 1: Dell Laptop 15 inch\n",
            "Title 2: MacBook Pro 13 inch\n",
            "Distance: 0.5890\n",
            "Prediction: MATCH\n",
            "------------------------------------------------------------\n",
            "Title 1: Sony WH-1000XM4 Headphones\n",
            "Title 2: Sony WH1000XM4 Wireless Noise Cancelling Headphones\n",
            "Distance: 0.3523\n",
            "Prediction: MATCH\n",
            "------------------------------------------------------------\n",
            "Title 1: Canon EOS 5D Mark IV DSLR\n",
            "Title 2: Canon EOS 6D Mark II DSLR Camera\n",
            "Distance: 0.2686\n",
            "Prediction: MATCH\n",
            "------------------------------------------------------------\n",
            "Title 1: Apple Watch Series 7 GPS\n",
            "Title 2: Apple Watch Series 7 Cellular\n",
            "Distance: 0.1179\n",
            "Prediction: MATCH\n",
            "------------------------------------------------------------\n",
            "Title 1: Adidas Ultraboost 21\n",
            "Title 2: Adidas Ultraboost 20 Shoes\n",
            "Distance: 0.2961\n",
            "Prediction: MATCH\n",
            "------------------------------------------------------------\n",
            "Title 1: Lenovo ThinkPad X1 Carbon\n",
            "Title 2: Lenovo ThinkPad X1 Yoga\n",
            "Distance: 0.5961\n",
            "Prediction: MATCH\n",
            "------------------------------------------------------------\n",
            "Title 1: Samsung Galaxy Tab S7\n",
            "Title 2: Samsung Galaxy Tab S8\n",
            "Distance: 0.1648\n",
            "Prediction: MATCH\n",
            "------------------------------------------------------------\n",
            "Title 1: Google Pixel 6 Pro\n",
            "Title 2: Google Pixel 6\n",
            "Distance: 0.0435\n",
            "Prediction: MATCH\n",
            "------------------------------------------------------------\n",
            "Title 1: Bose QuietComfort 35 II\n",
            "Title 2: Bose Noise Cancelling Headphones 700\n",
            "Distance: 0.3689\n",
            "Prediction: MATCH\n",
            "------------------------------------------------------------\n",
            "Title 1: HP Spectre x360 Laptop\n",
            "Title 2: HP Envy x360 Laptop\n",
            "Distance: 0.4737\n",
            "Prediction: MATCH\n",
            "------------------------------------------------------------\n",
            "Title 1: Microsoft Surface Pro 7\n",
            "Title 2: Microsoft Surface Go 3\n",
            "Distance: 0.3035\n",
            "Prediction: MATCH\n",
            "------------------------------------------------------------\n",
            "Title 1: Fitbit Charge 5\n",
            "Title 2: Fitbit Inspire 2\n",
            "Distance: 0.2773\n",
            "Prediction: MATCH\n",
            "------------------------------------------------------------\n",
            "Title 1: Logitech MX Master 3 Mouse\n",
            "Title 2: Logitech MX Anywhere 3 Mouse\n",
            "Distance: 0.1786\n",
            "Prediction: MATCH\n",
            "------------------------------------------------------------\n",
            "Title 1: Razer BlackWidow V3 Keyboard\n",
            "Title 2: Razer Huntsman Mini Keyboard\n",
            "Distance: 0.3818\n",
            "Prediction: MATCH\n",
            "------------------------------------------------------------\n",
            "Title 1: GoPro Hero 9 Black\n",
            "Title 2: GoPro Hero 8 Black\n",
            "Distance: 0.1093\n",
            "Prediction: MATCH\n",
            "------------------------------------------------------------\n",
            "Title 1: Nintendo Switch Console\n",
            "Title 2: Nintendo Switch OLED Console\n",
            "Distance: 0.5321\n",
            "Prediction: MATCH\n",
            "------------------------------------------------------------\n",
            "Title 1: Amazon Echo Dot 4th Gen\n",
            "Title 2: Amazon Echo Dot 3rd Gen\n",
            "Distance: 0.2559\n",
            "Prediction: MATCH\n",
            "------------------------------------------------------------\n",
            "Title 1: JBL Flip 5 Bluetooth Speaker\n",
            "Title 2: JBL Charge 4 Speaker\n",
            "Distance: 0.3279\n",
            "Prediction: MATCH\n",
            "------------------------------------------------------------\n",
            "Title 1: Canon PIXMA MG3620 Printer\n",
            "Title 2: Canon PIXMA TS6320 Printer\n",
            "Distance: 0.2469\n",
            "Prediction: MATCH\n",
            "------------------------------------------------------------\n",
            "Title 1: Samsung Galaxy Buds Pro\n",
            "Title 2: Samsung Galaxy Buds Live\n",
            "Distance: 0.0823\n",
            "Prediction: MATCH\n",
            "------------------------------------------------------------\n",
            "Title 1: Apple AirPods Pro\n",
            "Title 2: Apple AirPods 2nd Gen\n",
            "Distance: 0.3028\n",
            "Prediction: MATCH\n",
            "------------------------------------------------------------\n",
            "Title 1: Sony PlayStation 5 Console\n",
            "Title 2: Sony PlayStation 4 Pro\n",
            "Distance: 0.3111\n",
            "Prediction: MATCH\n",
            "------------------------------------------------------------\n",
            "Title 1: LG 55 inch OLED TV\n",
            "Title 2: LG 65 inch OLED TV\n",
            "Distance: 0.1041\n",
            "Prediction: MATCH\n",
            "------------------------------------------------------------\n",
            "Title 1: Dyson V11 Vacuum Cleaner\n",
            "Title 2: Dyson V10 Vacuum Cleaner\n",
            "Distance: 0.2892\n",
            "Prediction: MATCH\n",
            "------------------------------------------------------------\n",
            "Title 1: Instant Pot Duo 7-in-1\n",
            "Title 2: Instant Pot Duo 6-in-1\n",
            "Distance: 0.1043\n",
            "Prediction: MATCH\n",
            "------------------------------------------------------------\n",
            "Title 1: Nikon D750 DSLR Camera\n",
            "Title 2: Nikon D5600 DSLR Camera\n",
            "Distance: 0.4157\n",
            "Prediction: MATCH\n",
            "------------------------------------------------------------\n",
            "Title 1: Corsair Vengeance LPX 16GB RAM\n",
            "Title 2: Corsair Dominator Platinum 16GB RAM\n",
            "Distance: 0.4473\n",
            "Prediction: MATCH\n",
            "------------------------------------------------------------\n",
            "Title 1: Seagate 2TB External Hard Drive\n",
            "Title 2: Seagate 1TB External Hard Drive\n",
            "Distance: 0.2184\n",
            "Prediction: MATCH\n",
            "------------------------------------------------------------\n",
            "Title 1: Samsung 970 EVO Plus SSD 1TB\n",
            "Title 2: Samsung 980 PRO SSD 1TB\n",
            "Distance: 0.2927\n",
            "Prediction: MATCH\n",
            "------------------------------------------------------------\n",
            "Title 1: Kingston A2000 500GB NVMe SSD\n",
            "Title 2: Crucial P2 500GB NVMe SSD\n",
            "Distance: 0.3751\n",
            "Prediction: MATCH\n",
            "------------------------------------------------------------\n",
            "Title 1: Anker PowerCore 10000mAh\n",
            "Title 2: Crucial P2 500GB NVMe SSD\n",
            "Distance: 0.6259\n",
            "Prediction: NO MATCH\n",
            "------------------------------------------------------------\n"
          ]
        }
      ]
    }
  ]
}